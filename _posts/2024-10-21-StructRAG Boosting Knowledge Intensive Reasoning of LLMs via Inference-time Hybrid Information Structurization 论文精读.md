---
layout: article
title: StructRAG 论文精读
key: post63
mode: immersive
tags:
  - nlp
  - 自然语言处理
  - 论文笔记
header:
  theme: ocean
article_header:
  type: overlay
  theme: ocean
  background_color: "#f1f8ff"
  background_image: false
excerpt_separator: <!---more-->
mathjax_autoNumber: "false"
---

# StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization 论文精读


<!---more-->

> 论文来源：刘老师发的
>
> 方向：RAG
>
> 遇到的问题：
>
> 


$$
\sum test_{i=1}^{n}i
$$

## 背景知识

### 知识密集型推理任务（knowledeg- intensive reasoning task）:

知识密集型推理任务（knowledge-intensive reasoning task）指的是需要大量先验知识或专业领域知识来进行推理和解决的任务。在这种任务中，推理和决策需要依赖于广泛的、深入的领域知识，通常涉及多个概念和关系的复杂推理过程。
举例来说，医学诊断就是一个知识密集型推理任务的典型案例。医生在对患者进行诊断时，需要结合患者的症状、病史、实验室检查结果等信息，并借助广泛的医学知识进行推理和判断，以最终做出准确的诊断。这种任务需要医生综合运用大量的医学知识，对病情进行推理和归纳，而且通常也需要考虑患者的个体差异和复杂情况，因此属于知识密集型推理任务的范畴

### 认知负荷理论

认知负荷理论是由John Sweller在1988年提出的，用于解释人类认知处理和学习的理论框架。该理论指出，**人脑的认知系统有着有限的处理能力，因此在学习和完成任务时会面临认知负荷的问题。**认知负荷理论通过研究认知处理的本质和人类学习的方式，提出了如何最大限度地减轻认知负荷，以便更有效地进行学习和任务处理。
认知负荷理论分为三种认知负荷：

1. 内在认知负荷：指的是完成任务所必须的认知处理和思考负担。例如，当学习新的知识或解决复杂问题时，人们会面临内在认知负荷。
2. 外在认知负荷：指的是执行任务所需要的外部支持和资源。例如，学习辅助工具、老师的讲解和指导等都可以帮助分担外在认知负荷。
3. 增量认知负荷：指的是学习者额外承担的负担，用于处理不必要的信息和过多的任务要求。
   认知负荷理论的应用包括设计更有效的教学方法、界面设计、工作流程等，以减轻学习者或用户在执行任务时所面临的认知负荷，从而提高学习效果和任务执行效率。

### HotpotQA等多跳任务

HotpotQA是一项旨在评估自然语言处理模型多跳推理（multi-hop reasoning）能力的问答任务。多跳推理指的是模型在回答问题时，需要跨越多个中间步骤，整合来自不同来源的信息，才能得出正确的答案。

**HotpotQA的主要特点：**

1. **多段落推理**：问题需要从多个文档或段落中提取信息，而不仅仅是从单一来源。这要求模型能够关联和综合不同信息片段。

2. **支持证据**：除了提供答案外，模型还需要指出支持答案的证据段落。这增强了模型的可解释性，便于评估其推理过程。

3. **多样化的问题类型**：包括比较类、桥接类等问题，涉及不同的推理路径和策略。

4. **开放域问答**：问题涉及广泛的主题，要求模型具备广博的知识和灵活的推理能力。

**其他多跳任务：**

除了HotpotQA，还有其他一些多跳推理任务和数据集，用于评估和提高模型的推理能力：

1. **WikiHop**：需要从维基百科的多个文档中进行推理，找到连接问题和答案的路径。

2. **ComplexWebQuestions**：基于WebQuestions数据集，问题更复杂，需要多步推理才能回答。

3. **QAngaroo**：包括WikiHop和MedHop两个子数据集，专注于跨文档的多跳推理。

4. **OpenBookQA**：要求模型结合常识和科学知识，进行多步推理来回答问题。

5. **NarrativeQA**：基于故事和情节的问题，需要理解上下文并进行深度推理。

**多跳任务的挑战：**

- **信息整合**：模型需要有效地从多个来源检索和整合信息。

- **推理路径**：需要找到正确的推理路径，避免干扰信息。

- **计算复杂性**：多跳推理增加了计算和时间成本，挑战模型的效率。

- **可解释性**：提供清晰的推理过程和证据对于模型的可信度至关重要。

**研究意义：**

多跳任务对于推进自然语言理解和人工智能推理能力具有重要意义。它们促使模型超越简单的模式匹配，发展出更深层次的理解和推理能力。这对于构建更智能、更可靠的AI系统，如智能问答、对话系统和决策支持系统，具有深远的影响。

**总结：**

HotpotQA等多跳任务通过设计需要跨越多个信息源的问题，评估模型的推理和信息整合能力。这些任务推动了自然语言处理领域在理解、推理和可解释性方面的研究和发展。

### Loong基准

**Loong基准**（Loong Benchmark）是一个专门为测试大语言模型（LLMs）的长上下文理解能力而设计的评估框架，重点是多文档问答（QA）任务，旨在创建更符合现实的复杂场景。这一基准与传统的长上下文评估不同，它从金融报告、法律案件和学术论文这三个领域精心选择文档，以确保上下文的完整性和相关性。

Loong基准包含四个主要评估类别：
1. **聚光定位**（Spotlight Locating） - 测试模型在多个文档中定位关键信息的能力。
2. **比较**（Comparison） - 评估模型跨文档比较信息的能力。
3. **聚类**（Clustering） - 基于语义相似性对相关信息进行分组。
4. **推理链**（Chain of Reasoning） - 检验模型在长上下文下进行逻辑推理的能力。

此外，Loong任务集覆盖了不同长度的输入，从10K到超过200K个token，允许对模型在不同上下文长度和任务复杂性下的性能进行细粒度评估。任务以中英文形式呈现，更接近实际应用场景【20†source】【21†source】【23†source】。

### Pocast Transcripts

**Podcast Transcripts** 数据集是专为音频媒体的自然语言处理（NLP）任务而设计的，旨在研究和处理播客的语音转录文本。这个领域最近受到了越来越多的关注，因为播客内容形式丰富，涉及新闻、对话、故事讲述等多种风格。以下是几种主要的 Podcast Transcripts 数据集：

1. **Spotify Podcast Dataset**：这是一个规模较大的数据集，包含约10万集播客，包含音频文件及其对应的自动语音识别（ASR）转录文本。该数据集包含来自全球不同地区的播客，涵盖多种音质和长度的音频内容，总时长超过5万小时【32†source】【33†source】。

2. **PodcastFillers Dataset**：该数据集专注于英语播客中的语气词和填充词标注，包含199集完整播客，共计145小时的音频。这些转录文本也由自动语音识别系统生成，专门用于分析语音中的自然停顿和填充词【32†source】。

这些数据集不仅提供了音频文件和转录文本，还包括丰富的元数据，如播客节目的标题、描述、时长、发布者等信息，有助于多维度的分析和处理，尤其适合于语音识别、文本摘要和对话建模等研究方向【34†source】。

## 摘要

> 思考的问题：
>
> 原始文档->结构化的信息是怎么样的?
>
> 怎么利用结构化的信息的？

背景：检索增强生成（RAG）是在许多基于知识的任务中有效增强大型语言模型（LLM）的关键手段

面对的问题：

- 现有的RAG方法在知识密集型推理任务中存在困难，因为这些任务所需的有用信息分散且不规律
- 这一特点使得现有的RAG方法很难准确识别关键信息并进行全局推理，因为存在噪声干扰

解决办法：

- 本文通过人类在应对知识密集型推理时将原始信息转化为各种**结构化知识**的认知理论的启发，提出了一个新的框架，名为StructRAG
- 该框架可以在进行任务时识别最佳结构类型，将原始文档重新构建为这种结构化格式，并根据生成的结构进行推理得出答案

实验结果

- 在各种知识密集型任务上进行的大量实验表明，StructRAG实现了最先进的性能
- 特别擅长在具有挑战性的场景中表现，展示了它作为增强LLMs在复杂现实世界应用中的有效解决方案的潜力。

## 引言

> 知识密集型推理任务（knowledeg- intensive reasoning task）是什么意思？
>
> 怎么根据根据任务需求以最合适的结构？
>
> 作者的LLM分散知识化结构 LLM-based scattered knowledge structurize是什么？
>
> 怎么构建偏好训练数据的？
>
> 数据是怎么样的？
>
> 如何使用DPO训练混合结构路由器？

### RAG背景

- 随着深度学习技术的进步，大规模语言模型（LLMs）在自然语言任务中展现出相当的优势，并广泛应用于复杂的现实世界场景（OpenAI等，2024年；Yang等，2024年a）。
- 然而，由于缺乏领域特定知识、实时更新信息和专有知识，它们在事实任务中仍然存在局限性
- 解决办法：RAG，通常，RAG方法涉及将原始文档分割成较短的部分，根据查询检索出最相关的部分，用这些部分使LLMs能够生成可靠的答案。

### 本文针对的RAG问题背景

- 当前的RAG方法无法有效处理**知识密集型推理任务**，因为解决这些任务所需的相关信息的分散性质

  - 具体来说，知识密集型推理任务通常需要大量有用的信息，这些信息分散在提供的文档中的许多位置

  - 与此同时，模型需要在检索到有用信息后执行综合推理

    >以财务报告分析为例，考虑到大量的财务文件和比较多家公司发展趋势的需求，LLM需要挖掘原始文件中散落的所有相关财务指标，然后通过仔细比较和全面分析这些指标来生成见解。

- 标准的RAG方法面临着精确检索所有相关文本块的挑战

  - 这些文本块可能包含大量噪音
  - 并且集成多个关键信息用于推理，导致这些任务的性能不尽如人意。

### 人类的思考方式的启发

人们并不是通过简单阅读原始文本来解决知识密集型的推理任务

- 正如认知负荷理论所建议的，人类通常将文档中的零散信息总结为结构化知识，进而缩短推理路径并实现更准确的判断
- 认知匹配理论表明，人类更喜欢在不同任务中使用不同类型的结构化知识，例如表格用于统计分析任务，图表用于长链推理

启发LLMs推理采用人类的思维过程，**将零散信息转化为各种结构格式，从而更好地服务于知识密集型的推理任务。**

### 作者提出的解决办法

我们提出了StructRAG，它采用**混合信息结构化机制，根据任务需求以最合适的格式构建和利用结构化知识。**

![结构图](/assets/posts_assets/StructRAG%20Boosting%20Knowledge%20Intensive%20Reasoning%20of%20LLMs%20via%20Inference-time%20Hybrid%20Information%20Structurization%20%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB.assets/%E6%88%AA%E5%B1%8F2024-10-19%2011.20.30.png)

StructRAG框架包括三个模块，旨在顺序识别最合适的结构类型，构建以该格式的结构化知识，并利用该结构化知识来推断最终答案。

- 首先，认识到不同的结构类型适用于不同的任务，提出了混合结构路由器，以根据当前任务的问题和文档信息确定最适当的结构类型。
- 其次，考虑到构建结构化知识是复杂的，并需要强大的理解和生成能力，采用了基于LLM的分散知识结构化程序，将原始文档转换为最佳类型的结构化知识。
- 最后，由于知识密集推理任务中的问题通常是复杂的组合问题，难以直接解决，所以使用了结构化知识利用程序，对问题进行分解，并进行精确知识提取，以便更准确地推断答案。

### 具体的主要工作

混合结构路由器能够准确选择每个输入任务的最适合结构类型

- 为了赋予路由器这种能力，我们提出了一种**混合结构路由器的训练方法**：受到强化学习在训练LLMs进行决策任务方面成功应用的启发，我们采用DPO算法来训练路由器模块，该算法遵循强化学习原则，无需额外的奖励模型。

- 然而，模型学习如何选择最佳结构类型的训练数据不足，而且在现实世界中收集足够的这类数据也具有挑战性。
  - 为了解决这个问题，**我们引入了一种新颖的流程**，用于**构建偏好训练数据**，其中包括任务合成、解决方案模拟和偏好判断，以创建高质量的合成数据，从而增强路由器选择适当结构类型的能力。

### 实验

在我们的实验中，我们评估了StructRAG在各种知识密集型推理任务中的表现，并将其与几个强大的RAG基线进行了比较。结果表明，StructRAG取得了最先进的性能，**在任务复杂性增加时改进更加显著。**

此外，与最近的图形RAG方法相比，StructRAG不仅在更广泛的任务范围内表现出卓越性能，而且平均操作速度也更快。

## 相关工作

> **HotpotQA等多跳任务是什么意思？**

### RAG

RAG技术通过提供外部知识来帮助回答问题并减少幻觉，在LLM时代取得了良好的表现

- RAG的初始策略涉及使用检索器根据查询搜索和保留知识库中高度相关的块，然后将这些块作为外部知识输入到生成模块中，以提高性能
- 为了改善RAG的效果，一些方法引入了迭代RAG，提出了各种增强方法，如查询扩展和重写
- 其他尝试改进检索和生成之间的协作
- 尽管现有方法在HotpotQA等多跳任务上取得了强大的性能，基于块的RAG在知识密集型任务上仍面临困难

### Graph RAG

- 一种方法利用预先构建的知识图，根据查询提取子图，然后将其编码为软提示或压缩成纯文本，用于生成模块。
- 另一种方法涉及根据查询要求从给定文本文档中提取实体关系三元组以构建图结构，然后用于知识增强。
- 尽管这些方法明显改善了多跳问答任务的性能，但它们仅关注基于图的知识通过三元组的格式，因此限制了它们在各种领域和知识密集型推理任务应用中的实际适用性。

## 通过混合信息结构化来构建STRUCTRAG

> 要是不能表示成该结构怎么办？
>
> 感觉就是把原本LLM黑盒中的一些部分拿出来，单独训练，在组合在一起。
>
> 核心内容C是怎么来的

### 任务建模


$$
a = F(q,D),where \ D = \{d^{(i)}\}^m_{i=1}
$$

- 知识密集型推理任务提供了一个问题 q 和一个大量的文档集合 D 作为输入，其目标是根据提供的文档得出答案 a

- m 是文档的数量，可以超过 20，导致总token数达到 200K

- 这些任务最明显的特征是有用信息分散在提供的文档中，要求模型基于大规模相关数据进行复杂推理。

  > 例如，在比较使用一批财务报告的几家公司的发展趋势时，任务需要检索分布在文档中的各种财务指标，然后详细比较这些指标。这涉及考虑不同指标的相对重要性以及数值差异的大小等因素。因此，知识密集型推理任务具有重大挑战。

### Hybird Structure Router

$$
t = R(q,C),where \ C = \{ c^{(i)}\}^m_{i=1} 
$$



**混合结构路由器R来选择最佳的结构类型。**

- 路由器利用问题q和文档D的核心内容C来做出决策并生成最适合的结构类型t，因为一次性处理整个文档集是不现实的。

- C 是来自每个文档 d(i) 的标题或前几句话的集中体现。
- t 有五种候选结构类型，分别适用于五种知识密集型任务：
  - **表格**适用于统计任务
  - **图表**适用于长链任务
  - **算法**适用于规划任务
  - **目录**适用于总结任务
  - 以及**块**适用于简单的单跳任务。
- 考虑到路由器在整体框架中的核心作用，我们的工作设计了一种基于DPO的训练方法，以开发一个在知识类型决策方面表现优异的路由器，详情请参考第4节。

### Scattered Knowledge Structurizer

$$
k^{(i)}_t,b^{(i)}_t=S(q,t,d^{(i)})
$$

**从原始文档中提取分散的文本知识，并将其重构为结构化知识**

StructRAG采用了基于LLM的分散知识结构器

- 结构化器S将问题q、选定的类型t和每个原始文档$d^{(i)}$作为输入，
- 并通过LLM强大的理解和生成能力从文档中提取结构化知识$k^{(i)}_t$。此外，还生成了结构化知识$k^{(i)}_t$的描述$b^{(i)}_t$。
- 然后，所有输出的结构化知识将被收集为整体知识$K_t = \{k^{(i)}_t \}^m_{i=1}$，并且整体结构化知识的描述将被构建为$B_t = \{b^{(i)}_t \}^m_{i=1}$。

结构的形式

- 表格使用markdown语法
- 图表使用头部-关系-尾部三元组列表，
- 块使用普通文本
- 算法使用伪代码
- 目录使用带有层次编号的文本（例如，第一节，1.1，1.1.2）作为明确的章节标识符。

### Structured Knowledge Utilizer

基于LLM的结构化知识利用器来促进问题分解、精确知识提取和最终答案推理
$$
\hat{Q} = U_{decompose}(q, B_t) = \{\hat{q}^{(j)}\}^n_{j=1} \\ 
\hat{K_t} = {U_{extract}(\hat{q}^{(j)}, K_t)}^n_{j=1} = \{\hat{k}^{(j)}_t \}^n_{j=1}  \\
a = U_{infer}(q, \hat{Q}, \hat{K}_t)
$$

- 利用者的分解过程以原始问题q和结构化知识$B_t$的整体描述作为输入，将问题分解为几个简单直观的子问题$\hat{q}^{(j)}$。
- 接下来，提取过程旨在从整个结构化知识$K_t$中为每个子问题$\hat{q}{(j)}$找到精确的知识$\hat{k}^{(j)}_t$。最后，推理过程整合所有子问题及其提取的精确知识，生成最终答案a，
- N 是子问题的数量，$\hat{Q}$是所有子问题的集合，$\hat{K}_t$是所有子问题的完整精确知识，而$U_{decompose}$、$U_{extract}$和$U_{infer}$分别是分解、提取和推理过程。

## 训练混合结构路由器

- 训练方法：鉴于强化学习在决策场景中具有强大的能力，我们使用DPO算法训练路由器，该算法实现了类似于强化学习的结果，同时避免了额外奖励模型的需求。
- 训练数据：由于不存在用于最佳结构类型选择任务的现有偏好数据，我们设计了一种**合成-模拟-判断**方法，以便高效地构建训练的优先对。在以下段落中提供了详细的解释，附录A.1中提供了示例和提示。

### 数据构建

![图片](/assets/posts_assets/StructRAG%20Boosting%20Knowledge%20Intensive%20Reasoning%20of%20LLMs%20via%20Inference-time%20Hybrid%20Information%20Structurization%20%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB.assets/%E5%9B%BE%E7%89%87.png)

1. 给定涵盖可能结构类型的几个手工收集的种子任务
2. 首先使用LLMs通过上下文学习方法合成一组新任务，其中每个任务包含一个问题和文档的核心内容。
3. 然后，对于每个合成任务，LLMs被用来模拟以不同类型的结构知识解决此任务的过程，从而获得不同的模拟解决方案
4. 最后，基于LLM的评委比较这些模拟解决方案来解决任务，生成关于结构类型的偏好对。

结果：每个构建的数据条目包括一个问题，文档的核心内容，选择的结构类型和拒绝的结构类型

$$
D_{synthenic}= \{q^{(k)},C^{(k)},t_w^{(k)},t_l^{k}\}^N_{k=1}
$$

$t_w$和$t_l$分别是选择的结构类型和被拒绝的结构类型。合成偏好对包括英语和中文数据，以提高普适性。

### 偏好训练

这个公式是关于**DPO (Direct Preference Optimization)** 的损失函数，通常用于训练强化学习中的策略模型。该损失函数的目标是使模型更符合用户偏好。


$$
\mathcal{L}_{\text{DPO}}(\pi_\theta; \pi_{\text{ref}}) = -\mathbb{E}_{(q, C, t_w, t_l) \sim D_{\text{synthetic}}} \left[ \log \sigma \left( \beta \log \frac{\pi_\theta(t_w \mid q, C)}{\pi_{\text{ref}}(t_w \mid q, C)} - \beta \log \frac{\pi_\theta(t_l \mid q, C)}{\pi_{\text{ref}}(t_l \mid q, C)} \right) \right]
$$

πθ和πref分别是目标策略和参考策略，β是超参数。

如后分析，这种偏好训练使模型能够区分各种类型的知识以及它们对于特定任务的适用性，从而实现更好的性能，相较于零样本和少样本设置。

## 实验

### 评估数据集

- Loong benchmark
- Pocast Transcripts

### 实现细节

我们基于Qwen2系列模型构建了框架（杨等人，2024a）。

- 对于混合结构路由器，StructRAG使用Qwen2-7B-Instruct作为基础模型，并通过trl2实现DPO训练。

  关于混合结构路由器训练的细节，StructRAG构建并使用了总共900份偏好数据，将学习率设置为1e-5，将训练轮数设置为3，β参数保持默认。

- 对于散乱知识结构化器和结构化知识利用器，StructRAG直接使用Qwen2-72B-Instruct作为基础模型，并使用vllm3将模型部署为API，按照Loong（王等人，2024a）的设置进行

### 实验结果

![图片](/assets/posts_assets/StructRAG%20Boosting%20Knowledge%20Intensive%20Reasoning%20of%20LLMs%20via%20Inference-time%20Hybrid%20Information%20Structurization%20%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB.assets/%E5%9B%BE%E7%89%87-9508638.png)

- StructRAG对于复杂任务尤为合适，性能提升在信息更分散的场景中变得更加重要。
- StructRAG是应对知识密集型推理任务的强大解决方案。

### 消融实验

消融（即逐步移除）模型中的不同模块或组件，来观察模型性能的变化。这样可以帮助他们了解模型中不同部分对最终性能的贡献，并且有助于确定哪些模块对模型性能起到了关键作用

![image-20241021193022347](/assets/posts_assets/StructRAG%20Boosting%20Knowledge%20Intensive%20Reasoning%20of%20LLMs%20via%20Inference-time%20Hybrid%20Information%20Structurization%20%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB.assets/image-20241021193022347.png)

“w/o router”指的是随机路由，“w/o structurizer”意味着仅使用块，“w/o utilizer”是指直接将结构化知识与原始问题连接起来以生成答案。以下是结论：

结论

- 所有三个模块都对整体框架起到积极的作用。
- 选择合适的结构类型并将文件构建为结构化知识比设计复杂的利用方法更为重要。

### 其他细节分析

![image-20241021200255458](/assets/posts_assets/StructRAG%20Boosting%20Knowledge%20Intensive%20Reasoning%20of%20LLMs%20via%20Inference-time%20Hybrid%20Information%20Structurization%20%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB.assets/image-20241021200255458.png)

为了探讨构建数据和进行DPO培训的必要性，以及混合结构路由器的性能与整体StructRAG之间的关系，我们首先将我们的路由器与原始LLMs进行比较，然后绘制路由器的曲线和整体StructRAG分数。得出以下结论：

1. **对于没有接受特殊培训的原始LLMs来说，根据任务选择最佳类型的知识是具有挑战性的。**

   根据表4中的实验结果，基于Qwen2-7B-Instruct模型训练的路由器在少样本设置下明显优于72B模型。这表明，即使模型规模达到72B，LLMs仍需要接受一些特殊培训才能具备根据任务需求选择最佳结构类型的能力。

2. **混合结构路由器的性能与StructRAG最终性能有显著相关性。**如图3所示，我们选择Qwen2-72B-Instruct（零样本）作为弱路由器，并设计了一个完全随机的路由器和一个完全不正确的糟糕路由器。图中的曲线明确显示了路由器准确性与StructRAG框架整体性能之间的正相关关系。这进一步证明，在知识密集型推理任务中，选择与任务需求相匹配的知识类型对于增强至关重要。

#### 固定结构的缺点分析

仅使用一种固定类型的知识无法在多样化的任务上取得良好表现。

![image-20241021195930009](/assets/posts_assets/StructRAG%20Boosting%20Knowledge%20Intensive%20Reasoning%20of%20LLMs%20via%20Inference-time%20Hybrid%20Information%20Structurization%20%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB.assets/image-20241021195930009.png)

#### 几个EM表现不佳的原因

根据表1中的实验结果，StructRAG在总体得分上超过了基准线，但在七种子情况的确切匹配率上表现不佳。

因此，我们分析了一些StructRAG方法得分较高但未能达到精确匹配的情况。

原因主要是关于结构化过程可能会改变原始信息的文本格式。如表5所示，结构化知识和原始信息之间存在一些措辞的差异（例如，从原始“$1,308,463”变为表中的“138463”）。直观上，这符合常识，结构化程序是一种概率语言模型，而不是基于规则的模型，因此可能无法避免一些可能的文本损失，GraphRAG方法的输出也存在类似问题。

### 性能报告

![image-20241021201118603](/assets/posts_assets/StructRAG%20Boosting%20Knowledge%20Intensive%20Reasoning%20of%20LLMs%20via%20Inference-time%20Hybrid%20Information%20Structurization%20%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB.assets/image-20241021201118603.png)

第一部分是构建延迟，指的是为RQ-RAG迭代检索块，为GraphRAG构建图形，并确定最佳知识类型并为StructRAG构建相应结构的过程。

第二部分是阅读延迟，指的是使用增强知识生成最终答案的过程。与RQ-RAG相比，StructRAG的延迟略高，但显然比GraphRAG快。

因此，StructRAG是一种具有可用实现速度的高性能框架。