<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-Hans"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" hreflang="zh-Hans" /><updated>2025-01-09T16:13:26+08:00</updated><id>/feed.xml</id><title type="html">Ennis’s Blog</title><subtitle>Willing to be a question, willing to be an answer.
</subtitle><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><entry><title type="html">Do not think that much for 2+3=? 论文粗读</title><link href="/2025/01/09/Do-not-think-that-much-for-2+3=-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Do not think that much for 2+3=? 论文粗读" /><published>2025-01-09T00:00:00+08:00</published><updated>2025-01-09T00:00:00+08:00</updated><id>/2025/01/09/Do-not-think-that-much-for-2+3=---%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2025/01/09/Do-not-think-that-much-for-2+3=-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="do-not-think-that-much-for-23-论文粗读">Do not think that much for 2+3=? 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs</span>                                                                                        |
| —————————————————————— | ——————————————————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/arXiv.2412.21187)</span></em>                                                                    |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Chen Xingyu,Xu Jiahao,Liang Tian,He Zhiwei,Pang Jianhui,Yu Dian,Song Linfeng,Liu Qiuzhi,Zhou Mengfei,Zhang Zhuosheng,Wang Rui,Tu Zhaopeng,Mi Haitao,Yu Dong</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2024-12-30</span>                                                                                                                                                  |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>O1 在推理的过程中模拟人类长时间思考取得了卓越的表现</p>

    <ul>
      <li>采用扩展的思考链过程，探索多种策略以增强问题解决的能力</li>
      <li>o1类模型存在显著的过度思考问题</li>
      <li><img src="/assets/posts_assets/AKLY9WBP.png" alt="" /></li>
    </ul>
  </li>
  <li>
    <p>问题：如何在测试过程中智能且高效的扩展计算资源？（自主选择何时慢思考）</p>
  </li>
</ul>

<p>*</p>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>对过度思考问题全面研究:</p>

<ul>
  <li>过度思考：为简单问题分配了过多的计算资源，几乎没有收益</li>
</ul>

<p>在数学任务上过度思考的模式：</p>

<ul>
  <li>对提高准确性贡献甚微</li>
  <li>缺乏推理策略的多样性</li>
  <li>在简单问题中过度思考更为频繁出现</li>
</ul>

<p>工作：</p>

<blockquote>
  <p>观点：推理不应该只要求准确性还要求应用合适复杂度。</p>
</blockquote>

<ul>
  <li>从结果和过程的角度引入了新颖的效率指标，以评估 o1 类模型的计算资源合理使用。</li>
</ul>

<h3 id="提出评估指标">提出评估指标</h3>

<h4 id="准确性提升的效率">准确性提升的效率</h4>

\[\xi_O=\frac{1}{N}\sum_{i=1}^{N}\sigma_i\frac{\hat{T}_i}{T_i}\]

<p>$\hat{T_i}$ 是在样本 i 第一次显式的出现答案的 token 数</p>

<p>$\sigma_i$ 是当回答正确时 =1 回答不正确是为 0</p>

<h4 id="多样性思考的效率">多样性思考的效率</h4>

\[\xi_P=\frac{1}{N}\sum_{i=1}^{N}\frac{D_i}{T_i}\]

\[D_i=\sum_{m=1}^M\tau_i^mT_i^m\]

<p>$D_i$是有效类别的 token 数量，$T_i$ 所有的 token 数量</p>

<h4 id="实验结果">实验结果</h4>

<p><img src="/assets/posts_assets/CX9KL7B3.png" alt="" /></p>

<p><img src="/assets/posts_assets/ZIS2VNK7.png" alt="" /></p>

<p>验证了那三种过度思考的模式</p>

<h3 id="缓解过度思考">缓解过度思考</h3>

<p>通过自我训练范式，提出了缓解过度思考的策略，简化推理过程而不影响准确性。</p>

<ul>
  <li>通过去除冗余解决方案来简化生成的响应，同时保持基本的反思性。</li>
</ul>

<h4 id="训练让回答更高效">训练让回答更高效</h4>

<p>造数据方法：自我训练的方法</p>

<p>生成三种数据：</p>

<ul>
  <li>Greedy：next-token选概率最大的</li>
  <li>Shortest：生成十个回答，除去错误的，选择最短的</li>
  <li>Longest：生成十个回答，除去错误的，选择最长的</li>
</ul>

<p>训练方式：</p>

<p>SFT、DPO、RPO、SimPo</p>

<h4 id="训练让回答提到多样性效率">训练让回答提到多样性效率</h4>

<p>策略：截断正确答案后的 解决方案</p>

<ul>
  <li>
    <p>First-Correct Solutions(FCS):只去第一个正确的解决方案，其他的截断</p>

    <ul>
      <li>缺点：让 O1 变回了传统的 LLM，没有利用长程反思的优势</li>
    </ul>
  </li>
  <li>
    <p>FCS + Reflection: 得到一个正确的解决方案后，再保留一个正确的解决方案</p>

    <ul>
      <li>目的是希望在<strong>保持效率</strong>的同时，不完全丧失模型“长程反思”优势</li>
      <li>缺点：第二个也只是用<strong>同一个思路</strong>去验证或重复第一个解法，缺乏“新意”</li>
    </ul>
  </li>
  <li>
    <p>Greedily Diverse Solutions (GDS):贪心地寻找新思路</p>

    <ul>
      <li>如果第二个解法只是重复或核对第一个，则舍弃；</li>
      <li>如果第二个解法确实提供了<strong>新视角</strong>或额外价值，就把它保留。</li>
    </ul>
  </li>
</ul>

<p>每个问题，生成 10 个答案，然后选择最短的结果
<img src="/assets/posts_assets/BJIFZT8L.png" alt="" /></p>

<p><img src="/assets/posts_assets/UTPJ9F5L.png" alt="" /></p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />
<p><img src="/assets/posts_assets/R47YTYPN.png" alt="" /></p>

<ul>
  <li>
    <p>保持模型性能的同时，成功减少了计算开销</p>

    <ul>
      <li>GSM8K、MATH500、GPQA和AIME</li>
    </ul>
  </li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>这些数据集都是定量分析或推理的数据集，O1 类模型是不用其他任务上（除推理之外）吗？其他任务上的过度思考会怎么样？</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[Do not think that much for 2+3=? 论文粗读 💡 Meta Data Title Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs Journal  (10.48550/arXiv.2412.21187) Authors Chen Xingyu,Xu Jiahao,Liang Tian,He Zhiwei,Pang Jianhui,Yu Dian,Song Linfeng,Liu Qiuzhi,Zhou Mengfei,Zhang Zhuosheng,Wang Rui,Tu Zhaopeng,Mi Haitao,Yu Dong Pub.date 2024-12-30]]></summary></entry><entry><title type="html">To CoT or not to CoT? 论文粗读</title><link href="/2025/01/08/To-CoT-or-not-to-CoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB-AUBG95ZE.html" rel="alternate" type="text/html" title="To CoT or not to CoT? 论文粗读" /><published>2025-01-08T00:00:00+08:00</published><updated>2025-01-08T00:00:00+08:00</updated><id>/2025/01/08/To-CoT-or-not-to-CoT---%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB-AUBG95ZE</id><content type="html" xml:base="/2025/01/08/To-CoT-or-not-to-CoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB-AUBG95ZE.html"><![CDATA[<h1 id="to-cot-or-not-to-cot-论文粗读">To CoT or not to CoT? 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning</span>                                                     |
| —————————————————————— | ———————————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/arXiv.2409.12183)</span></em>                                               |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Sprague Zayne,Yin Fangcong,Rodriguez Juan Diego,Jiang Dongwei,Wadhwa Manya,Singhal Prasann,Zhao Xinyu,Ye Xi,Mahowald Kyle,Durrett Greg</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2024-10-29</span>                                                                                                                             |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>COT 这种额外的“思考”对于哪些类型的任务真的有帮助呢？</p>

    <ul>
      <li>CoT 在大量研究中被证明是有效的，但是这些研究中许多都关注的是一部分特定的任务。（比如评估推理仅在数学领域进行评估）</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="工作一">工作一</h3>

<p>工作：</p>

<ul>
  <li>进行了一个定量的元分析，涵盖了110多篇使用CoT的论文，并对14个模型的20个数据集进行了自己的评估。
<img src="/assets/posts_assets/ZN7FD44Y.png" alt="" /></li>
</ul>

<p>去论文中平均后：
<img src="/assets/posts_assets/CJ6GM385.png" alt="" /></p>

<p>符号推理、数学、逻辑推理提升：14.2、12.3、6.9</p>

<p>其他类别使用 CoT 平均表现 56.8，未使用平均表现 56.1</p>

<p>解释分析：为什么 CoT 仅限这些问题上会有提升？</p>

<blockquote>
  <p>观察图中异常值：</p>

  <ul>
    <li>BIG-bench Hard：需要算法、算术或逻辑推理的问题组成的基准</li>
    <li>BIG-bench Navigate是一个空间推理任务，但在得出最终结论时严重依赖于计算步数这一数学基础</li>
    <li>BIG-bench Temporal是一个时间推理任务（回答关于某些事件何时可能发生的问题），但它需要推理能力来解决</li>
    <li>法律论证推理（SemEval-2024 Task 5）（Bongard et al., 2022）被归类为上下文感知的QA，但也需要相当大的推理能力</li>
    <li>MMLU-道德场景（Hendrycks et al., 2021a）需要同时回答两个独立的问题，这本质上涉及到两个更简单问题的符号组合。</li>
  </ul>
</blockquote>

<p>发现1：</p>

<ul>
  <li>
    <p>CoT 仅在需要数学、逻辑或算法推理的问题上显著有帮助。</p>

    <ul>
      <li>
        <p>具体发现 CoT 仅在数据集的数学部分有所益处</p>

        <ul>
          <li>在 MMLU 中 CoT 带来的性能提升中，有多达 95%归因于问题或生成输出中包含“=”的问法</li>
          <li>而非数学问题，我们没有发现任何特征可以知识 CoT 何时会有帮助</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>实验：
<img src="/assets/posts_assets/FKFJ2TBA.png" alt="" /></p>

<p>结果：</p>

<p><img src="assets/posts_assets/4ARKITKU.png" alt="" /></p>

<ul>
  <li>在非符号推理类别：（常识问题、语言理解和阅读理解）zero-shot CoT 和 zero-shot 直接回答性能几乎没有区别。</li>
  <li>在数学和符号类别改进获得了很大提升</li>
  <li>ContextHub 和 MuSR 谋杀谜题这样半符号数据集显示出一定的增益。</li>
  <li>增加样本也影响甚微（在 CoT 有帮助时）</li>
</ul>

<blockquote>
  <p>“半符号推理”可以理解为介于纯符号推理与非符号推理之间的一种推理方式。在纯符号推理中，我们通常可以把问题映射到一个被广泛认可并使用的形式系统（比如一阶逻辑或数学表达），然后用已有的符号求解器来直接计算答案。而在非符号推理中，问题往往依赖于常识、情境理解或经验判断，缺乏一个公认的形式系统来表达和解决问题。</p>

  <p>“半符号推理”则结合了这两种思路：</p>

  <ol>
    <li><strong>部分地依赖某个已有的形式系统</strong>：在问题里可能存在某些可以形式化的规则、逻辑或推理准则（比如“有动机、有作案手段、有作案机会就意味着是凶手”），这些可以用符号的形式表达并交给求解器处理。</li>
    <li><strong>仍然需要常识或经验性的推理</strong>：问题中往往存在无法被完全形式化的部分，需要通过语言模型或人类常识来补充额外信息或进行解释。例如，在谋杀案场景中，区分角色之间复杂的社会关系、有时候需要联想到常见的社会行为或动机，超出了简单逻辑公式所能直接处理的范围。</li>
  </ol>

  <p>因此，在半符号推理中，我们既需要能把可形式化的部分映射到符号表达中去，同时又要结合常识理解和更高层次的推理，以最终得到问题的答案。</p>
</blockquote>

<h3 id="工作二">工作二</h3>

<ul>
  <li>
    <p>数学和形式逻辑推理数据集可以分为两个处理阶段：</p>

    <ul>
      <li>一个规划步骤（例：将一个问题解析为方程）</li>
      <li>一个执行步骤（生成中间输出并向解决方案逼近）</li>
    </ul>
  </li>
</ul>

<p>CoT 主要帮助执行经计算和符号操作的执行步骤。</p>

<p>工作：</p>

<ul>
  <li>将规划与执行分开并与工具增强的 LLMs 进行比较，分析了 CoT 在这些问题上的表现。
<img src="/assets/posts_assets/869QNSNA.png" alt="" /></li>
</ul>

<p>发现2：</p>

<ul>
  <li>
    <p>CoT 主要帮助执行计算和符号操作的步骤，但未能达到工具增强的 LLMs 的性能。</p>

    <ul>
      <li>使用 CoT 提示的LLM 能够生成可执行的解决计划，并比直接回答更好执行计划。</li>
      <li>使用 LLM 生成解决计划，然后用工具求解，在两个阶段、所有任务中均优于使用 CoT</li>
    </ul>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>发现：</p>

<ul>
  <li>
    <p>CoT 在涉及数学或逻辑的任务上表现出显著的性能提升，而在其他类型的任务上提升则小得多</p>

    <ul>
      <li>在 MMLU 上直接生成答案而不用 CoT 的准确率与使用 CoT 时相同，除非问题和模型包含符号运算和推理。</li>
    </ul>
  </li>
  <li>
    <p>CoT 的大部分收益来自于符号执行，但是相对于使用工具求解，表现并不好</p>
  </li>
</ul>

<p>结论：</p>

<ul>
  <li>
    <ul>
      <li>CoT 在许多任务重是不必要的，CoT可以有选择的应用，保持性能的同时节省推理成本。</li>
      <li>CoT</li>
      <li>需要用超越基于prompt 的 CoT，探索新范式（比如搜索、交互 agent、更多微调来学习 CoT），以更好地利用整个大模型应用范围内的中间计算。</li>
    </ul>
  </li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[To CoT or not to CoT? 论文粗读 💡 Meta Data Title To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning Journal  (10.48550/arXiv.2409.12183) Authors Sprague Zayne,Yin Fangcong,Rodriguez Juan Diego,Jiang Dongwei,Wadhwa Manya,Singhal Prasann,Zhao Xinyu,Ye Xi,Mahowald Kyle,Durrett Greg Pub.date 2024-10-29]]></summary></entry><entry><title type="html">AnyTool-论文粗读</title><link href="/2025/01/07/AnyTool-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="AnyTool-论文粗读" /><published>2025-01-07T00:00:00+08:00</published><updated>2025-01-07T00:00:00+08:00</updated><id>/2025/01/07/AnyTool--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2025/01/07/AnyTool-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="anytool-论文粗读">AnyTool 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls</span>                            |
| —————————————————————— | ———————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/arXiv.2402.04253 ICML 2024)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Du Yu,Wei Fangyun,Zhang Hongyang</span>                                                                   |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2024-02-06</span>                                                                                         |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<ul>
  <li>如何驱动 LLM 有效的使用工具</li>
  <li>提供一种使用大量工具解决用户查询的方式</li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了AnyTool</p>

<blockquote>
  <p>Anytool 采用GPT-4 API 无需训练外部模块</p>
</blockquote>

<ul>
  <li>
    <p>一个具有层次结构API 检索器（用 GPT-4无需训练）</p>

    <ul>
      <li>由三个层组成，每个层包含一个或多个具有不同角色的 agent，克服了LLMs 中最大上下文长度的限制</li>
      <li><img src="/assets/posts_assets/MKPY75CK.png" alt="" /></li>
      <li>首先 meta agent 根据 rapidapi 类和 query 动态给出类别代理</li>
      <li>然后类别代理从工具集中识别工具，创建工具代理</li>
      <li>最后工具代理选择 API添加到 API 候选池中（工具代理不只管理一个工具）</li>
    </ul>
  </li>
  <li>
    <p>使用选定 api 候选者解决用户查询的求解器(Tool LLaMA / GPT-4)</p>

    <ul>
      <li>有两种输出：给出解决方案和放弃</li>
      <li>当放弃时 要给出不相关 API 的原因和名称
*</li>
    </ul>
  </li>
  <li>
    <p>自我反思机制</p>

    <ul>
      <li>
        <p>如果初始解决方案被证明不可行，则重新激活 AnyTool</p>
      </li>
      <li>
        <p>两种情况会被激活：</p>

        <ul>
          <li>给出解决方案，但是 GPT4 评判未解决（由 GPT-4 给出理由）</li>
          <li>求解器给出放弃的结果（由求解器给出理由）</li>
        </ul>
      </li>
      <li>
        <p>然后将理由添加在API 检索器中刚刚激活的代理的上下文中（从下到上），这个过程会重新扩展 API 候选池</p>
      </li>
      <li>
        <p>优点：显著减少了对简单查询的“过渡搜索“的倾向，同时为复杂查询提供了更丰富的上下文和更深入的搜索。</p>
      </li>
      <li>
        <p><img src="/assets/posts_assets/QLYGWVIZ.png" alt="" /></p>
      </li>
    </ul>
  </li>
</ul>

<p>提出修订的评估办法：AnyToolBench</p>

<ul>
  <li>原本：\(R=\frac{\#(\text{Non-solvable})+\#(\mathrm{Solved})}{\#(\text{Non-solvable})+\#(\mathrm{Solved})+\#(\mathrm{Unsolved})}.\)修改后：</li>
</ul>

\[R=\frac{\#(\mathrm{Solved})}{\#(\mathrm{Solved})+\#(\mathrm{Unsolved})}.\]

<ul>
  <li>解决了在不可解决的 query 算通过率，导致了人为的提高通过率的问题，能更好的反应实际应用场景的</li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>在多个数据集上实验表明，AnyTool 的比ToolLLM、GPT-4要好</p>

<ul>
  <li>在 ToolBench 上，AnyTool 的平均通过率比 ToolLLM 高 35.4%</li>
</ul>

<p><img src="/assets/posts_assets/NT2I6J24.png" alt="" /></p>

<ul>
  <li>在 AnyToolBench 上
<img src="/assets/posts_assets/TAR35YZJ.png" alt="" /></li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>消融实验非常的完善</li>
  <li>将自我反思作用在Retriever 上，通过添加 agent 的上下文来实现是一种有效的自我反思方法。</li>
  <li>自我反思关键是要能把已有的错误修正。</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[AnyTool 论文粗读 💡 Meta Data Title AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls Journal  (10.48550/arXiv.2402.04253 ICML 2024) Authors Du Yu,Wei Fangyun,Zhang Hongyang Pub.date 2024-02-06]]></summary></entry><entry><title type="html">Towards-Autonomous-Tool-Utilization-论文粗读</title><link href="/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Towards-Autonomous-Tool-Utilization-论文粗读" /><published>2024-12-30T00:00:00+08:00</published><updated>2024-12-30T00:00:00+08:00</updated><id>/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="towards-autonomous-tool-utilization论文粗读">Towards Autonomous Tool Utilization论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Towards Autonomous Tool Utilization in Language Models: A Unified, Efficient and Scalable Framework</span> |
| —————————————————————— | ————————————————————————————————————————————————————- |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(LREC-COLING)</span></em>                          |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Li Zhi,Li Yicheng,Ye Hequan,Zhang Yin</span>                                                               |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> |                                                                                                                                                               |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>为了实现完全自主的工具使用问题：</p>

    <ul>
      <li>仅凭一个查询语言模型能够自主决定是否使用工具，选择那个特定的工具，以及如何使用这些工具，</li>
      <li>并且所有这一切都不需要在上下文中提供任何特定工具的提示</li>
    </ul>
  </li>
  <li>
    <p>研究现状</p>

    <ul>
      <li>
        <p>ToolLLM选择工具需要额外的检索步骤</p>

        <ul>
          <li>
            <p>缺点：</p>

            <ul>
              <li>会导致累积错误，</li>
              <li>缺乏端到端的优化</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>在上下文中提供与特定场景相关的多种工具</p>

        <ul>
          <li>缺点：有限的上下文使得拓展工具变得困难</li>
        </ul>
      </li>
      <li>
        <p>Toolformer 和 TRICE 关注的问题与本文类似</p>

        <ul>
          <li>缺点：采用自监督数据集构建效率低下，考察工具类型有限</li>
          <li>缺乏对可扩展性的讨论和分析</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>思路：期望大模型能够通过充分的内化各种的工具知识，实现完全自主的工具使用。</p>

<p>为了实现这个目标：引入了一种统一、高效且可扩展的语言模型微调框架</p>

<ul>
  <li>
    <p>根据工具依赖程度，将初始query分为三种不同类型</p>

    <ul>
      <li>
        <p>可直接解决的问题</p>
      </li>
      <li>
        <p>需要验证的问题</p>

        <ul>
          <li>LLM 一定程度上能解决但是容易产生幻觉（复杂的数学计算）</li>
        </ul>
      </li>
      <li>
        <p>由于固有限制而无法解决的问题（实时查询）</p>
      </li>
      <li>
        <p>最后通过将统一建模为序列决策问题来解决</p>

        <ul>
          <li>$\begin{aligned}P(\mathrm{Y,W_e,W_i,H\mid X})&amp;=P(\mathrm{W_{e}}\mid\mathrm{X})&amp;\times P(\mathrm{W_{i}\mid W_{e},X})&amp;\times P(\mathrm{H}\mid\mathrm{W_{e}},\mathrm{W_{i}},\mathrm{X})&amp;\times P(\mathrm{Y}\mid\mathrm{H},\mathrm{W}<em>\mathrm{e},\mathrm{W}</em>\mathrm{i},\mathrm{X})\end{aligned}$
*</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>构建数据集的方法：</p>

    <ul>
      <li>
        <p>“指导、执行、重新格式化“的高效数据集构建策略</p>

        <ul>
          <li>以基础种子查询为起点，通过自我指导来增强这些查询</li>
          <li>用 LLM 参考查询、工具指令来制定 API 调用</li>
          <li>如果 API 调用成功，专门的团队会评估数据示例</li>
          <li>最后重组数据,将工具指令从输入角色转换为输出角色</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/posts_assets/892LKX85.png" alt="" /></p>
<ul>
  <li>
    <p>持续学习：动态平衡重演策略</p>

    <ul>
      <li>从关注新的 API 类别开始，逐渐增加旧 API 类别的比例直到实现平衡（防止忘记旧的 API 调用的知识）</li>
      <li>结果：只需最少的新工具标注数据即可展现出卓越的性能，同时保持现有的工具能力</li>
    </ul>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />
<p><img src="/assets/posts_assets/7396C33A.png" alt="" /></p>

<ul>
  <li>通过对包含26种多样化API的注释数据集进行端到端训练，该模型表现出一定的自我意识，在必要时会自动寻求工具的帮助。</li>
  <li>它在多个评估指标上显著超越了原始指令调优的开源语言模型和GPT-3.5/4。</li>
  <li>消融实验：我们的统一框架可以有效促进模型在不同工具之间学习。</li>
  <li>持续学习只需要最少的新标注即可展现出卓越的性能</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>本文的创新点：就是一个概率分解，然后端到端的训练</li>
  <li>概率分解真的有用吗？最后不还是 nexttoken 微调吗？</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[Towards Autonomous Tool Utilization论文粗读 💡 Meta Data Title Towards Autonomous Tool Utilization in Language Models: A Unified, Efficient and Scalable Framework Journal  (LREC-COLING) Authors Li Zhi,Li Yicheng,Ye Hequan,Zhang Yin Pub.date  ]]></summary></entry><entry><title type="html">Why Can GPT ICL 论文粗读</title><link href="/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Why Can GPT ICL 论文粗读" /><published>2024-12-23T00:00:00+08:00</published><updated>2024-12-23T00:00:00+08:00</updated><id>/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="why-can-gpt-icl-论文粗读">Why Can GPT ICL 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers</span> |
| —————————————————————— | ————————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(acl 2023)</span></em>                              |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Dai Damai,Sun Yutao,Dong Li,Hao Yaru,Ma Shuming,Sui Zhifang,Wei Furu</span>                                 |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> |                                                                                                                                                                |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>LLM 涌现了few-shot In-Context learning的能力</p>

    <ul>
      <li>通过少量示例可以预测训练的时候没有遇到的输入</li>
    </ul>
  </li>
  <li>
    <p>但是ICL能力的机制还是个开放问题</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>有人已经研究了发现：线性层的梯度下降和线性注意力形式上是类似的</p>

<h3 id="工作一解释icl">工作一：解释ICL</h3>

<p>transformer attention和梯度下降的形式非常类似，所以将语言模型解释为“元优化器”，将上下文学习理解为隐式微调：</p>

<p>公式推导：</p>

<p>q是当前推理到的token，X是前面不是示例的token，X‘是前面示例的token, $W_{ZSL}q$ 是 zero-shot下 q 的 attention 结果</p>

<ol>
  <li>初始公式</li>
</ol>

\[\begin{aligned}\mathcal{F}_{\mathrm{ICL}}(\mathbf{q})&amp;=\mathrm{Attn}(V,K,\mathbf{q})\\&amp;=W_V[X^{\prime};X]\operatorname{softmax}\left(\frac{(W_K[X^{\prime};X])^T\mathbf{q}}{\sqrt{d}}\right),\end{aligned}\]

<p>2. 简化，线性化</p>

\[\begin{aligned}\mathcal{F}_{\mathrm{ICL}}(\mathbf{q})&amp;\approx W_V[X^{\prime};X]\left(W_K[X^{\prime};X]\right)^T\mathbf{q}\\&amp;=W_VX\left(W_KX\right)^T\mathbf{q}+W_VX^{\prime}\left(W_KX^{\prime}\right)^T\mathbf{q}\\&amp;\equiv\widetilde{\mathcal{F}}_{\mathrm{ICL}}(\mathbf{q}).\end{aligned}\]

<p>3. 转换简化后的式子</p>

\[\begin{aligned}\widetilde{\mathcal{F}}_{\mathrm{ICL}}(&amp;(\mathbf{q})=W_\mathrm{ZSL}{\mathbf{q}}+W_VX^{\prime}\left(W_KX^{\prime}\right)^T\mathbf{q}\\&amp;=W_\mathrm{ZSL}\mathbf{q}+\text{LinearAttn}\left(W_VX^{\prime},W_KX^{\prime},\mathbf{q}\right)\\&amp;=W_{\mathrm{ZSL}}\mathbf{q}+\sum_iW_V\mathbf{x}_i^{\prime}\left(\left(W_K\mathbf{x}_i^{\prime}\right)^T\mathbf{q}\right)\\&amp;=W_{\mathrm{ZSL}}\mathbf{q}+\sum_i\left((W_V\mathbf{x}_i^{\prime})\otimes(W_K\mathbf{x}_i^{\prime})\right)\mathbf{q}\\&amp;=W_\mathrm{ZSL}{\mathbf{q}}+\Delta W_\mathrm{ICL}{\mathbf{q}}\\&amp;=\left(W_{\mathrm{ZSL}}+\Delta W_{\mathrm{ICL}}\right)\mathbf{q}.\end{aligned}\]

<p>所以ICL理解如下：</p>

<ul>
  <li>预训练的GPT充当元优化器</li>
  <li>通过前向计算根据示范示例产生元梯度</li>
  <li>然后通过注意力将这些元梯度应用于原始GPT，以构建ICL模型</li>
</ul>

<p>ICL 与 fine-tuning 的关系 :</p>

<ul>
  <li>ICL 通过前向计算产生元梯度</li>
  <li>微调通过反向传播计算梯度
<img src="/assets/posts_assets/7BNKYIFK.png" alt="" /></li>
</ul>

<h3 id="工作二提出一种新的注意力机制">工作二：提出一种新的注意力机制</h3>

<p>受到 fine-tuning 和 ICL 的相似性的启发，通过与基于动量的梯度下降类比设计了一种基于动量的注意力，比基础的注意力提升了性能。
<img src="/assets/posts_assets/LB8NYI98.png" alt="" /></p>

<p>基于动量的梯度下降公式：</p>

\[\Theta_t = \Theta_{t-1} - \gamma \sum_{i=1}^{t-1} \eta^{t-i} \nabla f_{\Theta_i}\]

<ul>
  <li>参数更新时不仅考虑当前的梯度，还结合了过去多个时间步的梯度信息</li>
</ul>

<p>基于动量的注意力机制公式：</p>

\[\begin{aligned}\mathrm{MoAttn}(V,K,\mathbf{q}_t)&amp;=\mathrm{Attn}(V,K,\mathbf{q}_t)+\mathrm{EMA}(V)\\&amp;=V\mathrm{softmax}(\frac{K^{T}\mathbf{q}_{t}}{\sqrt{d}})+\sum_{i=1}^{t-1}\eta^{t-i}\mathbf{v}_{i},\end{aligned}\]

<ul>
  <li>
    <p>$v_i$是第 i 个位置token 的 value 向量</p>
  </li>
  <li>
    <p>注意力v向量的动量明确增强了注意力的近期偏差，这已被证明对语言建模有帮助</p>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<h3 id="icl-行为与显式微调相似">ICL 行为与显式微调相似</h3>

<p>在六个分类任务中，比较ICL和微调的模型预测、注意力输出、对query token的注意力权重</p>

<p>实验结果验证了ICL和微调的行为在多个方面相似</p>

<ul>
  <li>ICL 的结果包含了大多数 fine-tuning 预测正确的结果</li>
  <li>ICL 和 fine-tuning 修改 attention 输出的方向相同</li>
  <li>ICL 和 fine-tuning 倾向于生成相同的 attention 权重</li>
  <li>ICL 和 fine-tuning 对于训练的 token 的注意力相似</li>
</ul>

<h3 id="基于动量的注意力机制有效">基于动量的注意力机制有效</h3>

<ul>
  <li>
    <p>困惑度降低<img src="/assets/posts_assets/AZD4IVSR.png" alt="" /></p>
  </li>
  <li>
    <p>ICL 性能提升<img src="/assets/posts_assets/CTC7IUS4.png" alt="" /></p>
  </li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>没有解释为什么ICL不如fine-tuning</p>
  </li>
  <li>
    <p>也没有解释一些ICL现象，</p>

    <ul>
      <li>比如示例中标签不正确的影响不大的现象</li>
      <li>为什么demostration 的顺序会影响ICL 的性能</li>
    </ul>
  </li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[Why Can GPT ICL 论文粗读 💡 Meta Data Title Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers Journal  (acl 2023) Authors Dai Damai,Sun Yutao,Dong Li,Hao Yaru,Ma Shuming,Sui Zhifang,Wei Furu Pub.date  ]]></summary></entry><entry><title type="html">TooL LLM 论文粗读</title><link href="/2024/12/18/TooL-LLM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="TooL LLM 论文粗读" /><published>2024-12-18T00:00:00+08:00</published><updated>2024-12-18T00:00:00+08:00</updated><id>/2024/12/18/%3CTooL%20LLM%3E%20%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/18/TooL-LLM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="tool-llm-论文粗读">&lt;TooL LLM&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</span>                                                                                                                                  |
| —————————————————————— | ———————————————————————————————————————————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/arXiv.2307.16789)</span></em>                                                                                                                      |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Qin Yujia,Liang Shihao,Ye Yining,Zhu Kunlun,Yan Lan,Lu Yaxi,Lin Yankai,Cong Xin,Tang Xiangru,Qian Bill,Zhao Sihan,Hong Lauren,Tian Runchu,Xie Ruobing,Zhou Jie,Gerstein Mark,Li Dahai,Liu Zhiyuan,Sun Maosong</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023-10-03</span>                                                                                                                                                                                                    |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>开源模型使用工具的能力还非常弱：</p>

    <ul>
      <li>因为instruct-tuning 主要集中在基本语言任务上，而忽略了工具使用</li>
      <li>与闭源的LLM有很大差距</li>
    </ul>
  </li>
  <li>
    <p>当前研究：有人探讨了为工具使用指令调优数据，但他们未能充分激发大语言模型的工具使用能力，并具有固有的局限性</p>

    <ul>
      <li>有限的API</li>
      <li>受限的场景</li>
      <li>低效的推理和规划</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>为了弥补差距，提出了ToolLLM，一个一般工具使用框架：包含数据构建、模型训练和评估。</p>

<h3 id="数据构建">数据构建</h3>

<p>提出了ToolBench，一个用于工具使用的指令微调数据集，是使用chatgpt自动构建的</p>

<p>构建可以分为三个阶段</p>

<ol>
  <li>
    <p>API集合：RapidAPI Hub中16464个真实世界的的RESTful API涵盖49个类别</p>
  </li>
  <li>
    <p>指令生成：提示Chatgpt生成涉及这些API的多样化指令，涵盖单工具和多工具场景</p>

    <ul>
      <li>
        <p>抽样不用的API组合，然后制定涉及他们的各种指令</p>

        <ul>
          <li>抽样方法：随机从统一类别中选择2-5个工具，从每个工具抽样3个API</li>
        </ul>
      </li>
      <li>
        <p>ICL+prompt 实现让gpt生成instruction</p>
      </li>
      <li>
        <p>然后用这些（instruction，relevant API）训练一个API retriever</p>
      </li>
    </ul>
  </li>
  <li>
    <p>解决路径注释：使用ChatGPT为每个instruction搜索有效的解决路径（API调用链）</p>

    <ul>
      <li>
        <p>解决路径：包含模型包含多个LLM推理轮次和实时API调用</p>
      </li>
      <li>
        <p>问题：但是GPT-4对复杂的指令通过率很低，这使得注释效率很低，CoT 和 ReACT 也不行</p>

        <ul>
          <li>错误积累</li>
          <li>探索有限（仅探索一个路径）</li>
        </ul>
      </li>
      <li>
        <p>解决：开发了一种新颖的基于深度优先搜索的决策树算法来增强LLM的规划和推理能力，它使LLM能评估多个推理轨迹，做出深思熟虑的决策（选择撤回或者继续走）</p>
      </li>
      <li>
        <p>结果：显著提高了注释效率，并完成了使用ReACT无法实现的复杂指令训<img src="/assets/posts_assets/45QMKDXT.png" alt="" /></p>
      </li>
    </ul>
  </li>
</ol>

<h3 id="评估">评估</h3>

<p>开发了一个自动评估器 ToolEval，包含两个指标</p>

<ol>
  <li>
    <p>通过率：衡量LLM在有限资源内成功执行指令的能力</p>
  </li>
  <li>
    <p>获胜率：比较两种解决方案的质量和有用性</p>

    <ul>
      <li>做法：向GPT提供一个指令和两个解决路径，获得偏好</li>
    </ul>
  </li>
</ol>

<p>通过这两点，构建ChatGPT的prompt</p>

<p>为什么要有ToolEval？</p>

<ol>
  <li>API不断变化的</li>
  <li>指令存在无线潜在解决路径</li>
  <li>为每个测试指令标注一个固定的真实解决路径是不可行的</li>
</ol>

<p>结果：发现ToolEval与人工标注者的通过率有87.1%的一致性而获胜率有80.3%</p>

<p>表明ToolEval很大程度上能够反映和代表人类评估。</p>

<h3 id="模型训练">模型训练</h3>

<p>基于ToolBench对LLaMA进行微调，得到ToolLLaMA，并为其配备了神经网络API检索器，以推荐适合每个指令的API</p>

<h4 id="api-retriever训练">API Retriever训练</h4>

<p>使用Sentence-BERT</p>

<ul>
  <li>API检索器将指令和API文档分别编码为两个向量嵌入，然后通过计算嵌入相似度来评估相关性，</li>
  <li>指令相关的API作为正例，并从其他API中随机抽取一些作为负例进行对比学习</li>
</ul>

<p><img src="/assets/posts_assets/M3KNXVCX.png" alt="" /></p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>性能好：ToolLLaMA展现出执行复杂指令和推广至未见 API 的卓越能力，并且其表现与 ChatGPT 相当</li>
  <li>泛化能力好：ToolLLaMA 在一个超出分布的工具使用数据集 APIBench 中也表现出强大的零-shot 泛化能力。</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;TooL LLM&gt; 论文粗读 💡 Meta Data Title ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs Journal  (10.48550/arXiv.2307.16789) Authors Qin Yujia,Liang Shihao,Ye Yining,Zhu Kunlun,Yan Lan,Lu Yaxi,Lin Yankai,Cong Xin,Tang Xiangru,Qian Bill,Zhao Sihan,Hong Lauren,Tian Runchu,Xie Ruobing,Zhou Jie,Gerstein Mark,Li Dahai,Liu Zhiyuan,Sun Maosong Pub.date 2023-10-03]]></summary></entry><entry><title type="html">Toolformer 论文粗读</title><link href="/2024/12/17/Toolformer-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Toolformer 论文粗读" /><published>2024-12-17T00:00:00+08:00</published><updated>2024-12-17T00:00:00+08:00</updated><id>/2024/12/17/%3CToolformer%3E%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/17/Toolformer-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="toolformer-论文粗读">&lt;Toolformer&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Toolformer: Language Models Can Teach Themselves to Use Tools</span>                                                           |
| —————————————————————— | ——————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/ARXIV.2302.04761)</span></em>                                |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Schick Timo,Dwivedi-Yu Jane,Dessì Roberto,Raileanu Roberta,Lomeli Maria,Zettlemoyer Luke,Cancedda Nicola,Scialom Thomas</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                                                    |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>LLM的对于一些任务上有卓越的能力，但是基本功能方面却存在困难，例如算数或事实查找。</p>

    <ul>
      <li>这些领域是小模型的强项</li>
    </ul>
  </li>
  <li>
    <p>当前的研究：要么依赖大量的人类标注数据、要么仅限于特定任务的工具使用，阻碍了工具在语言模型中的广泛采用。</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="思路">思路</h3>

<ul>
  <li>
    <p>让LLM通过简单的API自我学习使用外部工具。</p>
  </li>
  <li>
    <p>提出了Toolformer，实现以下愿望：</p>

    <ul>
      <li>
        <p>自监督学习工具，不用人类标注数据</p>

        <ul>
          <li>
            <p>原因：</p>

            <ul>
              <li>人类标注成本高</li>
              <li>人类觉得有用的不一定是LLM觉得有用的</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>LM 不能失去其泛化能力，不局限于特定任务</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="方法">方法</h3>

<p>利用In-context learning，从零开始生成数据集</p>

<ol>
  <li>首先仅通过少量人类编写的API使用示例，让语言模型为一个庞大的语言建模数据集标注潜在的API调用</li>
  <li>然后使用自监督损失（self-supervised loss）来确定哪些API调用实际上有助于模型预测未来的token</li>
  <li>最后微调模型</li>
</ol>

<p>具体：</p>

<p><img src="/assets/posts_assets/Pasted%20image%2020241218101428.png" alt="" /></p>

<ol>
  <li>
    <p><strong>给定一个普通文本的数据集，然后转化成带有API调用的数据集</strong></p>

    <ol>
      <li>
        <p>编写prompt，利用In-context-learning 采样大量潜在的API调用（生成多个API调用）</p>

        <ul>
          <li>先找到序列中哪个位置调用API（设定一个阈值，如果生成&lt;API&gt;概率大于阈值则保留该位置）</li>
          <li>然后选定API：选定位置后，继续生成，然后进行采样多个API候补</li>
        </ul>
      </li>
      <li>
        <p>然后执行API调用（每个API的返回是文本序列）</p>
      </li>
    </ol>
  </li>
  <li>
    <p><strong>然后检查获得的相应是否有助于未来的token，来筛选</strong></p>

    <ol>
      <li>具体就是比较加入API调用后，生成后序序列的概率和不加API调用的概率哪个大（要大过设定的阈值），如果加入API后大超过阈值那就是有帮助，则保留</li>
    </ol>
  </li>
  <li>
    <p><strong>经过筛选得到了增强的数据集，然后进行微调</strong></p>
  </li>
</ol>

<blockquote>
  <p>生成过程中如果生成到了spacial token了就中断生成过程，获得API响应后，插入响应和&lt;/API&gt; token后继续解码过程</p>
</blockquote>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>Toolformer 显著提高了zero-shot性能</li>
  <li>语言建模能力也没有牺牲</li>
</ul>

<p><img src="/assets/posts_assets/BVWDZZY3.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<p>缺点：</p>

<ul>
  <li>无法与搜索引擎交互，只能用他给出的结果，无法重构查询等，然后就没有修补办法。</li>
</ul>

<p>收获：</p>

<ul>
  <li>微调以后再禁用API测试，确实是一个检测微调后有没有损失模型性能的好办法</li>
  <li>微调过程中仅对工具选择算loss感觉挺有用
*</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;Toolformer&gt; 论文粗读 💡 Meta Data Title Toolformer: Language Models Can Teach Themselves to Use Tools Journal  (10.48550/ARXIV.2302.04761) Authors Schick Timo,Dwivedi-Yu Jane,Dessì Roberto,Raileanu Roberta,Lomeli Maria,Zettlemoyer Luke,Cancedda Nicola,Scialom Thomas Pub.date 2023]]></summary></entry><entry><title type="html">TALM 论文粗读</title><link href="/2024/12/17/TALM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="TALM 论文粗读" /><published>2024-12-17T00:00:00+08:00</published><updated>2024-12-17T00:00:00+08:00</updated><id>/2024/12/17/TALM--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/17/TALM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="talm-论文粗读">&lt;TALM&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">TALM: Tool Augmented Language Models</span>                                                     |
| —————————————————————— | ————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/ARXIV.2205.12255)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Parisi Aaron,Zhao Yao,Fiedel Noah</span>                                                        |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2022</span>                                                                                     |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>LLM 需要工具：LLM 不能使模型解决需要访问训练时不可用短暂、变化或私人数据的任务，许多任务用API更好解决</li>
  <li>最近研究将LLM连接到一个环境（仅是作为query的接受者）</li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了工具增强语言模型（TALM），使用模型生成的输出调用任意工具，并关注工具输出以生成任务输出</p>

<p>贡献：</p>

<ul>
  <li>仅使用text-to-text 的API 来增强语言模型</li>
  <li>提出自我博弈（self-play）技术，提高了在few-shot的启动性能</li>
</ul>

<h3 id="talm模型">TALM模型</h3>

<p><img src="/assets/posts_assets/LMBWTV2M.png" alt="" /></p>

<ol>
  <li>
    <table>
      <tbody>
        <tr>
          <td>TALM 首先生成一个基于任务输入文本的工具输入，并通过生成分隔符，例如“</td>
          <td>result”，调用工具的 API。</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>每当检测到这个分隔符时，就会调用工具 API，并将其结果附加到文本序列中。</p>
  </li>
  <li>然后，TALM 继续生成最终的任务输出。<img src="assets/posts_assets/VQ5T6NKX.png" alt="" /></li>
</ol>

<p>TALM 同时学习两个子任务：调用工具和基于工具结果生成答案。</p>

<p>TALM 在架构上用了Seq2Seq模型</p>

<h3 id="迭代iterative-self-play">迭代Iterative self-play</h3>

<ol>
  <li>首先有示例数据集，然后微调这个数据集，再在新数据集（无工具示例）生成工具调用的过程。</li>
  <li>然后看最终结果怎么样，如果大于阈值就添加到原本的数据集中</li>
</ol>

<blockquote>
  <p>这个过程虽然本文是单步的（使用单个工具的），但是很容易建模成多步的，用类似马尔科夫链建模</p>
</blockquote>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>一个知识密集型问答任务（NQ）和一个使用简单工具的推理导向数学任务（MathQA）上表现出色。</li>
  <li>TALM 成功地在问答和数学任务上进行分布外推理，而未增强的语言模型则失败。</li>
  <li>小模型从工具中收益更多（知识密集的任务）</li>
</ul>

<p><img src="assets/posts_assets/K39LZNDR.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />需要再搞清楚seq2seq模型和decoder-only模型的本质区别是什么  [created:: 2024-12-17]  [due:: 2024-12-17]</li>
  <li class="task-list-item">这些论文学习工具的过程感觉都是 少样本-&gt;自己增强（标准不一样）-&gt;然后再微调自己</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;TALM&gt; 论文粗读 💡 Meta Data Title TALM: Tool Augmented Language Models Journal  (10.48550/ARXIV.2205.12255) Authors Parisi Aaron,Zhao Yao,Fiedel Noah Pub.date 2022]]></summary></entry><entry><title type="html">Self-Planning Code Generation with Large Language Models 论文粗读</title><link href="/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Self-Planning Code Generation with Large Language Models 论文粗读" /><published>2024-12-16T00:00:00+08:00</published><updated>2024-12-16T00:00:00+08:00</updated><id>/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="self-planning-code-generation-with-large-language-models-论文粗读">&lt;Self-Planning Code Generation with Large Language Models&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Self-Planning Code Generation with Large Language Models</span>                                                                               |
| —————————————————————— | ———————————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)">ACM Transactions on Software Engineering and Methodology </span><em><span style="background-color: rgb(243, 250, 244)">(10.1145/3672456)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Jiang Xue,Dong Yihong,Wang Lecheng,Fang Zheng,Shang Qiwei,Li Ge,Jin Zhi,Jiao Wenpin</span>                                                    |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023-06-30</span>                                                                                                                             |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<p>问题：</p>

<ul>
  <li>
    <p>LLM代码生成无法应对有复杂意图的任务</p>

    <ul>
      <li>解决方法：需要采用规划来分解复杂问题，并在实施之前安排解决方案步骤</li>
    </ul>
  </li>
  <li>
    <p>生成CoT的过程和生成代码的过程本质是相似的，直接将CoT应用于代码并不能减少难度</p>

    <ul>
      <li>解决方法：要专注实现问题的分解</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>思路：将规划引入到了代码生成中，以帮助模型理解复杂意图并降低问题解决难度</p>

<p><img src="/assets/posts_assets/QACCGZ7E.png" alt="" /></p>

<p>具体方法：</p>

<ul>
  <li>规划阶段：大型语言模型通过结合少量示例提示（包含细粒度的规划过程），从意图中规划出简洁的解决方案步骤</li>
  <li>实现阶段：模型在前面解决方案步骤的指导下（把计划加入prompt中），逐步生成代码</li>
</ul>

<p>训练方法：少样本实现规划能力，而不是标记数据（记意图-计划对），无需微调。</p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ol>
  <li>
    <p>性能提升：自规划代码生成在Pass\@1指标上实现了高达25.4%的相对提升，与思维链代码生成相比则实现了高达11.9%的提升</p>
  </li>
  <li>
    <p>根据人类评估，正确性、可读性和稳健性提升了代码质量</p>
  </li>
  <li>
    <p>规划能力：我们表明，自我规划是一种出现在足够大的大型语言模型上的涌现能力，但规划可以使大多数大型语言模型受益。</p>
  </li>
  <li>
    <p>最优：我们深入探讨了自我规划方法的几种变体，并证明我们设计的自我规划方法是这些变体中的最佳选择。<img src="/assets/posts_assets/6BX4DXWS.png" alt="" /></p>
  </li>
  <li>
    <p>泛化：我们验证了自我规划方法在多种编程语言（包括Python、Java、Go和JavaScript）上的有效性。</p>
  </li>
</ol>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>为什么多轮的效果不如单轮的</p>

    <ul>
      <li>由于大型语言模型在大量的拼接文本和代码上进行训练以预测下一个标记，因此大型语言模型可能存在截断问题，即它们无法精确控制其输出的终止。当使用计划来生成部分函数（通常是若干语句）时，很难定义截断规则。</li>
    </ul>
  </li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;Self-Planning Code Generation with Large Language Models&gt; 论文粗读 💡 Meta Data Title Self-Planning Code Generation with Large Language Models Journal ACM Transactions on Software Engineering and Methodology (10.1145/3672456) Authors Jiang Xue,Dong Yihong,Wang Lecheng,Fang Zheng,Shang Qiwei,Li Ge,Jin Zhi,Jiao Wenpin Pub.date 2023-06-30]]></summary></entry><entry><title type="html">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting 论文粗读</title><link href="/2024/12/15/MultiTool-CoT-GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting 论文粗读" /><published>2024-12-15T00:00:00+08:00</published><updated>2024-12-15T00:00:00+08:00</updated><id>/2024/12/15/MultiTool-CoT--GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/15/MultiTool-CoT-GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="multitool-cot-gpt-3-can-use-multiple-external-tools-with-chain-of-thought-prompting-论文粗读">&lt;MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting</span> |
| —————————————————————— | ———————————————————————————————————————————————- |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">()</span></em>                      |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Inaba Tatsuro,Kiyomaru Hirokazu,Cheng Fei,Kurohashi Sadao</span>                            |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | 2023                                                                                                                                           |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<ul>
  <li>
    <p>LLM 在各种推理任务上取得了令人瞩目的性能。</p>
  </li>
  <li>
    <p>外部工具注入推理过程的研究都集中于单个外部攻击解决LLM的单个问题，而没有一起解决不同的问题</p>

    <ul>
      <li>本文解决：多个外部工具、同时解决多个问题</li>
    </ul>
  </li>
  <li>
    <p>为了进一步提高性能，提出了MultiTool-CoT</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了MultiTool-CoT 交互式框架：利用CoT提示在推理过程中整合多种外部工具（计算器、知识检索器）（包含工具触发的推理）</p>

<p>训练方法：few-shot learning ，学习在适当的推理步骤中调用多个外部工具</p>

<p><img src="/assets/posts_assets/9PDWDS27.png" alt="" /></p>

<ul>
  <li>
    <p>指令包括：可用的外部工具、带有推理过程的少样本示例、待解决的问题</p>
  </li>
  <li>
    <p>工具触发器：«外部工具名称»</p>
  </li>
  <li>
    <p>工具触发的流程：</p>

    <ul>
      <li>在推理时如果生成了工具触发，则停止文本生成，</li>
      <li>然后从推理过程中提取外部工具的名称和工具的输入，</li>
      <li>然后执行工具，并将结果附加到推理过程末尾</li>
      <li>如果工具调用失败，则回退让GPT生成工具的输出</li>
    </ul>
  </li>
  <li>
    <p>答案：用额外的few-shot从最后一句输出映射到答案值</p>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>NumGLUE 的任务 2 数据集（该数据集需要数值推理和特定领域的知识），MultiTool-CoT 显著优于强大的基线模型，并取得了最先进的性能</li>
</ul>

<p><img src="/assets/posts_assets/TG94PG4C.png" alt="" /></p>

<p>error case:</p>

<ul>
  <li>不正确的推理过程（39%）</li>
  <li>无效的工具输入（35%）</li>
  <li>格式错误（11%）</li>
  <li>不正确的答案（15%）</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>这里的工具调用是如何实现停止的？（直接输出停止吗？）</p>

    <ul>
      <li>是检测到工具触发格式了就停止生成了。然后调用工具继续再生成</li>
    </ul>
  </li>
</ul>

<p>*</p>

<p>*</p>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting&gt; 论文粗读 💡 Meta Data Title MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting Journal  () Authors Inaba Tatsuro,Kiyomaru Hirokazu,Cheng Fei,Kurohashi Sadao Pub.date 2023]]></summary></entry></feed>