<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-Hans"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" hreflang="zh-Hans" /><updated>2025-01-02T21:29:46+08:00</updated><id>/feed.xml</id><title type="html">Ennis’s Blog</title><subtitle>Willing to be a question, willing to be an answer.
</subtitle><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><entry><title type="html">AnyTool-论文粗读</title><link href="/2025/01/01/AnyTool-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="AnyTool-论文粗读" /><published>2025-01-01T00:00:00+08:00</published><updated>2025-01-01T00:00:00+08:00</updated><id>/2025/01/01/AnyTool--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2025/01/01/AnyTool-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="anytool-论文粗读">AnyTool 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls</span>                            |
| —————————————————————— | ———————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/arXiv.2402.04253 ICML 2024)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Du Yu,Wei Fangyun,Zhang Hongyang</span>                                                                   |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2024-02-06</span>                                                                                         |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<ul>
  <li>如何驱动 LLM 有效的使用工具</li>
  <li>提供一种使用大量工具解决用户查询的方式</li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了AnyTool</p>

<blockquote>
  <p>Anytool 采用GPT-4 API 无需训练外部模块</p>
</blockquote>

<ul>
  <li>
    <p>一个具有层次结构API 检索器（用 GPT-4无需训练）</p>

    <ul>
      <li>由三个层组成，每个层包含一个或多个具有不同角色的 agent，克服了LLMs 中最大上下文长度的限制</li>
      <li><img src="/assets/posts_assets/MKPY75CK.png" alt="" /></li>
      <li>首先 meta agent 根据 rapidapi 类和 query 动态给出类别代理</li>
      <li>然后类别代理从工具集中识别工具，创建工具代理</li>
      <li>最后工具代理选择 API添加到 API 候选池中（工具代理不只管理一个工具）</li>
    </ul>
  </li>
  <li>
    <p>使用选定 api 候选者解决用户查询的求解器(Tool LLaMA / GPT-4)</p>

    <ul>
      <li>有两种输出：给出解决方案和放弃</li>
      <li>当放弃时 要给出不相关 API 的原因和名称
*</li>
    </ul>
  </li>
  <li>
    <p>自我反思机制</p>

    <ul>
      <li>
        <p>如果初始解决方案被证明不可行，则重新激活 AnyTool</p>
      </li>
      <li>
        <p>两种情况会被激活：</p>

        <ul>
          <li>给出解决方案，但是 GPT4 评判未解决（由 GPT-4 给出理由）</li>
          <li>求解器给出放弃的结果（由求解器给出理由）</li>
        </ul>
      </li>
      <li>
        <p>然后将理由添加在API 检索器中刚刚激活的代理的上下文中（从下到上），这个过程会重新扩展 API 候选池</p>
      </li>
      <li>
        <p>优点：显著减少了对简单查询的“过渡搜索“的倾向，同时为复杂查询提供了更丰富的上下文和更深入的搜索。</p>
      </li>
      <li>
        <p><img src="/assets/posts_assets/QLYGWVIZ.png" alt="" /></p>
      </li>
    </ul>
  </li>
</ul>

<p>提出修订的评估办法：AnyToolBench</p>

<ul>
  <li>原本：\(R=\frac{\#(\text{Non-solvable})+\#(\mathrm{Solved})}{\#(\text{Non-solvable})+\#(\mathrm{Solved})+\#(\mathrm{Unsolved})}.\)修改后：</li>
</ul>

\[R=\frac{\#(\mathrm{Solved})}{\#(\mathrm{Solved})+\#(\mathrm{Unsolved})}.\]

<ul>
  <li>解决了在不可解决的 query 算通过率，导致了人为的提高通过率的问题，能更好的反应实际应用场景的</li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>在多个数据集上实验表明，AnyTool 的比ToolLLM、GPT-4要好</p>

<ul>
  <li>在 ToolBench 上，AnyTool 的平均通过率比 ToolLLM 高 35.4%</li>
</ul>

<p><img src="/assets/posts_assets/NT2I6J24.png" alt="" /></p>

<ul>
  <li>在 AnyToolBench 上
<img src="/assets/posts_assets/TAR35YZJ.png" alt="" /></li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>消融实验非常的完善</li>
  <li>将自我反思作用在Retriever 上，通过添加 agent 的上下文来实现是一种有效的自我反思方法。</li>
  <li>自我反思关键是要能把已有的错误修正。</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[AnyTool 论文粗读 💡 Meta Data Title AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls Journal  (10.48550/arXiv.2402.04253 ICML 2024) Authors Du Yu,Wei Fangyun,Zhang Hongyang Pub.date 2024-02-06]]></summary></entry><entry><title type="html">Towards-Autonomous-Tool-Utilization-论文粗读</title><link href="/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Towards-Autonomous-Tool-Utilization-论文粗读" /><published>2024-12-30T00:00:00+08:00</published><updated>2024-12-30T00:00:00+08:00</updated><id>/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="towards-autonomous-tool-utilization论文粗读">Towards Autonomous Tool Utilization论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Towards Autonomous Tool Utilization in Language Models: A Unified, Efficient and Scalable Framework</span> |
| —————————————————————— | ————————————————————————————————————————————————————- |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(LREC-COLING)</span></em>                          |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Li Zhi,Li Yicheng,Ye Hequan,Zhang Yin</span>                                                               |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> |                                                                                                                                                               |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>为了实现完全自主的工具使用问题：</p>

    <ul>
      <li>仅凭一个查询语言模型能够自主决定是否使用工具，选择那个特定的工具，以及如何使用这些工具，</li>
      <li>并且所有这一切都不需要在上下文中提供任何特定工具的提示</li>
    </ul>
  </li>
  <li>
    <p>研究现状</p>

    <ul>
      <li>
        <p>ToolLLM选择工具需要额外的检索步骤</p>

        <ul>
          <li>
            <p>缺点：</p>

            <ul>
              <li>会导致累积错误，</li>
              <li>缺乏端到端的优化</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>在上下文中提供与特定场景相关的多种工具</p>

        <ul>
          <li>缺点：有限的上下文使得拓展工具变得困难</li>
        </ul>
      </li>
      <li>
        <p>Toolformer 和 TRICE 关注的问题与本文类似</p>

        <ul>
          <li>缺点：采用自监督数据集构建效率低下，考察工具类型有限</li>
          <li>缺乏对可扩展性的讨论和分析</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>思路：期望大模型能够通过充分的内化各种的工具知识，实现完全自主的工具使用。</p>

<p>为了实现这个目标：引入了一种统一、高效且可扩展的语言模型微调框架</p>

<ul>
  <li>
    <p>根据工具依赖程度，将初始query分为三种不同类型</p>

    <ul>
      <li>
        <p>可直接解决的问题</p>
      </li>
      <li>
        <p>需要验证的问题</p>

        <ul>
          <li>LLM 一定程度上能解决但是容易产生幻觉（复杂的数学计算）</li>
        </ul>
      </li>
      <li>
        <p>由于固有限制而无法解决的问题（实时查询）</p>
      </li>
      <li>
        <p>最后通过将统一建模为序列决策问题来解决</p>

        <ul>
          <li>$\begin{aligned}P(\mathrm{Y,W_e,W_i,H\mid X})&amp;=P(\mathrm{W_{e}}\mid\mathrm{X})&amp;\times P(\mathrm{W_{i}\mid W_{e},X})&amp;\times P(\mathrm{H}\mid\mathrm{W_{e}},\mathrm{W_{i}},\mathrm{X})&amp;\times P(\mathrm{Y}\mid\mathrm{H},\mathrm{W}<em>\mathrm{e},\mathrm{W}</em>\mathrm{i},\mathrm{X})\end{aligned}$
*</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>构建数据集的方法：</p>

    <ul>
      <li>
        <p>“指导、执行、重新格式化“的高效数据集构建策略</p>

        <ul>
          <li>以基础种子查询为起点，通过自我指导来增强这些查询</li>
          <li>用 LLM 参考查询、工具指令来制定 API 调用</li>
          <li>如果 API 调用成功，专门的团队会评估数据示例</li>
          <li>最后重组数据,将工具指令从输入角色转换为输出角色</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/posts_assets/892LKX85.png" alt="" /></p>
<ul>
  <li>
    <p>持续学习：动态平衡重演策略</p>

    <ul>
      <li>从关注新的 API 类别开始，逐渐增加旧 API 类别的比例直到实现平衡（防止忘记旧的 API 调用的知识）</li>
      <li>结果：只需最少的新工具标注数据即可展现出卓越的性能，同时保持现有的工具能力</li>
    </ul>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />
<p><img src="/assets/posts_assets/7396C33A.png" alt="" /></p>

<ul>
  <li>通过对包含26种多样化API的注释数据集进行端到端训练，该模型表现出一定的自我意识，在必要时会自动寻求工具的帮助。</li>
  <li>它在多个评估指标上显著超越了原始指令调优的开源语言模型和GPT-3.5/4。</li>
  <li>消融实验：我们的统一框架可以有效促进模型在不同工具之间学习。</li>
  <li>持续学习只需要最少的新标注即可展现出卓越的性能</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>本文的创新点：就是一个概率分解，然后端到端的训练</li>
  <li>概率分解真的有用吗？最后不还是 nexttoken 微调吗？</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[Towards Autonomous Tool Utilization论文粗读 💡 Meta Data Title Towards Autonomous Tool Utilization in Language Models: A Unified, Efficient and Scalable Framework Journal  (LREC-COLING) Authors Li Zhi,Li Yicheng,Ye Hequan,Zhang Yin Pub.date  ]]></summary></entry><entry><title type="html">Why Can GPT ICL 论文粗读</title><link href="/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Why Can GPT ICL 论文粗读" /><published>2024-12-23T00:00:00+08:00</published><updated>2024-12-23T00:00:00+08:00</updated><id>/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="why-can-gpt-icl-论文粗读">Why Can GPT ICL 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers</span> |
| —————————————————————— | ————————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(acl 2023)</span></em>                              |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Dai Damai,Sun Yutao,Dong Li,Hao Yaru,Ma Shuming,Sui Zhifang,Wei Furu</span>                                 |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> |                                                                                                                                                                |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>LLM 涌现了few-shot In-Context learning的能力</p>

    <ul>
      <li>通过少量示例可以预测训练的时候没有遇到的输入</li>
    </ul>
  </li>
  <li>
    <p>但是ICL能力的机制还是个开放问题</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>有人已经研究了发现：线性层的梯度下降和线性注意力形式上是类似的</p>

<h3 id="工作一解释icl">工作一：解释ICL</h3>

<p>transformer attention和梯度下降的形式非常类似，所以将语言模型解释为“元优化器”，将上下文学习理解为隐式微调：</p>

<p>公式推导：</p>

<p>q是当前推理到的token，X是前面不是示例的token，X‘是前面示例的token, $W_{ZSL}q$ 是 zero-shot下 q 的 attention 结果</p>

<ol>
  <li>初始公式</li>
</ol>

\[\begin{aligned}\mathcal{F}_{\mathrm{ICL}}(\mathbf{q})&amp;=\mathrm{Attn}(V,K,\mathbf{q})\\&amp;=W_V[X^{\prime};X]\operatorname{softmax}\left(\frac{(W_K[X^{\prime};X])^T\mathbf{q}}{\sqrt{d}}\right),\end{aligned}\]

<p>2. 简化，线性化</p>

\[\begin{aligned}\mathcal{F}_{\mathrm{ICL}}(\mathbf{q})&amp;\approx W_V[X^{\prime};X]\left(W_K[X^{\prime};X]\right)^T\mathbf{q}\\&amp;=W_VX\left(W_KX\right)^T\mathbf{q}+W_VX^{\prime}\left(W_KX^{\prime}\right)^T\mathbf{q}\\&amp;\equiv\widetilde{\mathcal{F}}_{\mathrm{ICL}}(\mathbf{q}).\end{aligned}\]

<p>3. 转换简化后的式子</p>

\[\begin{aligned}\widetilde{\mathcal{F}}_{\mathrm{ICL}}(&amp;(\mathbf{q})=W_\mathrm{ZSL}{\mathbf{q}}+W_VX^{\prime}\left(W_KX^{\prime}\right)^T\mathbf{q}\\&amp;=W_\mathrm{ZSL}\mathbf{q}+\text{LinearAttn}\left(W_VX^{\prime},W_KX^{\prime},\mathbf{q}\right)\\&amp;=W_{\mathrm{ZSL}}\mathbf{q}+\sum_iW_V\mathbf{x}_i^{\prime}\left(\left(W_K\mathbf{x}_i^{\prime}\right)^T\mathbf{q}\right)\\&amp;=W_{\mathrm{ZSL}}\mathbf{q}+\sum_i\left((W_V\mathbf{x}_i^{\prime})\otimes(W_K\mathbf{x}_i^{\prime})\right)\mathbf{q}\\&amp;=W_\mathrm{ZSL}{\mathbf{q}}+\Delta W_\mathrm{ICL}{\mathbf{q}}\\&amp;=\left(W_{\mathrm{ZSL}}+\Delta W_{\mathrm{ICL}}\right)\mathbf{q}.\end{aligned}\]

<p>所以ICL理解如下：</p>

<ul>
  <li>预训练的GPT充当元优化器</li>
  <li>通过前向计算根据示范示例产生元梯度</li>
  <li>然后通过注意力将这些元梯度应用于原始GPT，以构建ICL模型</li>
</ul>

<p>ICL 与 fine-tuning 的关系 :</p>

<ul>
  <li>ICL 通过前向计算产生元梯度</li>
  <li>微调通过反向传播计算梯度
<img src="/assets/posts_assets/7BNKYIFK.png" alt="" /></li>
</ul>

<h3 id="工作二提出一种新的注意力机制">工作二：提出一种新的注意力机制</h3>

<p>受到 fine-tuning 和 ICL 的相似性的启发，通过与基于动量的梯度下降类比设计了一种基于动量的注意力，比基础的注意力提升了性能。
<img src="/assets/posts_assets/LB8NYI98.png" alt="" /></p>

<p>基于动量的梯度下降公式：</p>

\[\Theta_t = \Theta_{t-1} - \gamma \sum_{i=1}^{t-1} \eta^{t-i} \nabla f_{\Theta_i}\]

<ul>
  <li>参数更新时不仅考虑当前的梯度，还结合了过去多个时间步的梯度信息</li>
</ul>

<p>基于动量的注意力机制公式：</p>

\[\begin{aligned}\mathrm{MoAttn}(V,K,\mathbf{q}_t)&amp;=\mathrm{Attn}(V,K,\mathbf{q}_t)+\mathrm{EMA}(V)\\&amp;=V\mathrm{softmax}(\frac{K^{T}\mathbf{q}_{t}}{\sqrt{d}})+\sum_{i=1}^{t-1}\eta^{t-i}\mathbf{v}_{i},\end{aligned}\]

<ul>
  <li>
    <p>$v_i$是第 i 个位置token 的 value 向量</p>
  </li>
  <li>
    <p>注意力v向量的动量明确增强了注意力的近期偏差，这已被证明对语言建模有帮助</p>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<h3 id="icl-行为与显式微调相似">ICL 行为与显式微调相似</h3>

<p>在六个分类任务中，比较ICL和微调的模型预测、注意力输出、对query token的注意力权重</p>

<p>实验结果验证了ICL和微调的行为在多个方面相似</p>

<ul>
  <li>ICL 的结果包含了大多数 fine-tuning 预测正确的结果</li>
  <li>ICL 和 fine-tuning 修改 attention 输出的方向相同</li>
  <li>ICL 和 fine-tuning 倾向于生成相同的 attention 权重</li>
  <li>ICL 和 fine-tuning 对于训练的 token 的注意力相似</li>
</ul>

<h3 id="基于动量的注意力机制有效">基于动量的注意力机制有效</h3>

<ul>
  <li>
    <p>困惑度降低<img src="/assets/posts_assets/AZD4IVSR.png" alt="" /></p>
  </li>
  <li>
    <p>ICL 性能提升<img src="/assets/posts_assets/CTC7IUS4.png" alt="" /></p>
  </li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>没有解释为什么ICL不如fine-tuning</p>
  </li>
  <li>
    <p>也没有解释一些ICL现象，</p>

    <ul>
      <li>比如示例中标签不正确的影响不大的现象</li>
      <li>为什么demostration 的顺序会影响ICL 的性能</li>
    </ul>
  </li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[Why Can GPT ICL 论文粗读 💡 Meta Data Title Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers Journal  (acl 2023) Authors Dai Damai,Sun Yutao,Dong Li,Hao Yaru,Ma Shuming,Sui Zhifang,Wei Furu Pub.date  ]]></summary></entry><entry><title type="html">TooL LLM 论文粗读</title><link href="/2024/12/18/TooL-LLM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="TooL LLM 论文粗读" /><published>2024-12-18T00:00:00+08:00</published><updated>2024-12-18T00:00:00+08:00</updated><id>/2024/12/18/%3CTooL%20LLM%3E%20%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/18/TooL-LLM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="tool-llm-论文粗读">&lt;TooL LLM&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</span>                                                                                                                                  |
| —————————————————————— | ———————————————————————————————————————————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/arXiv.2307.16789)</span></em>                                                                                                                      |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Qin Yujia,Liang Shihao,Ye Yining,Zhu Kunlun,Yan Lan,Lu Yaxi,Lin Yankai,Cong Xin,Tang Xiangru,Qian Bill,Zhao Sihan,Hong Lauren,Tian Runchu,Xie Ruobing,Zhou Jie,Gerstein Mark,Li Dahai,Liu Zhiyuan,Sun Maosong</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023-10-03</span>                                                                                                                                                                                                    |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>开源模型使用工具的能力还非常弱：</p>

    <ul>
      <li>因为instruct-tuning 主要集中在基本语言任务上，而忽略了工具使用</li>
      <li>与闭源的LLM有很大差距</li>
    </ul>
  </li>
  <li>
    <p>当前研究：有人探讨了为工具使用指令调优数据，但他们未能充分激发大语言模型的工具使用能力，并具有固有的局限性</p>

    <ul>
      <li>有限的API</li>
      <li>受限的场景</li>
      <li>低效的推理和规划</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>为了弥补差距，提出了ToolLLM，一个一般工具使用框架：包含数据构建、模型训练和评估。</p>

<h3 id="数据构建">数据构建</h3>

<p>提出了ToolBench，一个用于工具使用的指令微调数据集，是使用chatgpt自动构建的</p>

<p>构建可以分为三个阶段</p>

<ol>
  <li>
    <p>API集合：RapidAPI Hub中16464个真实世界的的RESTful API涵盖49个类别</p>
  </li>
  <li>
    <p>指令生成：提示Chatgpt生成涉及这些API的多样化指令，涵盖单工具和多工具场景</p>

    <ul>
      <li>
        <p>抽样不用的API组合，然后制定涉及他们的各种指令</p>

        <ul>
          <li>抽样方法：随机从统一类别中选择2-5个工具，从每个工具抽样3个API</li>
        </ul>
      </li>
      <li>
        <p>ICL+prompt 实现让gpt生成instruction</p>
      </li>
      <li>
        <p>然后用这些（instruction，relevant API）训练一个API retriever</p>
      </li>
    </ul>
  </li>
  <li>
    <p>解决路径注释：使用ChatGPT为每个instruction搜索有效的解决路径（API调用链）</p>

    <ul>
      <li>
        <p>解决路径：包含模型包含多个LLM推理轮次和实时API调用</p>
      </li>
      <li>
        <p>问题：但是GPT-4对复杂的指令通过率很低，这使得注释效率很低，CoT 和 ReACT 也不行</p>

        <ul>
          <li>错误积累</li>
          <li>探索有限（仅探索一个路径）</li>
        </ul>
      </li>
      <li>
        <p>解决：开发了一种新颖的基于深度优先搜索的决策树算法来增强LLM的规划和推理能力，它使LLM能评估多个推理轨迹，做出深思熟虑的决策（选择撤回或者继续走）</p>
      </li>
      <li>
        <p>结果：显著提高了注释效率，并完成了使用ReACT无法实现的复杂指令训<img src="/assets/posts_assets/45QMKDXT.png" alt="" /></p>
      </li>
    </ul>
  </li>
</ol>

<h3 id="评估">评估</h3>

<p>开发了一个自动评估器 ToolEval，包含两个指标</p>

<ol>
  <li>
    <p>通过率：衡量LLM在有限资源内成功执行指令的能力</p>
  </li>
  <li>
    <p>获胜率：比较两种解决方案的质量和有用性</p>

    <ul>
      <li>做法：向GPT提供一个指令和两个解决路径，获得偏好</li>
    </ul>
  </li>
</ol>

<p>通过这两点，构建ChatGPT的prompt</p>

<p>为什么要有ToolEval？</p>

<ol>
  <li>API不断变化的</li>
  <li>指令存在无线潜在解决路径</li>
  <li>为每个测试指令标注一个固定的真实解决路径是不可行的</li>
</ol>

<p>结果：发现ToolEval与人工标注者的通过率有87.1%的一致性而获胜率有80.3%</p>

<p>表明ToolEval很大程度上能够反映和代表人类评估。</p>

<h3 id="模型训练">模型训练</h3>

<p>基于ToolBench对LLaMA进行微调，得到ToolLLaMA，并为其配备了神经网络API检索器，以推荐适合每个指令的API</p>

<h4 id="api-retriever训练">API Retriever训练</h4>

<p>使用Sentence-BERT</p>

<ul>
  <li>API检索器将指令和API文档分别编码为两个向量嵌入，然后通过计算嵌入相似度来评估相关性，</li>
  <li>指令相关的API作为正例，并从其他API中随机抽取一些作为负例进行对比学习</li>
</ul>

<p><img src="/assets/posts_assets/M3KNXVCX.png" alt="" /></p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>性能好：ToolLLaMA展现出执行复杂指令和推广至未见 API 的卓越能力，并且其表现与 ChatGPT 相当</li>
  <li>泛化能力好：ToolLLaMA 在一个超出分布的工具使用数据集 APIBench 中也表现出强大的零-shot 泛化能力。</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;TooL LLM&gt; 论文粗读 💡 Meta Data Title ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs Journal  (10.48550/arXiv.2307.16789) Authors Qin Yujia,Liang Shihao,Ye Yining,Zhu Kunlun,Yan Lan,Lu Yaxi,Lin Yankai,Cong Xin,Tang Xiangru,Qian Bill,Zhao Sihan,Hong Lauren,Tian Runchu,Xie Ruobing,Zhou Jie,Gerstein Mark,Li Dahai,Liu Zhiyuan,Sun Maosong Pub.date 2023-10-03]]></summary></entry><entry><title type="html">TALM 论文粗读</title><link href="/2024/12/17/TALM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="TALM 论文粗读" /><published>2024-12-17T00:00:00+08:00</published><updated>2024-12-17T00:00:00+08:00</updated><id>/2024/12/17/TALM--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/17/TALM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="talm-论文粗读">&lt;TALM&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">TALM: Tool Augmented Language Models</span>                                                     |
| —————————————————————— | ————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/ARXIV.2205.12255)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Parisi Aaron,Zhao Yao,Fiedel Noah</span>                                                        |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2022</span>                                                                                     |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>LLM 需要工具：LLM 不能使模型解决需要访问训练时不可用短暂、变化或私人数据的任务，许多任务用API更好解决</li>
  <li>最近研究将LLM连接到一个环境（仅是作为query的接受者）</li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了工具增强语言模型（TALM），使用模型生成的输出调用任意工具，并关注工具输出以生成任务输出</p>

<p>贡献：</p>

<ul>
  <li>仅使用text-to-text 的API 来增强语言模型</li>
  <li>提出自我博弈（self-play）技术，提高了在few-shot的启动性能</li>
</ul>

<h3 id="talm模型">TALM模型</h3>

<p><img src="/assets/posts_assets/LMBWTV2M.png" alt="" /></p>

<ol>
  <li>
    <table>
      <tbody>
        <tr>
          <td>TALM 首先生成一个基于任务输入文本的工具输入，并通过生成分隔符，例如“</td>
          <td>result”，调用工具的 API。</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>每当检测到这个分隔符时，就会调用工具 API，并将其结果附加到文本序列中。</p>
  </li>
  <li>然后，TALM 继续生成最终的任务输出。<img src="assets/posts_assets/VQ5T6NKX.png" alt="" /></li>
</ol>

<p>TALM 同时学习两个子任务：调用工具和基于工具结果生成答案。</p>

<p>TALM 在架构上用了Seq2Seq模型</p>

<h3 id="迭代iterative-self-play">迭代Iterative self-play</h3>

<ol>
  <li>首先有示例数据集，然后微调这个数据集，再在新数据集（无工具示例）生成工具调用的过程。</li>
  <li>然后看最终结果怎么样，如果大于阈值就添加到原本的数据集中</li>
</ol>

<blockquote>
  <p>这个过程虽然本文是单步的（使用单个工具的），但是很容易建模成多步的，用类似马尔科夫链建模</p>
</blockquote>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>一个知识密集型问答任务（NQ）和一个使用简单工具的推理导向数学任务（MathQA）上表现出色。</li>
  <li>TALM 成功地在问答和数学任务上进行分布外推理，而未增强的语言模型则失败。</li>
  <li>小模型从工具中收益更多（知识密集的任务）</li>
</ul>

<p><img src="assets/posts_assets/K39LZNDR.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />需要再搞清楚seq2seq模型和decoder-only模型的本质区别是什么  [created:: 2024-12-17]  [due:: 2024-12-17]</li>
  <li class="task-list-item">这些论文学习工具的过程感觉都是 少样本-&gt;自己增强（标准不一样）-&gt;然后再微调自己</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;TALM&gt; 论文粗读 💡 Meta Data Title TALM: Tool Augmented Language Models Journal  (10.48550/ARXIV.2205.12255) Authors Parisi Aaron,Zhao Yao,Fiedel Noah Pub.date 2022]]></summary></entry><entry><title type="html">Toolformer 论文粗读</title><link href="/2024/12/17/Toolformer-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Toolformer 论文粗读" /><published>2024-12-17T00:00:00+08:00</published><updated>2024-12-17T00:00:00+08:00</updated><id>/2024/12/17/%3CToolformer%3E%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/17/Toolformer-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="toolformer-论文粗读">&lt;Toolformer&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Toolformer: Language Models Can Teach Themselves to Use Tools</span>                                                           |
| —————————————————————— | ——————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/ARXIV.2302.04761)</span></em>                                |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Schick Timo,Dwivedi-Yu Jane,Dessì Roberto,Raileanu Roberta,Lomeli Maria,Zettlemoyer Luke,Cancedda Nicola,Scialom Thomas</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                                                    |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>LLM的对于一些任务上有卓越的能力，但是基本功能方面却存在困难，例如算数或事实查找。</p>

    <ul>
      <li>这些领域是小模型的强项</li>
    </ul>
  </li>
  <li>
    <p>当前的研究：要么依赖大量的人类标注数据、要么仅限于特定任务的工具使用，阻碍了工具在语言模型中的广泛采用。</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="思路">思路</h3>

<ul>
  <li>
    <p>让LLM通过简单的API自我学习使用外部工具。</p>
  </li>
  <li>
    <p>提出了Toolformer，实现以下愿望：</p>

    <ul>
      <li>
        <p>自监督学习工具，不用人类标注数据</p>

        <ul>
          <li>
            <p>原因：</p>

            <ul>
              <li>人类标注成本高</li>
              <li>人类觉得有用的不一定是LLM觉得有用的</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>LM 不能失去其泛化能力，不局限于特定任务</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="方法">方法</h3>

<p>利用In-context learning，从零开始生成数据集</p>

<ol>
  <li>首先仅通过少量人类编写的API使用示例，让语言模型为一个庞大的语言建模数据集标注潜在的API调用</li>
  <li>然后使用自监督损失（self-supervised loss）来确定哪些API调用实际上有助于模型预测未来的token</li>
  <li>最后微调模型</li>
</ol>

<p>具体：</p>

<p><img src="/assets/posts_assets/Pasted%20image%2020241218101428.png" alt="" /></p>

<ol>
  <li>
    <p><strong>给定一个普通文本的数据集，然后转化成带有API调用的数据集</strong></p>

    <ol>
      <li>
        <p>编写prompt，利用In-context-learning 采样大量潜在的API调用（生成多个API调用）</p>

        <ul>
          <li>先找到序列中哪个位置调用API（设定一个阈值，如果生成&lt;API&gt;概率大于阈值则保留该位置）</li>
          <li>然后选定API：选定位置后，继续生成，然后进行采样多个API候补</li>
        </ul>
      </li>
      <li>
        <p>然后执行API调用（每个API的返回是文本序列）</p>
      </li>
    </ol>
  </li>
  <li>
    <p><strong>然后检查获得的相应是否有助于未来的token，来筛选</strong></p>

    <ol>
      <li>具体就是比较加入API调用后，生成后序序列的概率和不加API调用的概率哪个大（要大过设定的阈值），如果加入API后大超过阈值那就是有帮助，则保留</li>
    </ol>
  </li>
  <li>
    <p><strong>经过筛选得到了增强的数据集，然后进行微调</strong></p>
  </li>
</ol>

<blockquote>
  <p>生成过程中如果生成到了spacial token了就中断生成过程，获得API响应后，插入响应和&lt;/API&gt; token后继续解码过程</p>
</blockquote>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>Toolformer 显著提高了zero-shot性能</li>
  <li>语言建模能力也没有牺牲</li>
</ul>

<p><img src="/assets/posts_assets/BVWDZZY3.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<p>缺点：</p>

<ul>
  <li>无法与搜索引擎交互，只能用他给出的结果，无法重构查询等，然后就没有修补办法。</li>
</ul>

<p>收获：</p>

<ul>
  <li>微调以后再禁用API测试，确实是一个检测微调后有没有损失模型性能的好办法</li>
  <li>微调过程中仅对工具选择算loss感觉挺有用
*</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;Toolformer&gt; 论文粗读 💡 Meta Data Title Toolformer: Language Models Can Teach Themselves to Use Tools Journal  (10.48550/ARXIV.2302.04761) Authors Schick Timo,Dwivedi-Yu Jane,Dessì Roberto,Raileanu Roberta,Lomeli Maria,Zettlemoyer Luke,Cancedda Nicola,Scialom Thomas Pub.date 2023]]></summary></entry><entry><title type="html">Self-Planning Code Generation with Large Language Models 论文粗读</title><link href="/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Self-Planning Code Generation with Large Language Models 论文粗读" /><published>2024-12-16T00:00:00+08:00</published><updated>2024-12-16T00:00:00+08:00</updated><id>/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="self-planning-code-generation-with-large-language-models-论文粗读">&lt;Self-Planning Code Generation with Large Language Models&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Self-Planning Code Generation with Large Language Models</span>                                                                               |
| —————————————————————— | ———————————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)">ACM Transactions on Software Engineering and Methodology </span><em><span style="background-color: rgb(243, 250, 244)">(10.1145/3672456)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Jiang Xue,Dong Yihong,Wang Lecheng,Fang Zheng,Shang Qiwei,Li Ge,Jin Zhi,Jiao Wenpin</span>                                                    |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023-06-30</span>                                                                                                                             |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<p>问题：</p>

<ul>
  <li>
    <p>LLM代码生成无法应对有复杂意图的任务</p>

    <ul>
      <li>解决方法：需要采用规划来分解复杂问题，并在实施之前安排解决方案步骤</li>
    </ul>
  </li>
  <li>
    <p>生成CoT的过程和生成代码的过程本质是相似的，直接将CoT应用于代码并不能减少难度</p>

    <ul>
      <li>解决方法：要专注实现问题的分解</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>思路：将规划引入到了代码生成中，以帮助模型理解复杂意图并降低问题解决难度</p>

<p><img src="/assets/posts_assets/QACCGZ7E.png" alt="" /></p>

<p>具体方法：</p>

<ul>
  <li>规划阶段：大型语言模型通过结合少量示例提示（包含细粒度的规划过程），从意图中规划出简洁的解决方案步骤</li>
  <li>实现阶段：模型在前面解决方案步骤的指导下（把计划加入prompt中），逐步生成代码</li>
</ul>

<p>训练方法：少样本实现规划能力，而不是标记数据（记意图-计划对），无需微调。</p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ol>
  <li>
    <p>性能提升：自规划代码生成在Pass\@1指标上实现了高达25.4%的相对提升，与思维链代码生成相比则实现了高达11.9%的提升</p>
  </li>
  <li>
    <p>根据人类评估，正确性、可读性和稳健性提升了代码质量</p>
  </li>
  <li>
    <p>规划能力：我们表明，自我规划是一种出现在足够大的大型语言模型上的涌现能力，但规划可以使大多数大型语言模型受益。</p>
  </li>
  <li>
    <p>最优：我们深入探讨了自我规划方法的几种变体，并证明我们设计的自我规划方法是这些变体中的最佳选择。<img src="/assets/posts_assets/6BX4DXWS.png" alt="" /></p>
  </li>
  <li>
    <p>泛化：我们验证了自我规划方法在多种编程语言（包括Python、Java、Go和JavaScript）上的有效性。</p>
  </li>
</ol>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>为什么多轮的效果不如单轮的</p>

    <ul>
      <li>由于大型语言模型在大量的拼接文本和代码上进行训练以预测下一个标记，因此大型语言模型可能存在截断问题，即它们无法精确控制其输出的终止。当使用计划来生成部分函数（通常是若干语句）时，很难定义截断规则。</li>
    </ul>
  </li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;Self-Planning Code Generation with Large Language Models&gt; 论文粗读 💡 Meta Data Title Self-Planning Code Generation with Large Language Models Journal ACM Transactions on Software Engineering and Methodology (10.1145/3672456) Authors Jiang Xue,Dong Yihong,Wang Lecheng,Fang Zheng,Shang Qiwei,Li Ge,Jin Zhi,Jiao Wenpin Pub.date 2023-06-30]]></summary></entry><entry><title type="html">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting 论文粗读</title><link href="/2024/12/15/MultiTool-CoT-GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting 论文粗读" /><published>2024-12-15T00:00:00+08:00</published><updated>2024-12-15T00:00:00+08:00</updated><id>/2024/12/15/MultiTool-CoT--GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/15/MultiTool-CoT-GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="multitool-cot-gpt-3-can-use-multiple-external-tools-with-chain-of-thought-prompting-论文粗读">&lt;MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting</span> |
| —————————————————————— | ———————————————————————————————————————————————- |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">()</span></em>                      |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Inaba Tatsuro,Kiyomaru Hirokazu,Cheng Fei,Kurohashi Sadao</span>                            |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | 2023                                                                                                                                           |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<ul>
  <li>
    <p>LLM 在各种推理任务上取得了令人瞩目的性能。</p>
  </li>
  <li>
    <p>外部工具注入推理过程的研究都集中于单个外部攻击解决LLM的单个问题，而没有一起解决不同的问题</p>

    <ul>
      <li>本文解决：多个外部工具、同时解决多个问题</li>
    </ul>
  </li>
  <li>
    <p>为了进一步提高性能，提出了MultiTool-CoT</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了MultiTool-CoT 交互式框架：利用CoT提示在推理过程中整合多种外部工具（计算器、知识检索器）（包含工具触发的推理）</p>

<p>训练方法：few-shot learning ，学习在适当的推理步骤中调用多个外部工具</p>

<p><img src="/assets/posts_assets/9PDWDS27.png" alt="" /></p>

<ul>
  <li>
    <p>指令包括：可用的外部工具、带有推理过程的少样本示例、待解决的问题</p>
  </li>
  <li>
    <p>工具触发器：«外部工具名称»</p>
  </li>
  <li>
    <p>工具触发的流程：</p>

    <ul>
      <li>在推理时如果生成了工具触发，则停止文本生成，</li>
      <li>然后从推理过程中提取外部工具的名称和工具的输入，</li>
      <li>然后执行工具，并将结果附加到推理过程末尾</li>
      <li>如果工具调用失败，则回退让GPT生成工具的输出</li>
    </ul>
  </li>
  <li>
    <p>答案：用额外的few-shot从最后一句输出映射到答案值</p>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>NumGLUE 的任务 2 数据集（该数据集需要数值推理和特定领域的知识），MultiTool-CoT 显著优于强大的基线模型，并取得了最先进的性能</li>
</ul>

<p><img src="/assets/posts_assets/TG94PG4C.png" alt="" /></p>

<p>error case:</p>

<ul>
  <li>不正确的推理过程（39%）</li>
  <li>无效的工具输入（35%）</li>
  <li>格式错误（11%）</li>
  <li>不正确的答案（15%）</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>这里的工具调用是如何实现停止的？（直接输出停止吗？）</p>

    <ul>
      <li>是检测到工具触发格式了就停止生成了。然后调用工具继续再生成</li>
    </ul>
  </li>
</ul>

<p>*</p>

<p>*</p>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting&gt; 论文粗读 💡 Meta Data Title MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting Journal  () Authors Inaba Tatsuro,Kiyomaru Hirokazu,Cheng Fei,Kurohashi Sadao Pub.date 2023]]></summary></entry><entry><title type="html">StructGPT 论文粗读</title><link href="/2024/12/14/StructGPT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="StructGPT 论文粗读" /><published>2024-12-14T00:00:00+08:00</published><updated>2024-12-14T00:00:00+08:00</updated><id>/2024/12/14/StructGPT%20%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/14/StructGPT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="structgpt论文粗读">&lt;StructGPT&gt;论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">StructGPT: A General Framework for Large Language Model to Reason over Structured Data</span>         |
| —————————————————————— | ——————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.18653/v1/2023.emnlp-main.574)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Jiang Jinhao,Zhou Kun,Dong Zican,Ye Keming,Zhao Xin,Wen Ji-Rong</span>                                |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                           |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p><strong>目的</strong>：以统一的方式提升大型语言模型 (LLMs) 在结构化数据上的推理能力</p>
  </li>
  <li>
    <p><strong>motivation</strong>：当前LLM在引入外部知识的时候，通常使用有结构的数据库，而数据库存放的数据通常是结构的，而LLM无法完全理解</p>

    <ul>
      <li>
        <p>直接解决方法：直接线性化（直接拼接成一长串句子）</p>

        <ul>
          <li>缺点：但是数据量很大的时候，不可能全部都直接假如到prompt中。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="问题描述">问题描述</h3>

<p>使用LLM解决基于结构化数据的复杂推理任务</p>

<p><strong>输入：</strong> 自然语言问题、结构化数据（知识图谱、表格、数据库）</p>

<p><strong>输出：</strong> 结果（自然语言或结构化表达式）</p>

<h3 id="解决思路">解决思路</h3>

<ul>
  <li>
    <p>引入专门的APi操作结构化的数据记录</p>

    <ul>
      <li>如何为特定任务设计合适的接口</li>
      <li>如何利用这些接口让LLMs进行推理</li>
    </ul>
  </li>
</ul>

<p>提出了 Iterative Reading and Reasoning 框架解决结构化数据的问答任务——Struct GPT</p>

<h3 id="iterative-reading-and-reasoning-框架">Iterative Reading and Reasoning 框架</h3>

<ul>
  <li>reading 读取：构建了专门的机构从结构化数据收集相关证据</li>
  <li>reasoning 推理：让LLM专注于收集到的信息的推理任务</li>
</ul>

<p>具体过程：invoking-&gt; linearzation -&gt; generation</p>

<h4 id="struct-api定义">struct API定义</h4>

<blockquote>
  <p>因为用LLM来结构化数据不好，所以作者自己设计了API而不是使用LLM</p>
</blockquote>

<ol>
  <li>
    <p>知识图谱：</p>

    <ul>
      <li>Extraction_Neighbor_Relations(e)</li>
      <li>Extract_Triples(e,{r})</li>
    </ul>
  </li>
  <li>
    <p>表格：</p>

    <ul>
      <li>Extract_Columns(T,{c})</li>
      <li>……</li>
    </ul>
  </li>
  <li>
    <p>数据库</p>

    <ul>
      <li>Extract_Table\&amp;Column_Name (D)</li>
      <li>……</li>
    </ul>
  </li>
</ol>

<h4 id="invoking">Invoking</h4>

<p>调用接口从结构化数据中提取相关信息，送到LLM中</p>

<h4 id="information-linearization">Information Linearization</h4>

<p>根据提取的信息，将其转换为可被大型语言模型理解的文本句子</p>

<p>每个结构定义一种线性化规则</p>

<p>来自知识图谱的信息:将其连接成一个长句子，并用特定的分隔符和边界符号标记。</p>

<p>对于表格：</p>

<p>例如“（第1行，年份，1896）”和“（第1行，城市，雅典）”。然后，对于每一行，我们将行索引提取到句首，并在三元组中省略行索引，以组成简化的句子，例如“第1行：（年份，1896），（城市，雅典）”。对于多行数据，我们通过特殊的分隔符将它们连接成一个长句子。</p>

<h4 id="llm-for-generation">LLM for Generation</h4>

<p>有两种prompt：</p>

<ul>
  <li>筛选数据：从线性的数据中根据问题筛选有用的数据</li>
  <li>给出答案：生成最终答案（可以是自然语言也可以是形式化语言（SQL））</li>
</ul>

<h4 id="举例解释流程">举例解释流程</h4>

<p>以知识图谱为例：</p>

<ol>
  <li>根据问题 query 中提到的实体 搜索调用接口Extract_Neighbor_Relation、Extract_Triples</li>
  <li>然后线性化</li>
  <li>利用LLM根据问题选择有用的关系</li>
  <li>调用Extract_Triples收集头实体 eT 和 {r} 中关系的相关三元组</li>
  <li>然后线性化此信息</li>
  <li>LLM应评估当前信息是否足以回答问题，然后，LLM将根据评估结果采取相应操作（停止或迭代）</li>
  <li>使用大型语言模型选择最相关的三元组，其尾实体将被视为最终答案</li>
</ol>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>在8个数据集上的实验结果表明，我们的方法可以有效提升LLMs在零样本和少样本设置下对结构化数据的推理性能，甚至可以与具有竞争力的全数据监督微调方法相媲美。</p>

<p>在KGQA、TableQA和text-to-SQL任务中，与在零样本设置下直接使用ChatGPT相比，我们的方法在WebQSP上实现了11.4%的Hits\@1提升，在TabFact上实现了4.2%的准确率提升，在Spider上实现了4.7%的执行准确率提升。</p>

<p><img src="/assets/posts_assets/42LCZJPX%202.png" alt="" /></p>

<p><img src="/assets/posts_assets/KI6GJZ8H.png" alt="" /></p>

<p><img src="/assets/posts_assets/Y3L54F4W.png" alt="" /></p>

<p>错误：</p>

<ul>
  <li>选择错误：相关信息不是LLM选的</li>
  <li>推理错误：有相关信息但是LLM推理错误</li>
  <li>生成答案格式错误：无法被结果解析识别（数据集不同很难控制生成对应的格式）</li>
  <li>幻觉问题</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>是什么情况下few-shot比zero-shot更差的？</li>
  <li>这种固定的pipeline可能无法让LLM选择自己要的数据</li>
  <li>这种自己定义数据的线性化，是不是太死板了，他说用LLM结构化不太好，但是后面有人做了，是可以的。</li>
  <li>总体来说并不算是真正的工具学习，因为不是 LLM 自主调用的，而是固定的步骤。</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;StructGPT&gt;论文粗读 💡 Meta Data Title StructGPT: A General Framework for Large Language Model to Reason over Structured Data Journal  (10.18653/v1/2023.emnlp-main.574) Authors Jiang Jinhao,Zhou Kun,Dong Zican,Ye Keming,Zhao Xin,Wen Ji-Rong Pub.date 2023]]></summary></entry><entry><title type="html">ChatCoT 论文粗读</title><link href="/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="ChatCoT 论文粗读" /><published>2024-12-14T00:00:00+08:00</published><updated>2024-12-14T00:00:00+08:00</updated><id>/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="chatcot论文粗读">&lt;ChatCoT&gt;论文粗读</h1>

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models</span>             |
| —————————————————————— | ———————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.18653/v1/2023.findings-emnlp.985)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Chen Zhipeng,Zhou Kun,Zhang Beichen,Gong Zheng,Zhao Xin,Wen Ji-Rong</span>                                |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                               |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<p>现有的问题：</p>

<p>CoT的生成过程是一次性的，在中间步骤中使用工具将需要对其进行打断，从而损害生成过程的连续性</p>

<p>工具的调用会打断CoT的进程</p>

<ul>
  <li>
    <p>现有的解决方法：</p>

    <ul>
      <li>
        <p>依赖LLM预先安排工具使用计划以供后序执行</p>

        <ul>
          <li>缺点：生成计划后无法与工具交互，及时看到明显的错误也无法纠正，存在误差累积</li>
        </ul>
      </li>
      <li>
        <p>设计针对特定任务的固定操作</p>

        <ul>
          <li>缺点：必须频繁的在LLM推理和执行行动之间切换，损害了CoT之间的连贯性（就比如CoT下一步必须是调工具）</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>作者要寻找一种更统一的方法整合CoT和tool</p>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="解决思路">解决思路</h3>

<ul>
  <li>
    <p>将LLM的工具的操作视为LLM与工具之间的交互。</p>
  </li>
  <li>
    <p>将LLM和工具之间的交互过程建模为多轮对话，利用LLM出色的对话能力来操作工具</p>

    <ul>
      <li>在每一轮中，LLM可以在需要时自由地与工具交互，否则自行进行推理</li>
      <li>对话持续进行直到LLM得出最终答案。</li>
    </ul>
  </li>
  <li>
    <p>针对问题：在此过程中，由于基于对话的LLM可以很好地理解多轮上下文，它们可以在整个对话中遵循思维链，并自然地相应地调用工具，从而保持推理过程的连续性。</p>
  </li>
</ul>

<p>所以作者提出了ChatCoT，一种用于基于聊天的LLM的工具增强型思维推理策略。</p>

<h3 id="初始设定">初始设定</h3>

<h4 id="任务定义">任务定义</h4>

<p>专注于提升LLM在复杂任务上的推理能力（解决数学竞赛问题）</p>

<p>任务描述：</p>

<ul>
  <li>问题陈述：复杂问题的背景和描述</li>
  <li>解答文本：获得答案单独详细解决过程</li>
  <li>答案</li>
</ul>

<p>任务目的：给定问题陈述最终生成准确答案</p>

<h4 id="工具集">工具集</h4>

<ul>
  <li>
    <p>计算器：给定数据表达式可以化简</p>

    <ul>
      <li>实现：用SymPy python库</li>
    </ul>
  </li>
  <li>
    <p>方程求解器：给定方程组和未知变量，可以求解</p>

    <ul>
      <li>实现：用SymPy python库</li>
    </ul>
  </li>
  <li>
    <p>检索器：给查询提取相关信息</p>

    <ul>
      <li>用SimCSE</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/posts_assets/MSM9TUAY.png" alt="" /></p>

<h3 id="具体方法">具体方法</h3>

<blockquote>
  <p>工具学习的训练方法：In-context learning</p>
</blockquote>

<p>通过agent（预定义的规则）与LLM的对话来实现推理和工具调用</p>

<p>整体分两个阶段：</p>

<ul>
  <li>
    <p>给LLM输入关于工具、任务和推理格式的知识来初始化对话的早期轮次(对话形式）</p>
  </li>
  <li>
    <p>迭代一个专门设计的<strong>工具增强型推理</strong>步骤(对话），直到获得答案</p>

    <ul>
      <li>在每次迭代中，基于当前的结果，我们首先利用大型语言模型进行推理，然后通过大型语言模型选择合适的工具，最后执行所选工具以获得当前步骤的中间结果。</li>
      <li>推理：LLM根据示例可以将推理分解为多轮对话，而无需专门的提示或指令。直到需要工具功能才停止</li>
      <li>工具选择：通过prompt提示让LLM选择（问LLM用什么工具如果回复不使用工具就继续推理）</li>
      <li>工具执行：给定选定的工具和参数，然后执行，可能结果无法让LLM满意，我们也可以增加几轮反馈，让LLM判断结果是否有用，然后重新使用该工具获取新结果</li>
    </ul>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>在两个复杂的推理基准数据集上进行了实验，即MATH 和HotpotQA 。</p>

<p>ChatCoT在MATH上取得了非常有希望的性能，与SOTA基线方法相比，平均性能相对提高了7.9%。</p>

<p><img src="/assets/posts_assets/J258MYBV.png" alt="" /></p>

<p><img src="/assets/posts_assets/YV2RNQDC.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>整体的prompt流程具体是什么样子？</li>
  <li>agent是如何搞的</li>
  <li>为什么比其他的CoT+Tool好呢？</li>
  <li>读一下其他CoT+Tool</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;ChatCoT&gt;论文粗读 💡 Meta Data Title ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models Journal  (10.18653/v1/2023.findings-emnlp.985) Authors Chen Zhipeng,Zhou Kun,Zhang Beichen,Gong Zheng,Zhao Xin,Wen Ji-Rong Pub.date 2023]]></summary></entry></feed>