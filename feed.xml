<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-Hans"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" hreflang="zh-Hans" /><updated>2025-01-02T11:53:00+08:00</updated><id>/feed.xml</id><title type="html">Ennis’s Blog</title><subtitle>Willing to be a question, willing to be an answer.
</subtitle><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><entry><title type="html">Towards-Autonomous-Tool-Utilization-论文粗读</title><link href="/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Towards-Autonomous-Tool-Utilization-论文粗读" /><published>2024-12-30T00:00:00+08:00</published><updated>2024-12-30T00:00:00+08:00</updated><id>/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/30/Towards-Autonomous-Tool-Utilization-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="towards-autonomous-tool-utilization论文粗读">Towards Autonomous Tool Utilization论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Towards Autonomous Tool Utilization in Language Models: A Unified, Efficient and Scalable Framework</span> |
| —————————————————————— | ————————————————————————————————————————————————————- |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(LREC-COLING)</span></em>                          |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Li Zhi,Li Yicheng,Ye Hequan,Zhang Yin</span>                                                               |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> |                                                                                                                                                               |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>为了实现完全自主的工具使用问题：</p>

    <ul>
      <li>仅凭一个查询语言模型能够自主决定是否使用工具，选择那个特定的工具，以及如何使用这些工具，</li>
      <li>并且所有这一切都不需要在上下文中提供任何特定工具的提示</li>
    </ul>
  </li>
  <li>
    <p>研究现状</p>

    <ul>
      <li>
        <p>ToolLLM选择工具需要额外的检索步骤</p>

        <ul>
          <li>
            <p>缺点：</p>

            <ul>
              <li>会导致累积错误，</li>
              <li>缺乏端到端的优化</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>在上下文中提供与特定场景相关的多种工具</p>

        <ul>
          <li>缺点：有限的上下文使得拓展工具变得困难</li>
        </ul>
      </li>
      <li>
        <p>Toolformer 和 TRICE 关注的问题与本文类似</p>

        <ul>
          <li>缺点：采用自监督数据集构建效率低下，考察工具类型有限</li>
          <li>缺乏对可扩展性的讨论和分析</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>思路：期望大模型能够通过充分的内化各种的工具知识，实现完全自主的工具使用。</p>

<p>为了实现这个目标：引入了一种统一、高效且可扩展的语言模型微调框架</p>

<ul>
  <li>
    <p>根据工具依赖程度，将初始query分为三种不同类型</p>

    <ul>
      <li>
        <p>可直接解决的问题</p>
      </li>
      <li>
        <p>需要验证的问题</p>

        <ul>
          <li>LLM 一定程度上能解决但是容易产生幻觉（复杂的数学计算）</li>
        </ul>
      </li>
      <li>
        <p>由于固有限制而无法解决的问题（实时查询）</p>
      </li>
      <li>
        <p>最后通过将统一建模为序列决策问题来解决</p>

        <ul>
          <li>$\begin{aligned}P(\mathrm{Y,W_e,W_i,H\mid X})&amp;=P(\mathrm{W_{e}}\mid\mathrm{X})&amp;\times P(\mathrm{W_{i}\mid W_{e},X})&amp;\times P(\mathrm{H}\mid\mathrm{W_{e}},\mathrm{W_{i}},\mathrm{X})&amp;\times P(\mathrm{Y}\mid\mathrm{H},\mathrm{W}<em>\mathrm{e},\mathrm{W}</em>\mathrm{i},\mathrm{X})\end{aligned}$
*</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>构建数据集的方法：</p>

    <ul>
      <li>
        <p>“指导、执行、重新格式化“的高效数据集构建策略</p>

        <ul>
          <li>以基础种子查询为起点，通过自我指导来增强这些查询</li>
          <li>用 LLM 参考查询、工具指令来制定 API 调用</li>
          <li>如果 API 调用成功，专门的团队会评估数据示例</li>
          <li>最后重组数据,将工具指令从输入角色转换为输出角色</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="attachments/892LKX85.png" alt="&lt;img alt=&quot;&quot; data-attachment-key=&quot;892LKX85&quot; width=&quot;1808&quot; height=&quot;484&quot; src=&quot;attachments/892LKX85.png&quot; ztype=&quot;zimage&quot;&gt;" /></p>

<ul>
  <li>
    <p>持续学习：动态平衡重演策略</p>

    <ul>
      <li>从关注新的 API 类别开始，逐渐增加旧 API 类别的比例直到实现平衡（防止忘记旧的 API 调用的知识）</li>
      <li>结果：只需最少的新工具标注数据即可展现出卓越的性能，同时保持现有的工具能力</li>
    </ul>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p><img src="attachments/7396C33A.png" alt="&lt;img alt=&quot;&quot; data-attachment-key=&quot;7396C33A&quot; width=&quot;1808&quot; height=&quot;640&quot; src=&quot;attachments/7396C33A.png&quot; ztype=&quot;zimage&quot;&gt;" /></p>

<ul>
  <li>通过对包含26种多样化API的注释数据集进行端到端训练，该模型表现出一定的自我意识，在必要时会自动寻求工具的帮助。</li>
  <li>它在多个评估指标上显著超越了原始指令调优的开源语言模型和GPT-3.5/4。</li>
  <li>消融实验：我们的统一框架可以有效促进模型在不同工具之间学习。</li>
  <li>持续学习只需要最少的新标注即可展现出卓越的性能</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>本文的创新点：就是一个概率分解，然后端到端的训练</li>
  <li>概率分解真的有用吗？</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[Towards Autonomous Tool Utilization论文粗读 💡 Meta Data Title Towards Autonomous Tool Utilization in Language Models: A Unified, Efficient and Scalable Framework Journal  (LREC-COLING) Authors Li Zhi,Li Yicheng,Ye Hequan,Zhang Yin Pub.date  ]]></summary></entry><entry><title type="html">Why Can GPT ICL 论文粗读</title><link href="/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Why Can GPT ICL 论文粗读" /><published>2024-12-23T00:00:00+08:00</published><updated>2024-12-23T00:00:00+08:00</updated><id>/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/23/Why-Can-GPT-ICL-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="why-can-gpt-icl-论文粗读">Why Can GPT ICL 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers</span> |
| —————————————————————— | ————————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(acl 2023)</span></em>                              |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Dai Damai,Sun Yutao,Dong Li,Hao Yaru,Ma Shuming,Sui Zhifang,Wei Furu</span>                                 |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> |                                                                                                                                                                |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>LLM 涌现了few-shot In-Context learning的能力</p>

    <ul>
      <li>通过少量示例可以预测训练的时候没有遇到的输入</li>
    </ul>
  </li>
  <li>
    <p>但是ICL能力的机制还是个开放问题</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>有人已经研究了发现：线性层的梯度下降和线性注意力形式上是类似的</p>

<h3 id="工作一解释icl">工作一：解释ICL</h3>

<p>transformer attention和梯度下降的形式非常类似，所以将语言模型解释为“元优化器”，将上下文学习理解为隐式微调：</p>

<p>公式推导：</p>

<p>q是当前推理到的token，X是前面不是示例的token，X‘是前面示例的token, $W_{ZSL}q$ 是 zero-shot下 q 的 attention 结果</p>

<ol>
  <li>初始公式</li>
</ol>

\[\begin{aligned}\mathcal{F}_{\mathrm{ICL}}(\mathbf{q})&amp;=\mathrm{Attn}(V,K,\mathbf{q})\\&amp;=W_V[X^{\prime};X]\operatorname{softmax}\left(\frac{(W_K[X^{\prime};X])^T\mathbf{q}}{\sqrt{d}}\right),\end{aligned}\]

<p>2. 简化，线性化</p>

\[\begin{aligned}\mathcal{F}_{\mathrm{ICL}}(\mathbf{q})&amp;\approx W_V[X^{\prime};X]\left(W_K[X^{\prime};X]\right)^T\mathbf{q}\\&amp;=W_VX\left(W_KX\right)^T\mathbf{q}+W_VX^{\prime}\left(W_KX^{\prime}\right)^T\mathbf{q}\\&amp;\equiv\widetilde{\mathcal{F}}_{\mathrm{ICL}}(\mathbf{q}).\end{aligned}\]

<p>3. 转换简化后的式子</p>

\[\begin{aligned}\widetilde{\mathcal{F}}_{\mathrm{ICL}}(&amp;(\mathbf{q})=W_\mathrm{ZSL}{\mathbf{q}}+W_VX^{\prime}\left(W_KX^{\prime}\right)^T\mathbf{q}\\&amp;=W_\mathrm{ZSL}\mathbf{q}+\text{LinearAttn}\left(W_VX^{\prime},W_KX^{\prime},\mathbf{q}\right)\\&amp;=W_{\mathrm{ZSL}}\mathbf{q}+\sum_iW_V\mathbf{x}_i^{\prime}\left(\left(W_K\mathbf{x}_i^{\prime}\right)^T\mathbf{q}\right)\\&amp;=W_{\mathrm{ZSL}}\mathbf{q}+\sum_i\left((W_V\mathbf{x}_i^{\prime})\otimes(W_K\mathbf{x}_i^{\prime})\right)\mathbf{q}\\&amp;=W_\mathrm{ZSL}{\mathbf{q}}+\Delta W_\mathrm{ICL}{\mathbf{q}}\\&amp;=\left(W_{\mathrm{ZSL}}+\Delta W_{\mathrm{ICL}}\right)\mathbf{q}.\end{aligned}\]

<p>所以ICL理解如下：</p>

<ul>
  <li>预训练的GPT充当元优化器</li>
  <li>通过前向计算根据示范示例产生元梯度</li>
  <li>然后通过注意力将这些元梯度应用于原始GPT，以构建ICL模型</li>
</ul>

<p>ICL 与 fine-tuning 的关系 :</p>

<ul>
  <li>ICL 通过前向计算产生元梯度</li>
  <li>微调通过反向传播计算梯度
<img src="/assets/posts_assets/7BNKYIFK.png" alt="" /></li>
</ul>

<h3 id="工作二提出一种新的注意力机制">工作二：提出一种新的注意力机制</h3>

<p>受到 fine-tuning 和 ICL 的相似性的启发，通过与基于动量的梯度下降类比设计了一种基于动量的注意力，比基础的注意力提升了性能。
<img src="/assets/posts_assets/LB8NYI98.png" alt="" /></p>

<p>基于动量的梯度下降公式：</p>

\[\Theta_t = \Theta_{t-1} - \gamma \sum_{i=1}^{t-1} \eta^{t-i} \nabla f_{\Theta_i}\]

<ul>
  <li>参数更新时不仅考虑当前的梯度，还结合了过去多个时间步的梯度信息</li>
</ul>

<p>基于动量的注意力机制公式：</p>

\[\begin{aligned}\mathrm{MoAttn}(V,K,\mathbf{q}_t)&amp;=\mathrm{Attn}(V,K,\mathbf{q}_t)+\mathrm{EMA}(V)\\&amp;=V\mathrm{softmax}(\frac{K^{T}\mathbf{q}_{t}}{\sqrt{d}})+\sum_{i=1}^{t-1}\eta^{t-i}\mathbf{v}_{i},\end{aligned}\]

<ul>
  <li>
    <p>$v_i$是第 i 个位置token 的 value 向量</p>
  </li>
  <li>
    <p>注意力v向量的动量明确增强了注意力的近期偏差，这已被证明对语言建模有帮助</p>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<h3 id="icl-行为与显式微调相似">ICL 行为与显式微调相似</h3>

<p>在六个分类任务中，比较ICL和微调的模型预测、注意力输出、对query token的注意力权重</p>

<p>实验结果验证了ICL和微调的行为在多个方面相似</p>

<ul>
  <li>ICL 的结果包含了大多数 fine-tuning 预测正确的结果</li>
  <li>ICL 和 fine-tuning 修改 attention 输出的方向相同</li>
  <li>ICL 和 fine-tuning 倾向于生成相同的 attention 权重</li>
  <li>ICL 和 fine-tuning 对于训练的 token 的注意力相似</li>
</ul>

<h3 id="基于动量的注意力机制有效">基于动量的注意力机制有效</h3>

<ul>
  <li>
    <p>困惑度降低<img src="/assets/posts_assets/AZD4IVSR.png" alt="" /></p>
  </li>
  <li>
    <p>ICL 性能提升<img src="/assets/posts_assets/CTC7IUS4.png" alt="" /></p>
  </li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>没有解释为什么ICL不如fine-tuning</p>
  </li>
  <li>
    <p>也没有解释一些ICL现象，</p>

    <ul>
      <li>比如示例中标签不正确的影响不大的现象</li>
      <li>为什么demostration 的顺序会影响ICL 的性能</li>
    </ul>
  </li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[Why Can GPT ICL 论文粗读 💡 Meta Data Title Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers Journal  (acl 2023) Authors Dai Damai,Sun Yutao,Dong Li,Hao Yaru,Ma Shuming,Sui Zhifang,Wei Furu Pub.date  ]]></summary></entry><entry><title type="html">TooL LLM 论文粗读</title><link href="/2024/12/18/TooL-LLM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="TooL LLM 论文粗读" /><published>2024-12-18T00:00:00+08:00</published><updated>2024-12-18T00:00:00+08:00</updated><id>/2024/12/18/%3CTooL%20LLM%3E%20%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/18/TooL-LLM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="tool-llm-论文粗读">&lt;TooL LLM&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</span>                                                                                                                                  |
| —————————————————————— | ———————————————————————————————————————————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/arXiv.2307.16789)</span></em>                                                                                                                      |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Qin Yujia,Liang Shihao,Ye Yining,Zhu Kunlun,Yan Lan,Lu Yaxi,Lin Yankai,Cong Xin,Tang Xiangru,Qian Bill,Zhao Sihan,Hong Lauren,Tian Runchu,Xie Ruobing,Zhou Jie,Gerstein Mark,Li Dahai,Liu Zhiyuan,Sun Maosong</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023-10-03</span>                                                                                                                                                                                                    |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>开源模型使用工具的能力还非常弱：</p>

    <ul>
      <li>因为instruct-tuning 主要集中在基本语言任务上，而忽略了工具使用</li>
      <li>与闭源的LLM有很大差距</li>
    </ul>
  </li>
  <li>
    <p>当前研究：有人探讨了为工具使用指令调优数据，但他们未能充分激发大语言模型的工具使用能力，并具有固有的局限性</p>

    <ul>
      <li>有限的API</li>
      <li>受限的场景</li>
      <li>低效的推理和规划</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>为了弥补差距，提出了ToolLLM，一个一般工具使用框架：包含数据构建、模型训练和评估。</p>

<h3 id="数据构建">数据构建</h3>

<p>提出了ToolBench，一个用于工具使用的指令微调数据集，是使用chatgpt自动构建的</p>

<p>构建可以分为三个阶段</p>

<ol>
  <li>
    <p>API集合：RapidAPI Hub中16464个真实世界的的RESTful API涵盖49个类别</p>
  </li>
  <li>
    <p>指令生成：提示Chatgpt生成涉及这些API的多样化指令，涵盖单工具和多工具场景</p>

    <ul>
      <li>
        <p>抽样不用的API组合，然后制定涉及他们的各种指令</p>

        <ul>
          <li>抽样方法：随机从统一类别中选择2-5个工具，从每个工具抽样3个API</li>
        </ul>
      </li>
      <li>
        <p>ICL+prompt 实现让gpt生成instruction</p>
      </li>
      <li>
        <p>然后用这些（instruction，relevant API）训练一个API retriever</p>
      </li>
    </ul>
  </li>
  <li>
    <p>解决路径注释：使用ChatGPT为每个instruction搜索有效的解决路径（API调用链）</p>

    <ul>
      <li>
        <p>解决路径：包含模型包含多个LLM推理轮次和实时API调用</p>
      </li>
      <li>
        <p>问题：但是GPT-4对复杂的指令通过率很低，这使得注释效率很低，CoT 和 ReACT 也不行</p>

        <ul>
          <li>错误积累</li>
          <li>探索有限（仅探索一个路径）</li>
        </ul>
      </li>
      <li>
        <p>解决：开发了一种新颖的基于深度优先搜索的决策树算法来增强LLM的规划和推理能力，它使LLM能评估多个推理轨迹，做出深思熟虑的决策（选择撤回或者继续走）</p>
      </li>
      <li>
        <p>结果：显著提高了注释效率，并完成了使用ReACT无法实现的复杂指令训<img src="/assets/posts_assets/45QMKDXT.png" alt="" /></p>
      </li>
    </ul>
  </li>
</ol>

<h3 id="评估">评估</h3>

<p>开发了一个自动评估器 ToolEval，包含两个指标</p>

<ol>
  <li>
    <p>通过率：衡量LLM在有限资源内成功执行指令的能力</p>
  </li>
  <li>
    <p>获胜率：比较两种解决方案的质量和有用性</p>

    <ul>
      <li>做法：向GPT提供一个指令和两个解决路径，获得偏好</li>
    </ul>
  </li>
</ol>

<p>通过这两点，构建ChatGPT的prompt</p>

<p>为什么要有ToolEval？</p>

<ol>
  <li>API不断变化的</li>
  <li>指令存在无线潜在解决路径</li>
  <li>为每个测试指令标注一个固定的真实解决路径是不可行的</li>
</ol>

<p>结果：发现ToolEval与人工标注者的通过率有87.1%的一致性而获胜率有80.3%</p>

<p>表明ToolEval很大程度上能够反映和代表人类评估。</p>

<h3 id="模型训练">模型训练</h3>

<p>基于ToolBench对LLaMA进行微调，得到ToolLLaMA，并为其配备了神经网络API检索器，以推荐适合每个指令的API</p>

<h4 id="api-retriever训练">API Retriever训练</h4>

<p>使用Sentence-BERT</p>

<ul>
  <li>API检索器将指令和API文档分别编码为两个向量嵌入，然后通过计算嵌入相似度来评估相关性，</li>
  <li>指令相关的API作为正例，并从其他API中随机抽取一些作为负例进行对比学习</li>
</ul>

<p><img src="/assets/posts_assets/M3KNXVCX.png" alt="" /></p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>性能好：ToolLLaMA展现出执行复杂指令和推广至未见 API 的卓越能力，并且其表现与 ChatGPT 相当</li>
  <li>泛化能力好：ToolLLaMA 在一个超出分布的工具使用数据集 APIBench 中也表现出强大的零-shot 泛化能力。</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;TooL LLM&gt; 论文粗读 💡 Meta Data Title ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs Journal  (10.48550/arXiv.2307.16789) Authors Qin Yujia,Liang Shihao,Ye Yining,Zhu Kunlun,Yan Lan,Lu Yaxi,Lin Yankai,Cong Xin,Tang Xiangru,Qian Bill,Zhao Sihan,Hong Lauren,Tian Runchu,Xie Ruobing,Zhou Jie,Gerstein Mark,Li Dahai,Liu Zhiyuan,Sun Maosong Pub.date 2023-10-03]]></summary></entry><entry><title type="html">Toolformer 论文粗读</title><link href="/2024/12/17/Toolformer-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Toolformer 论文粗读" /><published>2024-12-17T00:00:00+08:00</published><updated>2024-12-17T00:00:00+08:00</updated><id>/2024/12/17/%3CToolformer%3E%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/17/Toolformer-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="toolformer-论文粗读">&lt;Toolformer&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Toolformer: Language Models Can Teach Themselves to Use Tools</span>                                                           |
| —————————————————————— | ——————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/ARXIV.2302.04761)</span></em>                                |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Schick Timo,Dwivedi-Yu Jane,Dessì Roberto,Raileanu Roberta,Lomeli Maria,Zettlemoyer Luke,Cancedda Nicola,Scialom Thomas</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                                                    |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>LLM的对于一些任务上有卓越的能力，但是基本功能方面却存在困难，例如算数或事实查找。</p>

    <ul>
      <li>这些领域是小模型的强项</li>
    </ul>
  </li>
  <li>
    <p>当前的研究：要么依赖大量的人类标注数据、要么仅限于特定任务的工具使用，阻碍了工具在语言模型中的广泛采用。</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="思路">思路</h3>

<ul>
  <li>
    <p>让LLM通过简单的API自我学习使用外部工具。</p>
  </li>
  <li>
    <p>提出了Toolformer，实现以下愿望：</p>

    <ul>
      <li>
        <p>自监督学习工具，不用人类标注数据</p>

        <ul>
          <li>
            <p>原因：</p>

            <ul>
              <li>人类标注成本高</li>
              <li>人类觉得有用的不一定是LLM觉得有用的</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>LM 不能失去其泛化能力，不局限于特定任务</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="方法">方法</h3>

<p>利用In-context learning，从零开始生成数据集</p>

<ol>
  <li>首先仅通过少量人类编写的API使用示例，让语言模型为一个庞大的语言建模数据集标注潜在的API调用</li>
  <li>然后使用自监督损失（self-supervised loss）来确定哪些API调用实际上有助于模型预测未来的token</li>
  <li>最后微调模型</li>
</ol>

<p>具体：</p>

<p><img src="/assets/posts_assets/Pasted%20image%2020241218101428.png" alt="" /></p>

<ol>
  <li>
    <p><strong>给定一个普通文本的数据集，然后转化成带有API调用的数据集</strong></p>

    <ol>
      <li>
        <p>编写prompt，利用In-context-learning 采样大量潜在的API调用（生成多个API调用）</p>

        <ul>
          <li>先找到序列中哪个位置调用API（设定一个阈值，如果生成&lt;API&gt;概率大于阈值则保留该位置）</li>
          <li>然后选定API：选定位置后，继续生成，然后进行采样多个API候补</li>
        </ul>
      </li>
      <li>
        <p>然后执行API调用（每个API的返回是文本序列）</p>
      </li>
    </ol>
  </li>
  <li>
    <p><strong>然后检查获得的相应是否有助于未来的token，来筛选</strong></p>

    <ol>
      <li>具体就是比较加入API调用后，生成后序序列的概率和不加API调用的概率哪个大（要大过设定的阈值），如果加入API后大超过阈值那就是有帮助，则保留</li>
    </ol>
  </li>
  <li>
    <p><strong>经过筛选得到了增强的数据集，然后进行微调</strong></p>
  </li>
</ol>

<blockquote>
  <p>生成过程中如果生成到了spacial token了就中断生成过程，获得API响应后，插入响应和&lt;/API&gt; token后继续解码过程</p>
</blockquote>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>Toolformer 显著提高了zero-shot性能</li>
  <li>语言建模能力也没有牺牲</li>
</ul>

<p><img src="/assets/posts_assets/BVWDZZY3.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<p>缺点：</p>

<ul>
  <li>无法与搜索引擎交互，只能用他给出的结果，无法重构查询等，然后就没有修补办法。</li>
</ul>

<p>收获：</p>

<ul>
  <li>微调以后再禁用API测试，确实是一个检测微调后有没有损失模型性能的好办法</li>
  <li>微调过程中仅对工具选择算loss感觉挺有用
*</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;Toolformer&gt; 论文粗读 💡 Meta Data Title Toolformer: Language Models Can Teach Themselves to Use Tools Journal  (10.48550/ARXIV.2302.04761) Authors Schick Timo,Dwivedi-Yu Jane,Dessì Roberto,Raileanu Roberta,Lomeli Maria,Zettlemoyer Luke,Cancedda Nicola,Scialom Thomas Pub.date 2023]]></summary></entry><entry><title type="html">TALM 论文粗读</title><link href="/2024/12/17/TALM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="TALM 论文粗读" /><published>2024-12-17T00:00:00+08:00</published><updated>2024-12-17T00:00:00+08:00</updated><id>/2024/12/17/TALM--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/17/TALM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="talm-论文粗读">&lt;TALM&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">TALM: Tool Augmented Language Models</span>                                                     |
| —————————————————————— | ————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/ARXIV.2205.12255)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Parisi Aaron,Zhao Yao,Fiedel Noah</span>                                                        |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2022</span>                                                                                     |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>LLM 需要工具：LLM 不能使模型解决需要访问训练时不可用短暂、变化或私人数据的任务，许多任务用API更好解决</li>
  <li>最近研究将LLM连接到一个环境（仅是作为query的接受者）</li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了工具增强语言模型（TALM），使用模型生成的输出调用任意工具，并关注工具输出以生成任务输出</p>

<p>贡献：</p>

<ul>
  <li>仅使用text-to-text 的API 来增强语言模型</li>
  <li>提出自我博弈（self-play）技术，提高了在few-shot的启动性能</li>
</ul>

<h3 id="talm模型">TALM模型</h3>

<p><img src="/assets/posts_assets/LMBWTV2M.png" alt="" /></p>

<ol>
  <li>
    <table>
      <tbody>
        <tr>
          <td>TALM 首先生成一个基于任务输入文本的工具输入，并通过生成分隔符，例如“</td>
          <td>result”，调用工具的 API。</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>每当检测到这个分隔符时，就会调用工具 API，并将其结果附加到文本序列中。</p>
  </li>
  <li>然后，TALM 继续生成最终的任务输出。<img src="assets/posts_assets/VQ5T6NKX.png" alt="" /></li>
</ol>

<p>TALM 同时学习两个子任务：调用工具和基于工具结果生成答案。</p>

<p>TALM 在架构上用了Seq2Seq模型</p>

<h3 id="迭代iterative-self-play">迭代Iterative self-play</h3>

<ol>
  <li>首先有示例数据集，然后微调这个数据集，再在新数据集（无工具示例）生成工具调用的过程。</li>
  <li>然后看最终结果怎么样，如果大于阈值就添加到原本的数据集中</li>
</ol>

<blockquote>
  <p>这个过程虽然本文是单步的（使用单个工具的），但是很容易建模成多步的，用类似马尔科夫链建模</p>
</blockquote>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>一个知识密集型问答任务（NQ）和一个使用简单工具的推理导向数学任务（MathQA）上表现出色。</li>
  <li>TALM 成功地在问答和数学任务上进行分布外推理，而未增强的语言模型则失败。</li>
  <li>小模型从工具中收益更多（知识密集的任务）</li>
</ul>

<p><img src="assets/posts_assets/K39LZNDR.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />需要再搞清楚seq2seq模型和decoder-only模型的本质区别是什么  [created:: 2024-12-17]  [due:: 2024-12-17]</li>
  <li class="task-list-item">这些论文学习工具的过程感觉都是 少样本-&gt;自己增强（标准不一样）-&gt;然后再微调自己</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;TALM&gt; 论文粗读 💡 Meta Data Title TALM: Tool Augmented Language Models Journal  (10.48550/ARXIV.2205.12255) Authors Parisi Aaron,Zhao Yao,Fiedel Noah Pub.date 2022]]></summary></entry><entry><title type="html">Self-Planning Code Generation with Large Language Models 论文粗读</title><link href="/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Self-Planning Code Generation with Large Language Models 论文粗读" /><published>2024-12-16T00:00:00+08:00</published><updated>2024-12-16T00:00:00+08:00</updated><id>/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="self-planning-code-generation-with-large-language-models-论文粗读">&lt;Self-Planning Code Generation with Large Language Models&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Self-Planning Code Generation with Large Language Models</span>                                                                               |
| —————————————————————— | ———————————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)">ACM Transactions on Software Engineering and Methodology </span><em><span style="background-color: rgb(243, 250, 244)">(10.1145/3672456)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Jiang Xue,Dong Yihong,Wang Lecheng,Fang Zheng,Shang Qiwei,Li Ge,Jin Zhi,Jiao Wenpin</span>                                                    |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023-06-30</span>                                                                                                                             |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<p>问题：</p>

<ul>
  <li>
    <p>LLM代码生成无法应对有复杂意图的任务</p>

    <ul>
      <li>解决方法：需要采用规划来分解复杂问题，并在实施之前安排解决方案步骤</li>
    </ul>
  </li>
  <li>
    <p>生成CoT的过程和生成代码的过程本质是相似的，直接将CoT应用于代码并不能减少难度</p>

    <ul>
      <li>解决方法：要专注实现问题的分解</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>思路：将规划引入到了代码生成中，以帮助模型理解复杂意图并降低问题解决难度</p>

<p><img src="/assets/posts_assets/QACCGZ7E.png" alt="" /></p>

<p>具体方法：</p>

<ul>
  <li>规划阶段：大型语言模型通过结合少量示例提示（包含细粒度的规划过程），从意图中规划出简洁的解决方案步骤</li>
  <li>实现阶段：模型在前面解决方案步骤的指导下（把计划加入prompt中），逐步生成代码</li>
</ul>

<p>训练方法：少样本实现规划能力，而不是标记数据（记意图-计划对），无需微调。</p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ol>
  <li>
    <p>性能提升：自规划代码生成在Pass\@1指标上实现了高达25.4%的相对提升，与思维链代码生成相比则实现了高达11.9%的提升</p>
  </li>
  <li>
    <p>根据人类评估，正确性、可读性和稳健性提升了代码质量</p>
  </li>
  <li>
    <p>规划能力：我们表明，自我规划是一种出现在足够大的大型语言模型上的涌现能力，但规划可以使大多数大型语言模型受益。</p>
  </li>
  <li>
    <p>最优：我们深入探讨了自我规划方法的几种变体，并证明我们设计的自我规划方法是这些变体中的最佳选择。<img src="/assets/posts_assets/6BX4DXWS.png" alt="" /></p>
  </li>
  <li>
    <p>泛化：我们验证了自我规划方法在多种编程语言（包括Python、Java、Go和JavaScript）上的有效性。</p>
  </li>
</ol>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>为什么多轮的效果不如单轮的</p>

    <ul>
      <li>由于大型语言模型在大量的拼接文本和代码上进行训练以预测下一个标记，因此大型语言模型可能存在截断问题，即它们无法精确控制其输出的终止。当使用计划来生成部分函数（通常是若干语句）时，很难定义截断规则。</li>
    </ul>
  </li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;Self-Planning Code Generation with Large Language Models&gt; 论文粗读 💡 Meta Data Title Self-Planning Code Generation with Large Language Models Journal ACM Transactions on Software Engineering and Methodology (10.1145/3672456) Authors Jiang Xue,Dong Yihong,Wang Lecheng,Fang Zheng,Shang Qiwei,Li Ge,Jin Zhi,Jiao Wenpin Pub.date 2023-06-30]]></summary></entry><entry><title type="html">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting 论文粗读</title><link href="/2024/12/15/MultiTool-CoT-GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting 论文粗读" /><published>2024-12-15T00:00:00+08:00</published><updated>2024-12-15T00:00:00+08:00</updated><id>/2024/12/15/MultiTool-CoT--GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/15/MultiTool-CoT-GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="multitool-cot-gpt-3-can-use-multiple-external-tools-with-chain-of-thought-prompting-论文粗读">&lt;MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting</span> |
| —————————————————————— | ———————————————————————————————————————————————- |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">()</span></em>                      |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Inaba Tatsuro,Kiyomaru Hirokazu,Cheng Fei,Kurohashi Sadao</span>                            |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | 2023                                                                                                                                           |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<ul>
  <li>
    <p>LLM 在各种推理任务上取得了令人瞩目的性能。</p>
  </li>
  <li>
    <p>外部工具注入推理过程的研究都集中于单个外部攻击解决LLM的单个问题，而没有一起解决不同的问题</p>

    <ul>
      <li>本文解决：多个外部工具、同时解决多个问题</li>
    </ul>
  </li>
  <li>
    <p>为了进一步提高性能，提出了MultiTool-CoT</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了MultiTool-CoT 交互式框架：利用CoT提示在推理过程中整合多种外部工具（计算器、知识检索器）（包含工具触发的推理）</p>

<p>训练方法：few-shot learning ，学习在适当的推理步骤中调用多个外部工具</p>

<p><img src="/assets/posts_assets/9PDWDS27.png" alt="" /></p>

<ul>
  <li>
    <p>指令包括：可用的外部工具、带有推理过程的少样本示例、待解决的问题</p>
  </li>
  <li>
    <p>工具触发器：«外部工具名称»</p>
  </li>
  <li>
    <p>工具触发的流程：</p>

    <ul>
      <li>在推理时如果生成了工具触发，则停止文本生成，</li>
      <li>然后从推理过程中提取外部工具的名称和工具的输入，</li>
      <li>然后执行工具，并将结果附加到推理过程末尾</li>
      <li>如果工具调用失败，则回退让GPT生成工具的输出</li>
    </ul>
  </li>
  <li>
    <p>答案：用额外的few-shot从最后一句输出映射到答案值</p>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>NumGLUE 的任务 2 数据集（该数据集需要数值推理和特定领域的知识），MultiTool-CoT 显著优于强大的基线模型，并取得了最先进的性能</li>
</ul>

<p><img src="/assets/posts_assets/TG94PG4C.png" alt="" /></p>

<p>error case:</p>

<ul>
  <li>不正确的推理过程（39%）</li>
  <li>无效的工具输入（35%）</li>
  <li>格式错误（11%）</li>
  <li>不正确的答案（15%）</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>这里的工具调用是如何实现停止的？（直接输出停止吗？）</p>

    <ul>
      <li>是检测到工具触发格式了就停止生成了。然后调用工具继续再生成</li>
    </ul>
  </li>
</ul>

<p>*</p>

<p>*</p>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting&gt; 论文粗读 💡 Meta Data Title MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting Journal  () Authors Inaba Tatsuro,Kiyomaru Hirokazu,Cheng Fei,Kurohashi Sadao Pub.date 2023]]></summary></entry><entry><title type="html">StructGPT 论文粗读</title><link href="/2024/12/14/StructGPT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="StructGPT 论文粗读" /><published>2024-12-14T00:00:00+08:00</published><updated>2024-12-14T00:00:00+08:00</updated><id>/2024/12/14/StructGPT%20%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/14/StructGPT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="structgpt论文粗读">&lt;StructGPT&gt;论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">StructGPT: A General Framework for Large Language Model to Reason over Structured Data</span>         |
| —————————————————————— | ——————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.18653/v1/2023.emnlp-main.574)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Jiang Jinhao,Zhou Kun,Dong Zican,Ye Keming,Zhao Xin,Wen Ji-Rong</span>                                |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                           |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p><strong>目的</strong>：以统一的方式提升大型语言模型 (LLMs) 在结构化数据上的推理能力</p>
  </li>
  <li>
    <p><strong>motivation</strong>：当前LLM在引入外部知识的时候，通常使用有结构的数据库，而数据库存放的数据通常是结构的，而LLM无法完全理解</p>

    <ul>
      <li>
        <p>直接解决方法：直接线性化（直接拼接成一长串句子）</p>

        <ul>
          <li>缺点：但是数据量很大的时候，不可能全部都直接假如到prompt中。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="问题描述">问题描述</h3>

<p>使用LLM解决基于结构化数据的复杂推理任务</p>

<p><strong>输入：</strong> 自然语言问题、结构化数据（知识图谱、表格、数据库）</p>

<p><strong>输出：</strong> 结果（自然语言或结构化表达式）</p>

<h3 id="解决思路">解决思路</h3>

<ul>
  <li>
    <p>引入专门的APi操作结构化的数据记录</p>

    <ul>
      <li>如何为特定任务设计合适的接口</li>
      <li>如何利用这些接口让LLMs进行推理</li>
    </ul>
  </li>
</ul>

<p>提出了 Iterative Reading and Reasoning 框架解决结构化数据的问答任务——Struct GPT</p>

<h3 id="iterative-reading-and-reasoning-框架">Iterative Reading and Reasoning 框架</h3>

<ul>
  <li>reading 读取：构建了专门的机构从结构化数据收集相关证据</li>
  <li>reasoning 推理：让LLM专注于收集到的信息的推理任务</li>
</ul>

<p>具体过程：invoking-&gt; linearzation -&gt; generation</p>

<h4 id="struct-api定义">struct API定义</h4>

<blockquote>
  <p>因为用LLM来结构化数据不好，所以作者自己设计了API而不是使用LLM</p>
</blockquote>

<ol>
  <li>
    <p>知识图谱：</p>

    <ul>
      <li>Extraction_Neighbor_Relations(e)</li>
      <li>Extract_Triples(e,{r})</li>
    </ul>
  </li>
  <li>
    <p>表格：</p>

    <ul>
      <li>Extract_Columns(T,{c})</li>
      <li>……</li>
    </ul>
  </li>
  <li>
    <p>数据库</p>

    <ul>
      <li>Extract_Table\&amp;Column_Name (D)</li>
      <li>……</li>
    </ul>
  </li>
</ol>

<h4 id="invoking">Invoking</h4>

<p>调用接口从结构化数据中提取相关信息，送到LLM中</p>

<h4 id="information-linearization">Information Linearization</h4>

<p>根据提取的信息，将其转换为可被大型语言模型理解的文本句子</p>

<p>每个结构定义一种线性化规则</p>

<p>来自知识图谱的信息:将其连接成一个长句子，并用特定的分隔符和边界符号标记。</p>

<p>对于表格：</p>

<p>例如“（第1行，年份，1896）”和“（第1行，城市，雅典）”。然后，对于每一行，我们将行索引提取到句首，并在三元组中省略行索引，以组成简化的句子，例如“第1行：（年份，1896），（城市，雅典）”。对于多行数据，我们通过特殊的分隔符将它们连接成一个长句子。</p>

<h4 id="llm-for-generation">LLM for Generation</h4>

<p>有两种prompt：</p>

<ul>
  <li>筛选数据：从线性的数据中根据问题筛选有用的数据</li>
  <li>给出答案：生成最终答案（可以是自然语言也可以是形式化语言（SQL））</li>
</ul>

<h4 id="举例解释流程">举例解释流程</h4>

<p>以知识图谱为例：</p>

<ol>
  <li>根据问题 query 中提到的实体 搜索调用接口Extract_Neighbor_Relation、Extract_Triples</li>
  <li>然后线性化</li>
  <li>利用LLM根据问题选择有用的关系</li>
  <li>调用Extract_Triples收集头实体 eT 和 {r} 中关系的相关三元组</li>
  <li>然后线性化此信息</li>
  <li>LLM应评估当前信息是否足以回答问题，然后，LLM将根据评估结果采取相应操作（停止或迭代）</li>
  <li>使用大型语言模型选择最相关的三元组，其尾实体将被视为最终答案</li>
</ol>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>在8个数据集上的实验结果表明，我们的方法可以有效提升LLMs在零样本和少样本设置下对结构化数据的推理性能，甚至可以与具有竞争力的全数据监督微调方法相媲美。</p>

<p>在KGQA、TableQA和text-to-SQL任务中，与在零样本设置下直接使用ChatGPT相比，我们的方法在WebQSP上实现了11.4%的Hits\@1提升，在TabFact上实现了4.2%的准确率提升，在Spider上实现了4.7%的执行准确率提升。</p>

<p><img src="/assets/posts_assets/42LCZJPX%202.png" alt="" /></p>

<p><img src="/assets/posts_assets/KI6GJZ8H.png" alt="" /></p>

<p><img src="/assets/posts_assets/Y3L54F4W.png" alt="" /></p>

<p>错误：</p>

<ul>
  <li>选择错误：相关信息不是LLM选的</li>
  <li>推理错误：有相关信息但是LLM推理错误</li>
  <li>生成答案格式错误：无法被结果解析识别（数据集不同很难控制生成对应的格式）</li>
  <li>幻觉问题</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>是什么情况下few-shot比zero-shot更差的？</li>
  <li>这种固定的pipeline可能无法让LLM选择自己要的数据</li>
  <li>这种自己定义数据的线性化，是不是太死板了，他说用LLM结构化不太好，但是后面有人做了，是可以的。</li>
  <li>总体来说并不算是真正的工具学习，因为不是 LLM 自主调用的，而是固定的步骤。</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;StructGPT&gt;论文粗读 💡 Meta Data Title StructGPT: A General Framework for Large Language Model to Reason over Structured Data Journal  (10.18653/v1/2023.emnlp-main.574) Authors Jiang Jinhao,Zhou Kun,Dong Zican,Ye Keming,Zhao Xin,Wen Ji-Rong Pub.date 2023]]></summary></entry><entry><title type="html">ChatCoT 论文粗读</title><link href="/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="ChatCoT 论文粗读" /><published>2024-12-14T00:00:00+08:00</published><updated>2024-12-14T00:00:00+08:00</updated><id>/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="chatcot论文粗读">&lt;ChatCoT&gt;论文粗读</h1>

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models</span>             |
| —————————————————————— | ———————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.18653/v1/2023.findings-emnlp.985)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Chen Zhipeng,Zhou Kun,Zhang Beichen,Gong Zheng,Zhao Xin,Wen Ji-Rong</span>                                |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                               |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<p>现有的问题：</p>

<p>CoT的生成过程是一次性的，在中间步骤中使用工具将需要对其进行打断，从而损害生成过程的连续性</p>

<p>工具的调用会打断CoT的进程</p>

<ul>
  <li>
    <p>现有的解决方法：</p>

    <ul>
      <li>
        <p>依赖LLM预先安排工具使用计划以供后序执行</p>

        <ul>
          <li>缺点：生成计划后无法与工具交互，及时看到明显的错误也无法纠正，存在误差累积</li>
        </ul>
      </li>
      <li>
        <p>设计针对特定任务的固定操作</p>

        <ul>
          <li>缺点：必须频繁的在LLM推理和执行行动之间切换，损害了CoT之间的连贯性（就比如CoT下一步必须是调工具）</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>作者要寻找一种更统一的方法整合CoT和tool</p>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="解决思路">解决思路</h3>

<ul>
  <li>
    <p>将LLM的工具的操作视为LLM与工具之间的交互。</p>
  </li>
  <li>
    <p>将LLM和工具之间的交互过程建模为多轮对话，利用LLM出色的对话能力来操作工具</p>

    <ul>
      <li>在每一轮中，LLM可以在需要时自由地与工具交互，否则自行进行推理</li>
      <li>对话持续进行直到LLM得出最终答案。</li>
    </ul>
  </li>
  <li>
    <p>针对问题：在此过程中，由于基于对话的LLM可以很好地理解多轮上下文，它们可以在整个对话中遵循思维链，并自然地相应地调用工具，从而保持推理过程的连续性。</p>
  </li>
</ul>

<p>所以作者提出了ChatCoT，一种用于基于聊天的LLM的工具增强型思维推理策略。</p>

<h3 id="初始设定">初始设定</h3>

<h4 id="任务定义">任务定义</h4>

<p>专注于提升LLM在复杂任务上的推理能力（解决数学竞赛问题）</p>

<p>任务描述：</p>

<ul>
  <li>问题陈述：复杂问题的背景和描述</li>
  <li>解答文本：获得答案单独详细解决过程</li>
  <li>答案</li>
</ul>

<p>任务目的：给定问题陈述最终生成准确答案</p>

<h4 id="工具集">工具集</h4>

<ul>
  <li>
    <p>计算器：给定数据表达式可以化简</p>

    <ul>
      <li>实现：用SymPy python库</li>
    </ul>
  </li>
  <li>
    <p>方程求解器：给定方程组和未知变量，可以求解</p>

    <ul>
      <li>实现：用SymPy python库</li>
    </ul>
  </li>
  <li>
    <p>检索器：给查询提取相关信息</p>

    <ul>
      <li>用SimCSE</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/posts_assets/MSM9TUAY.png" alt="" /></p>

<h3 id="具体方法">具体方法</h3>

<blockquote>
  <p>工具学习的训练方法：In-context learning</p>
</blockquote>

<p>通过agent（预定义的规则）与LLM的对话来实现推理和工具调用</p>

<p>整体分两个阶段：</p>

<ul>
  <li>
    <p>给LLM输入关于工具、任务和推理格式的知识来初始化对话的早期轮次(对话形式）</p>
  </li>
  <li>
    <p>迭代一个专门设计的<strong>工具增强型推理</strong>步骤(对话），直到获得答案</p>

    <ul>
      <li>在每次迭代中，基于当前的结果，我们首先利用大型语言模型进行推理，然后通过大型语言模型选择合适的工具，最后执行所选工具以获得当前步骤的中间结果。</li>
      <li>推理：LLM根据示例可以将推理分解为多轮对话，而无需专门的提示或指令。直到需要工具功能才停止</li>
      <li>工具选择：通过prompt提示让LLM选择（问LLM用什么工具如果回复不使用工具就继续推理）</li>
      <li>工具执行：给定选定的工具和参数，然后执行，可能结果无法让LLM满意，我们也可以增加几轮反馈，让LLM判断结果是否有用，然后重新使用该工具获取新结果</li>
    </ul>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>在两个复杂的推理基准数据集上进行了实验，即MATH 和HotpotQA 。</p>

<p>ChatCoT在MATH上取得了非常有希望的性能，与SOTA基线方法相比，平均性能相对提高了7.9%。</p>

<p><img src="/assets/posts_assets/J258MYBV.png" alt="" /></p>

<p><img src="/assets/posts_assets/YV2RNQDC.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>整体的prompt流程具体是什么样子？</li>
  <li>agent是如何搞的</li>
  <li>为什么比其他的CoT+Tool好呢？</li>
  <li>读一下其他CoT+Tool</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;ChatCoT&gt;论文粗读 💡 Meta Data Title ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models Journal  (10.18653/v1/2023.findings-emnlp.985) Authors Chen Zhipeng,Zhou Kun,Zhang Beichen,Gong Zheng,Zhao Xin,Wen Ji-Rong Pub.date 2023]]></summary></entry><entry><title type="html">DSPY COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES论文学习</title><link href="/2024/12/08/DSPY-COMPILING-DECLARATIVE-LANGUAGE-MODEL-CALLS-INTO-SELF-IMPROVING-PIPELINES%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0.html" rel="alternate" type="text/html" title="DSPY COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES论文学习" /><published>2024-12-08T00:00:00+08:00</published><updated>2024-12-08T00:00:00+08:00</updated><id>/2024/12/08/DSPY%20COMPILING%20DECLARATIVE%20LANGUAGE%20%20MODEL%20CALLS%20INTO%20SELF-IMPROVING%20PIPELINES%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0</id><content type="html" xml:base="/2024/12/08/DSPY-COMPILING-DECLARATIVE-LANGUAGE-MODEL-CALLS-INTO-SELF-IMPROVING-PIPELINES%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0.html"><![CDATA[<h1 id="dspy-compiling-declarative-language-model-calls-into-self-improving-pipelines论文学习">DSPY COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES论文学习</h1>

<h2 id="不懂的">不懂的</h2>

<!---more-->
<h3 id="teleprompter-在-dspy-编译器中的作用"><strong>Teleprompter 在 DSPy 编译器中的作用</strong></h3>

<p>在 DSPy 编程模型中，<strong>Teleprompter（提示器）</strong> 是一种核心组件，负责模块化优化过程。具体来说，Teleprompter 是通用的优化策略，用于指导 DSPy 编译器如何让各个模块从数据中学习，以提升整个程序的质量或降低其运行成本。以下是对 Teleprompter 的详细解释：</p>

<ol>
  <li><strong>定义与功能</strong>
    <ul>
      <li><strong>通用优化策略</strong>：Teleprompter 不局限于特定的优化方法，而是提供了一套通用的框架，可以应用于多种优化需求，如提升模型性能、减少计算资源消耗等。</li>
      <li><strong>决策指导</strong>：它决定了每个 DSPy 模块应如何从输入数据中学习。这包括选择合适的学习方法（如少样本学习、微调等）以及如何生成和利用示例数据来改进模块的行为。</li>
    </ul>
  </li>
  <li><strong>工作机制</strong>
    <ul>
      <li><strong>模块学习</strong>：Teleprompter 通过分析模块的示例轨迹（example traces），来理解模块在不同输入下的表现。这些轨迹包含模块在处理特定任务时的详细操作步骤和输出结果。</li>
      <li><strong>构建提示或微调模型</strong>：基于这些轨迹，Teleprompter 可以生成有效的少样本提示（few-shot prompts），帮助模块在未来处理类似任务时表现得更好。此外，它还可以指导对小型语言模型（LMs）的微调，使其更适应管道中各个步骤的需求。</li>
    </ul>
  </li>
  <li><strong>模块化优势</strong>
    <ul>
      <li><strong>高度模块化</strong>：由于 Teleprompter 是模块化设计的，它可以独立于具体的优化目标进行扩展和调整。这意味着可以灵活地应用不同的优化策略，而不需要对整个编译器进行大幅修改。</li>
      <li><strong>适应多种任务</strong>：无论是提示优化、模型微调、推理增强还是数据增强，Teleprompter 都能够根据具体任务需求，选择最合适的优化方法。</li>
    </ul>
  </li>
  <li><strong>自动化优化流程</strong>
    <ul>
      <li><strong>自动映射</strong>：Teleprompter 帮助编译器自动将声明式模块映射为高质量的优化组合。这包括提示生成、模型微调、推理过程的优化等，使得整个自然语言处理管道能够高效协同工作。</li>
      <li><strong>自我改进</strong>：通过不断地模拟和优化，Teleprompter 使得 DSPy 程序能够自我改进，逐步提升其在特定任务上的表现。</li>
    </ul>
  </li>
  <li><strong>类比与启发</strong>
    <ul>
      <li><strong>类比 PyTorch 的优化器</strong>：类似于 PyTorch 中用于调整模型参数的优化器（如 SGD、Adam 等），Teleprompter 也是一种用于优化 DSPy 模块行为的工具。不过，Teleprompter 更加专注于如何利用数据和示例来指导模块的学习过程。</li>
    </ul>
  </li>
</ol>

<p><strong>总结</strong>
Teleprompter 在 DSPy 编译器中扮演着至关重要的角色，通过提供通用的优化策略，指导各个模块如何从数据中有效学习，从而自动优化整个 DSPy 程序的性能和效率。其模块化和自动化的设计，使得 DSPy 编程模型能够灵活适应多种自然语言处理任务，并持续提升其处理能力。</p>

<h2 id="摘要">摘要</h2>

<p>背景：</p>

<p>当前的解决复杂问题，需要将多个语言模型堆叠成管道单的技术来解决，然后每个 LLM 负责一个特定的任务。一般情况下设计 prompt 模版让 LLM 负责特定的任务</p>

<p>问题：</p>

<ol>
  <li>需要专家人工设计 prompt</li>
  <li>设计的 prompt 依赖于经验和试错，面对复杂任务时会出错</li>
  <li>设计的 prompt 通用性较差，无法迁移到新的任务和场景上。</li>
  <li>Prompt 是静态的，缺乏灵活的机制</li>
  <li>用 prompt 可能让多个 LLM 堆叠的性能下降</li>
</ol>

<p>工作:</p>

<p>提出 DSPy（Declarative Self-Improvement Pipelines）模块: 将 LM 的工作流转换为 text transformation graph 文本变换图来实现对复杂任务的处理</p>

<blockquote>
  <p>这些图实际上是 <strong>命令式计算图（imperative computation graphs）</strong>，其中语言模型（LM）通过声明式的模块调用。</p>
</blockquote>

<p>解释：</p>

<ul>
  <li>DSPy 模块具有<strong>参数化</strong>特性，可以通过创建和收集示例来学习- 如何应用 <strong>prompting</strong>、<strong>微调（finetuning）</strong>、<strong>数据增强（augmentation）</strong> 和 <strong>推理（reasoning）</strong> 等技术的组合。</li>
  <li>DSPy 允许用户通过编写简单的程序来定义 LM 管道，这些管道能够执行复杂的任务，如<strong>数学问题推理</strong>、<strong>多跳检索</strong>、<strong>复杂问题回答</strong>和<strong>控制智能体循环</strong>等。</li>
  <li>DSPy 中的程序通过一个<strong>编译器</strong>进行优化，能够在几分钟内自动调整管道，以最大化某个指定的指标（如任务表现）。</li>
</ul>

<p>结果：</p>

<ul>
  <li>
    <p>比<strong>少量样本提示（few-shot prompting）</strong> 提高了 25% 到 65% 的表现，并且相比 <strong>专家创建的示例</strong> 提高了 5% 到 46%（具体数据取决于不同的模型和任务）。</p>
  </li>
  <li>
    <p>DSPy 程序即使编译到较小的开源语言模型（如 770M 参数的 T5 和 llama2-13b-chat）上，表现也能与依赖专家编写提示链的专有 GPT-3.5 方法相媲美。</p>
  </li>
</ul>

<h2 id="引言">引言</h2>

<h3 id="背景">背景</h3>

<p>多阶段管道和 agent 发展：将复杂任务分解为对多个可以调用 LM 任务</p>

<h3 id="问题">问题</h3>

<ol>
  <li>LLM 对 prompt 非常敏感，并且在多个 LM 的系统中更敏感</li>
  <li>当前 LM 调用一般使用 prompt 模版来实现
    <ol>
      <li>这种 prompt 无法扩展泛化不能用到其他的 pipeline 上</li>
    </ol>
  </li>
</ol>

<h3 id="工作">工作</h3>

<h5 id="引入">引入</h5>

<p>为了实现更系统化的 AI pipeline设计方法，我们引入了 DSPy 编程模块</p>

<ul>
  <li>不用自由形式的 strings，而是用类似编程语言</li>
  <li>然后编译器就可以自动从中生成 LM 调用策略和 prompt</li>
</ul>

<p>想法来源：</p>

<p>受到了<strong>神经网络抽象的启发</strong></p>

<ul>
  <li><strong>通用层的模块化组合</strong>：在构建复杂的神经网络架构时，许多通用的层（如卷积层、全连接层等）可以以模块化的方式进行组合。类似地，DSPy 也允许将各种处理步骤（例如提示生成、数据预处理等）作为模块组合起来，构建复杂的语言模型管道。</li>
  <li><strong>优化器而非手动调优</strong>：神经网络的训练不再依赖于人工手动调整每个模型参数，而是通过使用优化算法（如梯度下降）来自动调整网络权重。同样，DSPy 的编译器通过自动化的优化策略，减少了人工设计和调优每个模型的需求</li>
</ul>

<h5 id="实现">实现</h5>

<h6 id="dspy-programming-model">DSPy programming model</h6>

<ol>
  <li>将 prompt 转换为具有自然语言类型签名的声明模块
    <ol>
      <li>DSPy 模块类似于神经网络的层，是适应任务的组件，能够抽象出各种文本转换任务，例如回答问题或总结论文。</li>
      <li>对每个模块进行参数化，能够通过在管道中反复引导有用的示范来学习其预期的行为。</li>
    </ol>
  </li>
</ol>

<blockquote>
  <p>pipeline 构建：</p>
  <ol>
    <li>声明所需模块</li>
    <li>使用的逻辑流来逻辑地连接模块</li>
  </ol>
</blockquote>

<h6 id="dspy-compiler">DSPy compiler</h6>
<ol>
  <li><strong>编译器的作用</strong>：
    <ul>
      <li><strong>优化 DSPy 程序</strong>：提升程序的质量或降低其成本。</li>
      <li><strong>自动映射</strong>：
        <ul>
          <li><strong>高质量组合</strong>：编译器自动将声明式模块映射为高质量的提示（prompting）、微调（finetuning）、推理（reasoning）和增强（augmentation）的组合，从而优化整个管道的性能。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>编译器的输入</strong>：
    <ul>
      <li><strong>程序</strong>：待优化的 DSPy 程序。</li>
      <li><strong>训练输入</strong>：少量带有可选标签的训练数据。</li>
      <li><strong>验证指标</strong>：用于评估优化效果的标准。</li>
    </ul>
  </li>
  <li><strong>训练过程</strong>：
    <ul>
      <li><strong>程序模拟</strong>：编译器在给定的输入上模拟程序的不同版本。</li>
      <li><strong>自我改进</strong>：通过引导模块生成示例轨迹，编译器利用这些轨迹构建有效的少样本提示（few-shot prompts）或对管道的步骤进行小型语言模型（LMs）的微调（finetuning）。</li>
      <li><strong>模块化优化</strong>：
        <ul>
          <li><strong>Teleprompters</strong>：编译器使用称为 teleprompters 的通用优化策略来决定模块如何从数据中学习。这些策略是高度模块化的，能够灵活应用于不同的优化需求。</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h6 id="评估">评估</h6>

<p>超过专家编写 prompt 的性能</p>

<p>数学语言问题（GMS8K；Cobbe等，2021）和多跳问答</p>

<h5 id="结果">结果</h5>

<ul>
  <li>表明简单的DSPy程序在性能上优于使用手工设计提示的系统，</li>
  <li>同时也使我们的程序能够有效地使用更小、更高效的语言模型。</li>
</ul>

<h2 id="相关工作">相关工作</h2>

<p>这一段介绍了 DSPy 编程模型的背景和灵感来源，并回顾了与之相关的研究和工作。主要包括以下几个方面：</p>

<h3 id="1-灵感来源">1. <strong>灵感来源</strong>：</h3>

<ul>
  <li>DSPy 的灵感来自于 <strong>Torch</strong>, <strong>Theano</strong>, <strong>Chainer</strong> 等深度学习框架的工作，这些框架通过提供强大的抽象，推动了深度学习的发展。</li>
  <li>类似的转变也正在发生在 <strong>语言模型（LM）管道</strong> 的发展上，DSPy 的目标是为 <strong>基础模型编程（foundation model programming）</strong> 提供一个坚实的概念框架和编程抽象。</li>
  <li>DSPy 借鉴了 <strong>可微编程（differentiable programming）</strong> 的思想，但应用于语言模型调用，而非神经网络，并且在语法上借鉴了 <strong>PyTorch</strong> 的元素。</li>
</ul>

<h3 id="2-in-context-learning-及其发展">2. <strong>In-context learning 及其发展</strong>：</h3>

<ul>
  <li><strong>In-context learning（上下文学习）</strong> 是基础模型编程的关键机制，随着研究的发展，越来越多的工作表明，尤其是在 <strong>指令调优（instruction tuning）</strong> 上，我们可以通过 <strong>prompting</strong>（提示）来引导语言模型表现出复杂的行为。</li>
  <li>这些方法依赖于语言模型进行任务指定的行为，而不再依赖于传统的手工构建的启发式规则或任务特定的标注（如 <strong>weak supervision</strong>），语言模型已经能够替代这些手动构建的任务特定方法。</li>
</ul>

<h3 id="3-语言模型管道和工具的应用">3. <strong>语言模型管道和工具的应用</strong>：</h3>

<ul>
  <li>当前，语言模型管道通常会调用各种工具，包括 <strong>检索模型</strong>、<strong>多模态基础模型</strong> 和更传统的工具（如 <strong>API</strong> 和 <strong>计算器</strong>）。许多工具包（如 <strong>LangChain</strong>, <strong>Semantic Kernel</strong>, <strong>LlamaIndex</strong> 等）已经被开发出来，用于简化这些管道的搭建和应用。</li>
  <li>这些工具包通常依赖于手工编写的 <strong>prompt模板</strong> 来表达任务特定的行为，这就是 DSPy 试图解决的问题。DSPy 提供了一种更系统化的方式，避免了手动调整模板的复杂性。</li>
</ul>

<h3 id="4-离散优化和强化学习的应用">4. <strong>离散优化和强化学习的应用</strong>：</h3>

<ul>
  <li>当前有一些研究应用了 <strong>离散优化</strong> 和 <strong>强化学习（RL）</strong> 来寻找有效的提示，通常是针对单一的语言模型调用（例如 <strong>Guo et al., 2023</strong> 等）。然而，DSPy 希望将这一领域的技术推广，提供一个更通用的框架，允许从高层次的声明性签名中优化任意管道，并通过引导高质量的多阶段演示和约束来实现这一目标。</li>
  <li>在此框架中，DSPy 编译器可能会应用 <strong>模型选择技术</strong>（如交叉验证）或使用 <strong>强化学习</strong> 和 <strong>语言模型反馈</strong> 进行优化，甚至可能结合 <strong>贝叶斯超参数优化方法</strong>。</li>
</ul>

<h3 id="5-dspy-编程模型的目标与贡献">5. <strong>DSPy 编程模型的目标与贡献</strong>：</h3>

<ul>
  <li>本文旨在 <strong>展示 DSPy 编程模型的动机</strong>，并报告应用 DSPy 编译器后的新实证结果。其灵感来自于早期的研究工作，如 <strong>Bergstra et al., 2010; 2013</strong> 和 <strong>Paszke et al., 2019</strong>，这些研究通过基准数据和定性指标支持各自的编程模型。</li>
  <li>本文重点展示了 <strong>DSPy 编程模型</strong> 和其编译器如何帮助构建 <strong>出色的语言模型系统</strong>，无需手工编写提示字符串，而是通过模块化的单元来构建，从而打开了在 <strong>高级抽象层次</strong> 上系统性探索丰富设计空间的大门。</li>
</ul>

<h2 id="dspy-programming-modeldspy-编程模型">DSPy programming model（DSPy 编程模型）</h2>

<p>我们提出了 DSPy，它将语言模型视为文本生成的抽象设备，并优化其在任意计算图中的使用。</p>

<p>DSPy 程序用 Python 表达：每个程序接收任务输入（例如，要回答的问题或要总结的论文），并在一系列步骤后返回输出（例如，答案或摘要）。</p>

<p>DSPy 为自动优化贡献了三个抽象：签名、模块和提词器。</p>

<ul>
  <li>签名抽象了模块的输入/输出行为；</li>
  <li>模块替代现有的手动提示技术，可以在任意管道中组合；</li>
  <li>提词器优化管道中的所有模块，以最大化某个指标。</li>
</ul>

<h3 id="自然语言签名natural-language-signatures">自然语言签名（Natural language signatures）</h3>

<p>使用自然语言类型签名，抽象 prompt 和 fine-tuning</p>

<p>与 prompt 不同，DSPy 程序使用自然语言签名将工作分配给 LLM。</p>

<p>自然语言类型签名：</p>

<ul>
  <li>自然语言类型的函数声明，描述了输入和输出，而不是提示 LM 来实现该操作。</li>
  <li>形式：一个元组（包含输入字段和输出字段）
    <ul>
      <li>一个字段由在字段名称和可选的元数据组成</li>
      <li><strong>在使用过程中 DSPy 编译器会根据字段名称推断字段的对应的内容（ICL）</strong></li>
    </ul>
  </li>
</ul>

<h3 id="模块">模块</h3>

<p>自然语言签名定义了一个接口，而没有实现，下面就介绍如何实例化模块。</p>

<p>使用签名，返回一个具有该签名的函数
<img src="assets/posts_assets/Pasted%20image%2020241210145143.png" alt="" /></p>

<h4 id="预测模块">预测模块</h4>

<ul>
  <li>总体功能
    <ul>
      <li>是签名和模型之间的桥梁</li>
      <li>存储提供的签名、可选的语言模型、一个用于提示的演示列表</li>
    </ul>
  </li>
  <li>工作：
    <ul>
      <li>接受输入字段的关键字参数</li>
      <li>利用输入字段过构造 prompt，并包括一些示范</li>
      <li>最后调用指定的 LM 生成输出</li>
      <li>解析输出字段，将语言模型结果转换为最终的输出</li>
    </ul>
  </li>
  <li>编译模式
    <ul>
      <li>
        <ul>
          <li>当 <strong>Predict</strong> 检测到它正处于“编译模式”时，它会<strong>内部追踪输入和输出的记录</strong>（input/output traces）。这些记录用于帮助 <strong>teleprompter</strong>（优化器）在后续的引导式学习过程中生成有用的示范（demonstrations）。</li>
        </ul>
      </li>
      <li>这个过程类似于通过示范和优化来增强模型的效果，从而提升任务执行的精度和效率。</li>
    </ul>
  </li>
</ul>

<h4 id="其他内置模块">其他内置模块</h4>

<ul>
  <li><strong>将 prompt 转换为支持任何签名的模块化函数，这与任务特定细节</strong></li>
  <li>模块里内置的是（方法），而签名定义的是任务</li>
</ul>

<h4 id="参数化-将上面介绍的参数化">参数化 (将上面介绍的参数化)</h4>

<p>参数化：DSPy 在构建和使用语言模型时，通过<strong>参数化</strong>来细化和控制模型的行为。换句话说，DSPy 允许对每个语言模型调用进行精细的定制，以满足特定任务的需求。</p>

<p><strong>参数化的三个关键要素</strong>： 要使语言模型正确执行一个特定的任务或签名，DSPy 需要传递三个重要的参数：</p>

<ul>
  <li>
    <p><strong>(1) 特定的语言模型（LM）</strong>： 这里，DSPy 需要明确调用哪个语言模型。不同的语言模型可能具有不同的能力和行为。例如，某些模型可能擅长生成文本，另一些可能在推理或翻译任务上更为有效。</p>

    <p>举例来说，如果任务是生成一段文章的摘要，DSPy 可能选择一个大规模的文本生成模型；如果任务是代码生成，可能选择一个训练过编程语言的特定模型。</p>
  </li>
  <li>
    <p><strong>(2) 提示指令和字段前缀（Prompt Instructions）</strong>： 对于每个任务，DSPy 需要明确地传达给模型它应该如何执行。例如，如果任务是翻译，提示指令可能是“Translate English to French”。同时，字段的前缀（字段名如 “question” 和 “answer”）会提供更多关于任务类型的上下文，以确保模型能够理解输入的格式和输出的要求。</p>

    <p>例如：</p>

    <ul>
      <li>输入字段：“question: What is the capital of France?”</li>
      <li>输出字段：“answer: ”</li>
    </ul>

    <p>DSPy 会使用这些字段来生成任务的提示，如“Question: What is the capital of France?” 然后根据输入的“question”字段生成“answer”的输出。</p>
  </li>
  <li>
    <p><strong>(3) 演示示例（Demonstrations）</strong>： 最重要的一部分是<strong>演示示例</strong>。这些示例是 DSPy 用来指导语言模型生成正确输出的数据。演示示例提供了任务的具体表现形式，可以用来训练模型或作为少量提示（few-shot prompts）引导模型在没有完全微调的情况下学习。</p>

    <ul>
      <li>对于冻结的模型（没有进一步训练的模型），演示示例作为提示直接传递给模型，帮助模型理解如何在特定上下文中生成正确的输出。</li>
      <li>对于需要微调的模型，演示示例可以作为训练数据，帮助模型学习任务的特定行为。</li>
    </ul>
  </li>
</ul>

<p><strong>作者的主要研究在于：</strong></p>

<ul>
  <li>
    <p><strong>自动生成和选择有用的演示</strong>： DSPy 的关键优势在于能够自动生成和选择有用的演示示例。这使得用户能够为模型任务提供高质量的“少量示例”，而不必手动编写或收集大量的训练数据。通过从实际使用中不断“启动”（bootstrapping）新的演示，DSPy 可以让语言模型不断学习新的行为。</p>
  </li>
  <li>
    <p>[I] 我们可以专注于模型该怎么去做，而不是专注于生成有效示例  [created:: 2024-12-10]</p>
  </li>
</ul>

<h4 id="示例">示例</h4>

<p><strong>RAG 系统示例：</strong></p>

<p>假设你想要创建一个基于“检索增强生成”（RAG）的系统，该系统结合了<strong>检索</strong>和<strong>生成</strong>的步骤来回答问题。具体来说，RAG 系统从数据库中检索相关信息（context），然后基于这些信息生成答案。</p>

<p>以下是 RAG 系统的代码示例：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RAG</span><span class="p">(</span><span class="n">dspy</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_passages</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="c1"># 'Retrieve'模块会使用用户的默认检索设置，除非被覆盖。
</span>        <span class="n">self</span><span class="p">.</span><span class="n">retrieve</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">Retrieve</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">num_passages</span><span class="p">)</span>
        <span class="c1"># 'ChainOfThought'模块：根据检索到的context和问题生成答案。
</span>        <span class="n">self</span><span class="p">.</span><span class="n">generate_answer</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">ChainOfThought</span><span class="p">(</span><span class="sh">"</span><span class="s">context, question -&gt; answer</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">question</span><span class="p">):</span>
        <span class="c1"># 使用检索模块来获取问题的相关文档（passages）。
</span>        <span class="n">context</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">retrieve</span><span class="p">(</span><span class="n">question</span><span class="p">).</span><span class="n">passages</span>
        <span class="c1"># 使用ChainOfThought模块来根据检索到的上下文和问题生成答案。
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">generate_answer</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span> <span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">)</span>
</code></pre></div></div>

<p>示例使用：</p>

<p>用户可以通过简单的调用来使用该系统：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">RAG</span><span class="p">()(</span><span class="sh">"</span><span class="s">Where is Guaraní spoken?</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>这行代码将会使用 <code class="language-plaintext highlighter-rouge">RAG</code> 模块来回答“Where is Guaraní spoken?”这个问题，具体的操作流程是：首先检索与问题相关的文档，然后使用 <code class="language-plaintext highlighter-rouge">ChainOfThought</code> 来生成答案。</p>

<h5 id="模块化的好处">模块化的好处：</h5>

<ul>
  <li>
    <p><strong>模块化</strong>：该系统清晰地分为两个独立的模块：一个用于检索相关信息，另一个用于基于检索到的信息生成答案。这种模块化设计使得每个部分可以独立地进行开发、测试和优化。</p>
  </li>
  <li>
    <p><strong>灵活的组合</strong>：用户可以根据不同的需求替换模块。例如，<code class="language-plaintext highlighter-rouge">ChainOfThought</code> 可以替代基本的 <code class="language-plaintext highlighter-rouge">Predict</code> 模块，用来生成更复杂的答案。甚至可以根据不同的任务（例如搜索查询生成）调整模块的功能。</p>
  </li>
</ul>

<h5 id="任务定制">任务定制：</h5>

<p>通过调整签名（signature），你可以改变系统的行为。例如，如果使用签名 <code class="language-plaintext highlighter-rouge">"context, question -&gt; search query"</code>，系统将不再生成答案，而是生成一个搜索查询。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">self</span><span class="p">.</span><span class="n">generate_search_query</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">ChainOfThought</span><span class="p">(</span><span class="sh">"</span><span class="s">context, question -&gt; search query</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>这会将任务从回答问题变为生成搜索查询。这样，用户可以灵活地在不同任务之间切换。</p>

<h3 id="提示器">提示器</h3>

<p>在编译 DSPy 程序时，我们通常会调用一个提词器，它是一个<strong>优化器</strong>，接收程序、训练集和指标，并返回一个新的优化程序。不同的提词器（第 4 节）采用不同的优化策略。</p>

<ul class="task-list">
  <li class="task-list-item">
    <p><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />DSPy要人工定义管道,我们可不可以自动生成管道，让 AI 定义 pipieline，这样的 pipeline 在复杂、多变的情况下更好，减少了人工干预的需要  [created:: 2024-12-10]  [completion:: 2024-12-11]</p>
  </li>
  <li class="task-list-item">训练数据：
    <ul>
      <li>小型训练集</li>
      <li>仅使用输入数据，并不需要完整中间步骤的标签，（除非对于评估模型性能的度量标准有用）
        <ul>
          <li>减少构建一个新 pipeline 的时候需要重新标注数据</li>
        </ul>
      </li>
    </ul>
  </li>
  <li class="task-list-item">评估指标：
    <ul>
      <li>简单的指标: EM、F 1</li>
      <li>复杂的指标，平衡多个关注点</li>
    </ul>
  </li>
  <li class="task-list-item">提示器可以由 teacher 模型组成
    <ul>
      <li>用 teacher 模型生成适合的演示样例，这样可以提供一些无标签的数据进行训练.</li>
    </ul>
  </li>
</ul>

<h4 id="示例-1">示例</h4>

<h5 id="rag">RAG</h5>

<ul>
  <li>展示了如何使用一个小型的问答训练集和精确匹配指标来优化RAG模块。</li>
</ul>

<p>代码逐行解释：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Small training set with only questions and final answers.
</span><span class="n">qa_trainset</span> <span class="o">=</span> <span class="p">[</span><span class="n">dspy</span><span class="p">.</span><span class="nc">Example</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="sh">"</span><span class="s">What is the capital of France?</span><span class="sh">"</span><span class="p">,</span> <span class="n">answer</span><span class="o">=</span><span class="sh">"</span><span class="s">Paris</span><span class="sh">"</span><span class="p">)]</span>

 <span class="c1"># The teleprompter will bootstrap missing labels: reasoning chains and retrieval contexts.
</span><span class="n">teleprompter</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">BootstrapFewShot</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">dspy</span><span class="p">.</span><span class="n">evaluate</span><span class="p">.</span><span class="n">answer_exact_match</span><span class="p">)</span>
<span class="n">compiled_rag</span> <span class="o">=</span> <span class="n">teleprompter</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="nc">RAG</span><span class="p">(),</span> <span class="n">trainset</span><span class="o">=</span><span class="n">qa_trainset</span><span class="p">)</span>
</code></pre></div></div>

<p>第1-2行：定义训练集</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">qa_trainset</span> <span class="o">=</span> <span class="p">[</span><span class="n">dspy</span><span class="p">.</span><span class="nc">Example</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="sh">"</span><span class="s">What is the capital of France?</span><span class="sh">"</span><span class="p">,</span> <span class="n">answer</span><span class="o">=</span><span class="sh">"</span><span class="s">Paris</span><span class="sh">"</span><span class="p">)]</span>
</code></pre></div></div>

<ul>
  <li><strong>解释</strong>：
    <ul>
      <li>创建了一个小型的训练集 <code class="language-plaintext highlighter-rouge">qa_trainset</code>，其中包含一个问答对。</li>
      <li>每个 <code class="language-plaintext highlighter-rouge">dspy.Example</code> 包含 <code class="language-plaintext highlighter-rouge">question</code>（问题）和 <code class="language-plaintext highlighter-rouge">answer</code>（答案）两个字段。</li>
      <li>这里的训练集非常小，仅包含一个示例，但DSPy设计允许在少量数据下仍能有效工作。</li>
    </ul>
  </li>
</ul>

<p>第4-6行：引导和编译管道</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">teleprompter</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">BootstrapFewShot</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">dspy</span><span class="p">.</span><span class="n">evaluate</span><span class="p">.</span><span class="n">answer_exact_match</span><span class="p">)</span>
<span class="n">compiled_rag</span> <span class="o">=</span> <span class="n">teleprompter</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="nc">RAG</span><span class="p">(),</span> <span class="n">trainset</span><span class="o">=</span><span class="n">qa_trainset</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><strong>解释</strong>：
    <ul>
      <li><strong>第5行</strong>：创建一个 <code class="language-plaintext highlighter-rouge">BootstrapFewShot</code> 类型的 <strong>远程提示器（teleprompter）</strong>，并指定使用的评估指标为精确匹配（EM）。
        <ul>
          <li><code class="language-plaintext highlighter-rouge">BootstrapFewShot</code> 的作用是自动生成缺失的标签，如推理链（reasoning chains）和检索上下文（retrieval contexts），从而丰富训练示例。</li>
          <li>评估指标 <code class="language-plaintext highlighter-rouge">dspy.evaluate.answer_exact_match</code> 用于衡量生成的答案与参考答案的精确匹配程度。</li>
        </ul>
      </li>
      <li><strong>第6行</strong>：使用远程提示器编译 <code class="language-plaintext highlighter-rouge">RAG</code> 模块，并传入训练集 <code class="language-plaintext highlighter-rouge">qa_trainset</code>。
        <ul>
          <li><code class="language-plaintext highlighter-rouge">RAG()</code> 创建了一个RAG模块实例，该模块包含检索（Retrieve）和生成（ChainOfThought）两个子模块。</li>
          <li><code class="language-plaintext highlighter-rouge">teleprompter.compile(RAG(), trainset=qa_trainset)</code> 会根据训练集和指定的指标，自动生成和优化RAG管道。</li>
          <li>编译后的 <code class="language-plaintext highlighter-rouge">compiled_rag</code> 是一个优化后的RAG管道，能够根据少量训练示例有效地执行问答任务。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>整体流程说明：</p>

<ol>
  <li>
    <p><strong>定义训练集</strong>：</p>

    <ul>
      <li>创建一个包含问题和答案的小型训练集。例如：“What is the capital of France?” -&gt; “Paris”。</li>
    </ul>
  </li>
  <li>
    <p><strong>创建远程提示器</strong>：</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">BootstrapFewShot</code> 使用指定的评估指标（如精确匹配）来指导管道的优化。</li>
      <li>远程提示器负责自动生成缺失的标签信息，如推理链和检索上下文，提升训练示例的质量和多样性。</li>
    </ul>
  </li>
  <li>
    <p><strong>编译优化管道</strong>：</p>

    <ul>
      <li>使用远程提示器编译RAG模块，并传入训练集。</li>
      <li>通过编译过程，DSPy 自动生成高质量的少量示例，优化RAG管道的各个模块，使其能够更好地完成问答任务。</li>
    </ul>
  </li>
</ol>

<p>优势：</p>

<ul>
  <li><strong>标签效率</strong>：只需为最终输出提供标签（答案），不需要为每个中间步骤提供标签（如推理链和检索上下文），减少了数据标注的工作量。</li>
  <li><strong>模块化与自动化优化</strong>：用户只需定义高层次的任务需求，DSPy 会自动生成和优化模块行为，使得管道能够高效且准确地完成任务。</li>
  <li><strong>少量数据有效性</strong>：即使训练集很小，通过引导生成高质量的示例，DSPy 仍能有效优化管道，适应复杂任务。</li>
</ul>

<h2 id="dspy-编译器">DSPy 编译器</h2>

<p>分为三个阶段</p>

<h3 id="阶段一候选生成">阶段一：候选生成</h3>

<p>生成数据</p>

<p>需要先造一下示例</p>

<p>用 teacher moodel 或者 zero-shot 生成一些输出，然后用指标去评估，选一些合格的好的</p>

<h3 id="阶段二参数优化">阶段二：参数优化</h3>

<p>参数优化是确保程序高效运行和达成预期目标的关键步骤。该阶段的核心任务是为每个参数选择最优的候选值，以提升整体系统的性能或降低资源消耗。</p>

<ul>
  <li>Few-shot
    <ul>
      <li>随机搜索</li>
      <li><strong>树结构的帕森估计器（Tree-structured Parzen Estimators, TPE）</strong></li>
    </ul>
  </li>
  <li>Fine-tuning
    <ul>
      <li>更新模块的权重</li>
    </ul>
  </li>
</ul>

<h3 id="阶段三高阶程序优化">阶段三：高阶程序优化</h3>

<p>修改程序的 pipeline</p>

<ul class="task-list">
  <li>方式一：集成
    <ul>
      <li>将引导多个相同程序的副本，然后用一个新的程序替换它，新的程序并行运行所有副本，并将它们的预测通过自定义函数（例如，多数投票）汇总成一个结果</li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />可不可让他自己优化pipeline  [created:: 2024-12-11]  [completion:: 2024-12-14]</li>
</ul>

<h2 id="目标和评估">目标和评估</h2>

<p>结果</p>

<ul>
  <li>通过 DSPy，我们可以用简洁且明确定义的模块替换手工制作的提示字符串，而不会降低质量或表达能力。</li>
  <li>参数化模块并将提示处理为优化问题使 DSPy 更适合适应不同的语言模型，并且它可能优于专家撰写的提示。</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[DSPY COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES论文学习 不懂的]]></summary></entry></feed>