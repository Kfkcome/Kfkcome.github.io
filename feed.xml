<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-Hans"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="zh-Hans" /><updated>2024-12-18T20:06:39+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ennis’s Blog</title><subtitle>Willing to be a question, willing to be an answer.
</subtitle><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><entry><title type="html">TooL LLM 论文粗读</title><link href="http://localhost:4000/2024/12/18/TooL-LLM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="TooL LLM 论文粗读" /><published>2024-12-18T00:00:00+08:00</published><updated>2024-12-18T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/18/%3CTooL%20LLM%3E%20%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/2024/12/18/TooL-LLM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="tool-llm-论文粗读">&lt;TooL LLM&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</span>                                                                                                                                  |
| —————————————————————— | ———————————————————————————————————————————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/arXiv.2307.16789)</span></em>                                                                                                                      |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Qin Yujia,Liang Shihao,Ye Yining,Zhu Kunlun,Yan Lan,Lu Yaxi,Lin Yankai,Cong Xin,Tang Xiangru,Qian Bill,Zhao Sihan,Hong Lauren,Tian Runchu,Xie Ruobing,Zhou Jie,Gerstein Mark,Li Dahai,Liu Zhiyuan,Sun Maosong</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023-10-03</span>                                                                                                                                                                                                    |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>开源模型使用工具的能力还非常弱：</p>

    <ul>
      <li>因为instruct-tuning 主要集中在基本语言任务上，而忽略了工具使用</li>
      <li>与闭源的LLM有很大差距</li>
    </ul>
  </li>
  <li>
    <p>当前研究：有人探讨了为工具使用指令调优数据，但他们未能充分激发大语言模型的工具使用能力，并具有固有的局限性</p>

    <ul>
      <li>有限的API</li>
      <li>受限的场景</li>
      <li>低效的推理和规划</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>为了弥补差距，提出了ToolLLM，一个一般工具使用框架：包含数据构建、模型训练和评估。</p>

<h3 id="数据构建">数据构建</h3>

<p>提出了ToolBench，一个用于工具使用的指令微调数据集，是使用chatgpt自动构建的</p>

<p>构建可以分为三个阶段</p>

<ol>
  <li>
    <p>API集合：RapidAPI Hub中16464个真实世界的的RESTful API涵盖49个类别</p>
  </li>
  <li>
    <p>指令生成：提示Chatgpt生成涉及这些API的多样化指令，涵盖单工具和多工具场景</p>

    <ul>
      <li>
        <p>抽样不用的API组合，然后制定涉及他们的各种指令</p>

        <ul>
          <li>抽样方法：随机从统一类别中选择2-5个工具，从每个工具抽样3个API</li>
        </ul>
      </li>
      <li>
        <p>ICL+prompt 实现让gpt生成instruction</p>
      </li>
      <li>
        <p>然后用这些（instruction，relevant API）训练一个API retriever</p>
      </li>
    </ul>
  </li>
  <li>
    <p>解决路径注释：使用ChatGPT为每个instruction搜索有效的解决路径（API调用链）</p>

    <ul>
      <li>
        <p>解决路径：包含模型包含多个LLM推理轮次和实时API调用</p>
      </li>
      <li>
        <p>问题：但是GPT-4对复杂的指令通过率很低，这使得注释效率很低，CoT 和 ReACT 也不行</p>

        <ul>
          <li>错误积累</li>
          <li>探索有限（仅探索一个路径）</li>
        </ul>
      </li>
      <li>
        <p>解决：开发了一种新颖的基于深度优先搜索的决策树算法来增强LLM的规划和推理能力，它使LLM能评估多个推理轨迹，做出深思熟虑的决策（选择撤回或者继续走）</p>
      </li>
      <li>
        <p>结果：显著提高了注释效率，并完成了使用ReACT无法实现的复杂指令训<img src="/assets/posts_assets/45QMKDXT.png" alt="" /></p>
      </li>
    </ul>
  </li>
</ol>

<h3 id="评估">评估</h3>

<p>开发了一个自动评估器 ToolEval，包含两个指标</p>

<ol>
  <li>
    <p>通过率：衡量LLM在有限资源内成功执行指令的能力</p>
  </li>
  <li>
    <p>获胜率：比较两种解决方案的质量和有用性</p>

    <ul>
      <li>做法：向GPT提供一个指令和两个解决路径，获得偏好</li>
    </ul>
  </li>
</ol>

<p>通过这两点，构建ChatGPT的prompt</p>

<p>为什么要有ToolEval？</p>

<ol>
  <li>API不断变化的</li>
  <li>指令存在无线潜在解决路径</li>
  <li>为每个测试指令标注一个固定的真实解决路径是不可行的</li>
</ol>

<p>结果：发现ToolEval与人工标注者的通过率有87.1%的一致性而获胜率有80.3%</p>

<p>表明ToolEval很大程度上能够反映和代表人类评估。</p>

<h3 id="模型训练">模型训练</h3>

<p>基于ToolBench对LLaMA进行微调，得到ToolLLaMA，并为其配备了神经网络API检索器，以推荐适合每个指令的API</p>

<h4 id="api-retriever训练">API Retriever训练</h4>

<p>使用Sentence-BERT</p>

<ul>
  <li>API检索器将指令和API文档分别编码为两个向量嵌入，然后通过计算嵌入相似度来评估相关性，</li>
  <li>指令相关的API作为正例，并从其他API中随机抽取一些作为负例进行对比学习</li>
</ul>

<p><img src="/assets/posts_assets/M3KNXVCX.png" alt="" /></p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>性能好：ToolLLaMA展现出执行复杂指令和推广至未见 API 的卓越能力，并且其表现与 ChatGPT 相当</li>
  <li>泛化能力好：ToolLLaMA 在一个超出分布的工具使用数据集 APIBench 中也表现出强大的零-shot 泛化能力。</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;TooL LLM&gt; 论文粗读 💡 Meta Data Title ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs Journal  (10.48550/arXiv.2307.16789) Authors Qin Yujia,Liang Shihao,Ye Yining,Zhu Kunlun,Yan Lan,Lu Yaxi,Lin Yankai,Cong Xin,Tang Xiangru,Qian Bill,Zhao Sihan,Hong Lauren,Tian Runchu,Xie Ruobing,Zhou Jie,Gerstein Mark,Li Dahai,Liu Zhiyuan,Sun Maosong Pub.date 2023-10-03]]></summary></entry><entry><title type="html">Toolformer 论文粗读</title><link href="http://localhost:4000/2024/12/17/Toolformer-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Toolformer 论文粗读" /><published>2024-12-17T00:00:00+08:00</published><updated>2024-12-17T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/17/%3CToolformer%3E%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/2024/12/17/Toolformer-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="toolformer-论文粗读">&lt;Toolformer&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Toolformer: Language Models Can Teach Themselves to Use Tools</span>                                                           |
| —————————————————————— | ——————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/ARXIV.2302.04761)</span></em>                                |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Schick Timo,Dwivedi-Yu Jane,Dessì Roberto,Raileanu Roberta,Lomeli Maria,Zettlemoyer Luke,Cancedda Nicola,Scialom Thomas</span> |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                                                    |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p>LLM的对于一些任务上有卓越的能力，但是基本功能方面却存在困难，例如算数或事实查找。</p>

    <ul>
      <li>这些领域是小模型的强项</li>
    </ul>
  </li>
  <li>
    <p>当前的研究：要么依赖大量的人类标注数据、要么仅限于特定任务的工具使用，阻碍了工具在语言模型中的广泛采用。</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="思路">思路</h3>

<ul>
  <li>
    <p>让LLM通过简单的API自我学习使用外部工具。</p>
  </li>
  <li>
    <p>提出了Toolformer，实现以下愿望：</p>

    <ul>
      <li>
        <p>自监督学习工具，不用人类标注数据</p>

        <ul>
          <li>
            <p>原因：</p>

            <ul>
              <li>人类标注成本高</li>
              <li>人类觉得有用的不一定是LLM觉得有用的</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>LM 不能失去其泛化能力，不局限于特定任务</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="方法">方法</h3>

<p>利用In-context learning，从零开始生成数据集</p>

<ol>
  <li>首先仅通过少量人类编写的API使用示例，让语言模型为一个庞大的语言建模数据集标注潜在的API调用</li>
  <li>然后使用自监督损失（self-supervised loss）来确定哪些API调用实际上有助于模型预测未来的token</li>
  <li>最后微调模型</li>
</ol>

<p>具体：</p>

<p><img src="/assets/posts_assets/Pasted%20image%2020241218101428.png" alt="" /></p>

<ol>
  <li>
    <p><strong>给定一个普通文本的数据集，然后转化成带有API调用的数据集</strong></p>

    <ol>
      <li>
        <p>编写prompt，利用In-context-learning 采样大量潜在的API调用（生成多个API调用）</p>

        <ul>
          <li>先找到序列中哪个位置调用API（设定一个阈值，如果生成&lt;API&gt;概率大于阈值则保留该位置）</li>
          <li>然后选定API：选定位置后，继续生成，然后进行采样多个API候补</li>
        </ul>
      </li>
      <li>
        <p>然后执行API调用（每个API的返回是文本序列）</p>
      </li>
    </ol>
  </li>
  <li>
    <p><strong>然后检查获得的相应是否有助于未来的token，来筛选</strong></p>

    <ol>
      <li>具体就是比较加入API调用后，生成后序序列的概率和不加API调用的概率哪个大（要大过设定的阈值），如果加入API后大超过阈值那就是有帮助，则保留</li>
    </ol>
  </li>
  <li>
    <p><strong>经过筛选得到了增强的数据集，然后进行微调</strong></p>
  </li>
</ol>

<blockquote>
  <p>生成过程中如果生成到了spacial token了就中断生成过程，获得API响应后，插入响应和&lt;/API&gt; token后继续解码过程</p>
</blockquote>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>Toolformer 显著提高了zero-shot性能</li>
  <li>语言建模能力也没有牺牲</li>
</ul>

<p><img src="/assets/posts_assets/BVWDZZY3.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<p>缺点：</p>

<ul>
  <li>无法与搜索引擎交互，只能用他给出的结果，无法重构查询等，然后就没有修补办法。</li>
</ul>

<p>收获：</p>

<ul>
  <li>微调以后再禁用API测试，确实是一个检测微调后有没有损失模型性能的好办法</li>
  <li>微调过程中仅对工具选择算loss感觉挺有用
*</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;Toolformer&gt; 论文粗读 💡 Meta Data Title Toolformer: Language Models Can Teach Themselves to Use Tools Journal  (10.48550/ARXIV.2302.04761) Authors Schick Timo,Dwivedi-Yu Jane,Dessì Roberto,Raileanu Roberta,Lomeli Maria,Zettlemoyer Luke,Cancedda Nicola,Scialom Thomas Pub.date 2023]]></summary></entry><entry><title type="html">TALM 论文粗读</title><link href="http://localhost:4000/2024/12/17/TALM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="TALM 论文粗读" /><published>2024-12-17T00:00:00+08:00</published><updated>2024-12-17T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/17/TALM--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/2024/12/17/TALM-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="talm-论文粗读">&lt;TALM&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">TALM: Tool Augmented Language Models</span>                                                     |
| —————————————————————— | ————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.48550/ARXIV.2205.12255)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Parisi Aaron,Zhao Yao,Fiedel Noah</span>                                                        |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2022</span>                                                                                     |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>LLM 需要工具：LLM 不能使模型解决需要访问训练时不可用短暂、变化或私人数据的任务，许多任务用API更好解决</li>
  <li>最近研究将LLM连接到一个环境（仅是作为query的接受者）</li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了工具增强语言模型（TALM），使用模型生成的输出调用任意工具，并关注工具输出以生成任务输出</p>

<p>贡献：</p>

<ul>
  <li>仅使用text-to-text 的API 来增强语言模型</li>
  <li>提出自我博弈（self-play）技术，提高了在few-shot的启动性能</li>
</ul>

<h3 id="talm模型">TALM模型</h3>

<p><img src="/assets/posts_assets/LMBWTV2M.png" alt="" /></p>

<ol>
  <li>
    <table>
      <tbody>
        <tr>
          <td>TALM 首先生成一个基于任务输入文本的工具输入，并通过生成分隔符，例如“</td>
          <td>result”，调用工具的 API。</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>每当检测到这个分隔符时，就会调用工具 API，并将其结果附加到文本序列中。</p>
  </li>
  <li>然后，TALM 继续生成最终的任务输出。<img src="assets/posts_assets/VQ5T6NKX.png" alt="" /></li>
</ol>

<p>TALM 同时学习两个子任务：调用工具和基于工具结果生成答案。</p>

<p>TALM 在架构上用了Seq2Seq模型</p>

<h3 id="迭代iterative-self-play">迭代Iterative self-play</h3>

<ol>
  <li>首先有示例数据集，然后微调这个数据集，再在新数据集（无工具示例）生成工具调用的过程。</li>
  <li>然后看最终结果怎么样，如果大于阈值就添加到原本的数据集中</li>
</ol>

<blockquote>
  <p>这个过程虽然本文是单步的，但是很容易建模成多步的，用类似马尔科夫链建模</p>
</blockquote>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>一个知识密集型问答任务（NQ）和一个使用简单工具的推理导向数学任务（MathQA）上表现出色。</li>
  <li>TALM 成功地在问答和数学任务上进行分布外推理，而未增强的语言模型则失败。</li>
  <li>小模型从工具中收益更多（知识密集的任务）</li>
</ul>

<p><img src="assets/posts_assets/K39LZNDR.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />需要再搞清楚seq2seq模型和decoder-only模型的本质区别是什么  [created:: 2024-12-17]  [due:: 2024-12-17]</li>
  <li class="task-list-item">这些论文学习工具的过程感觉都是 少样本-&gt;自己增强（标准不一样）-&gt;然后再微调自己</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;TALM&gt; 论文粗读 💡 Meta Data Title TALM: Tool Augmented Language Models Journal  (10.48550/ARXIV.2205.12255) Authors Parisi Aaron,Zhao Yao,Fiedel Noah Pub.date 2022]]></summary></entry><entry><title type="html">Self-Planning Code Generation with Large Language Models 论文粗读</title><link href="http://localhost:4000/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="Self-Planning Code Generation with Large Language Models 论文粗读" /><published>2024-12-16T00:00:00+08:00</published><updated>2024-12-16T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/2024/12/16/Self-Planning-Code-Generation-with-Large-Language-Models-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="self-planning-code-generation-with-large-language-models-论文粗读">&lt;Self-Planning Code Generation with Large Language Models&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">Self-Planning Code Generation with Large Language Models</span>                                                                               |
| —————————————————————— | ———————————————————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)">ACM Transactions on Software Engineering and Methodology </span><em><span style="background-color: rgb(243, 250, 244)">(10.1145/3672456)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Jiang Xue,Dong Yihong,Wang Lecheng,Fang Zheng,Shang Qiwei,Li Ge,Jin Zhi,Jiao Wenpin</span>                                                    |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023-06-30</span>                                                                                                                             |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<p>问题：</p>

<ul>
  <li>
    <p>LLM代码生成无法应对有复杂意图的任务</p>

    <ul>
      <li>解决方法：需要采用规划来分解复杂问题，并在实施之前安排解决方案步骤</li>
    </ul>
  </li>
  <li>
    <p>生成CoT的过程和生成代码的过程本质是相似的，直接将CoT应用于代码并不能减少难度</p>

    <ul>
      <li>解决方法：要专注实现问题的分解</li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>思路：将规划引入到了代码生成中，以帮助模型理解复杂意图并降低问题解决难度</p>

<p><img src="/assets/posts_assets/QACCGZ7E.png" alt="" /></p>

<p>具体方法：</p>

<ul>
  <li>规划阶段：大型语言模型通过结合少量示例提示（包含细粒度的规划过程），从意图中规划出简洁的解决方案步骤</li>
  <li>实现阶段：模型在前面解决方案步骤的指导下（把计划加入prompt中），逐步生成代码</li>
</ul>

<p>训练方法：少样本实现规划能力，而不是标记数据（记意图-计划对），无需微调。</p>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ol>
  <li>
    <p>性能提升：自规划代码生成在Pass\@1指标上实现了高达25.4%的相对提升，与思维链代码生成相比则实现了高达11.9%的提升</p>
  </li>
  <li>
    <p>根据人类评估，正确性、可读性和稳健性提升了代码质量</p>
  </li>
  <li>
    <p>规划能力：我们表明，自我规划是一种出现在足够大的大型语言模型上的涌现能力，但规划可以使大多数大型语言模型受益。</p>
  </li>
  <li>
    <p>最优：我们深入探讨了自我规划方法的几种变体，并证明我们设计的自我规划方法是这些变体中的最佳选择。<img src="/assets/posts_assets/6BX4DXWS.png" alt="" /></p>
  </li>
  <li>
    <p>泛化：我们验证了自我规划方法在多种编程语言（包括Python、Java、Go和JavaScript）上的有效性。</p>
  </li>
</ol>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>为什么多轮的效果不如单轮的</p>

    <ul>
      <li>由于大型语言模型在大量的拼接文本和代码上进行训练以预测下一个标记，因此大型语言模型可能存在截断问题，即它们无法精确控制其输出的终止。当使用计划来生成部分函数（通常是若干语句）时，很难定义截断规则。</li>
    </ul>
  </li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;Self-Planning Code Generation with Large Language Models&gt; 论文粗读 💡 Meta Data Title Self-Planning Code Generation with Large Language Models Journal ACM Transactions on Software Engineering and Methodology (10.1145/3672456) Authors Jiang Xue,Dong Yihong,Wang Lecheng,Fang Zheng,Shang Qiwei,Li Ge,Jin Zhi,Jiao Wenpin Pub.date 2023-06-30]]></summary></entry><entry><title type="html">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting 论文粗读</title><link href="http://localhost:4000/2024/12/15/MultiTool-CoT-GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting 论文粗读" /><published>2024-12-15T00:00:00+08:00</published><updated>2024-12-15T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/15/MultiTool-CoT--GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting--%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/2024/12/15/MultiTool-CoT-GPT-3-Can-Use-Multiple-External-Tools-with-Chain-of-Thought-Prompting-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="multitool-cot-gpt-3-can-use-multiple-external-tools-with-chain-of-thought-prompting-论文粗读">&lt;MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting&gt; 论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting</span> |
| —————————————————————— | ———————————————————————————————————————————————- |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">()</span></em>                      |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Inaba Tatsuro,Kiyomaru Hirokazu,Cheng Fei,Kurohashi Sadao</span>                            |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | 2023                                                                                                                                           |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<ul>
  <li>
    <p>LLM 在各种推理任务上取得了令人瞩目的性能。</p>
  </li>
  <li>
    <p>外部工具注入推理过程的研究都集中于单个外部攻击解决LLM的单个问题，而没有一起解决不同的问题</p>

    <ul>
      <li>本文解决：多个外部工具、同时解决多个问题</li>
    </ul>
  </li>
  <li>
    <p>为了进一步提高性能，提出了MultiTool-CoT</p>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<p>提出了MultiTool-CoT 交互式框架：利用CoT提示在推理过程中整合多种外部工具（计算器、知识检索器）（包含工具触发的推理）</p>

<p>训练方法：few-shot learning ，学习在适当的推理步骤中调用多个外部工具</p>

<p><img src="/assets/posts_assets/9PDWDS27.png" alt="" /></p>

<ul>
  <li>
    <p>指令包括：可用的外部工具、带有推理过程的少样本示例、待解决的问题</p>
  </li>
  <li>
    <p>工具触发器：«外部工具名称»</p>
  </li>
  <li>
    <p>工具触发的流程：</p>

    <ul>
      <li>在推理时如果生成了工具触发，则停止文本生成，</li>
      <li>然后从推理过程中提取外部工具的名称和工具的输入，</li>
      <li>然后执行工具，并将结果附加到推理过程末尾</li>
      <li>如果工具调用失败，则回退让GPT生成工具的输出</li>
    </ul>
  </li>
  <li>
    <p>答案：用额外的few-shot从最后一句输出映射到答案值</p>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<ul>
  <li>NumGLUE 的任务 2 数据集（该数据集需要数值推理和特定领域的知识），MultiTool-CoT 显著优于强大的基线模型，并取得了最先进的性能</li>
</ul>

<p><img src="/assets/posts_assets/TG94PG4C.png" alt="" /></p>

<p>error case:</p>

<ul>
  <li>不正确的推理过程（39%）</li>
  <li>无效的工具输入（35%）</li>
  <li>格式错误（11%）</li>
  <li>不正确的答案（15%）</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>
    <p>这里的工具调用是如何实现停止的？（直接输出停止吗？）</p>

    <ul>
      <li>是检测到工具触发格式了就停止生成了。然后调用工具继续再生成</li>
    </ul>
  </li>
</ul>

<p>*</p>

<p>*</p>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting&gt; 论文粗读 💡 Meta Data Title MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting Journal  () Authors Inaba Tatsuro,Kiyomaru Hirokazu,Cheng Fei,Kurohashi Sadao Pub.date 2023]]></summary></entry><entry><title type="html">StructGPT 论文粗读</title><link href="http://localhost:4000/2024/12/14/StructGPT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="StructGPT 论文粗读" /><published>2024-12-14T00:00:00+08:00</published><updated>2024-12-14T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/14/StructGPT%20%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/2024/12/14/StructGPT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="structgpt论文粗读">&lt;StructGPT&gt;论文粗读</h1>

<hr />

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">StructGPT: A General Framework for Large Language Model to Reason over Structured Data</span>         |
| —————————————————————— | ——————————————————————————————————————————————————– |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.18653/v1/2023.emnlp-main.574)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Jiang Jinhao,Zhou Kun,Dong Zican,Ye Keming,Zhao Xin,Wen Ji-Rong</span>                                |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                           |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<ul>
  <li>
    <p><strong>目的</strong>：以统一的方式提升大型语言模型 (LLMs) 在结构化数据上的推理能力</p>
  </li>
  <li>
    <p><strong>motivation</strong>：当前LLM在引入外部知识的时候，通常使用有结构的数据库，而数据库存放的数据通常是结构的，而LLM无法完全理解</p>

    <ul>
      <li>
        <p>直接解决方法：直接线性化（直接拼接成一长串句子）</p>

        <ul>
          <li>缺点：但是数据量很大的时候，不可能全部都直接假如到prompt中。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="问题描述">问题描述</h3>

<p>使用LLM解决基于结构化数据的复杂推理任务</p>

<p><strong>输入：</strong> 自然语言问题、结构化数据（知识图谱、表格、数据库）</p>

<p><strong>输出：</strong> 结果（自然语言或结构化表达式）</p>

<h3 id="解决思路">解决思路</h3>

<ul>
  <li>
    <p>引入专门的APi操作结构化的数据记录</p>

    <ul>
      <li>如何为特定任务设计合适的接口</li>
      <li>如何利用这些接口让LLMs进行推理</li>
    </ul>
  </li>
</ul>

<p>提出了 Iterative Reading and Reasoning 框架解决结构化数据的问答任务——Struct GPT</p>

<h3 id="iterative-reading-and-reasoning-框架">Iterative Reading and Reasoning 框架</h3>

<ul>
  <li>reading 读取：构建了专门的机构从结构化数据收集相关证据</li>
  <li>reasoning 推理：让LLM专注于收集到的信息的推理任务</li>
</ul>

<p>具体过程：invoking-&gt; linearzation -&gt; generation</p>

<h4 id="struct-api定义">struct API定义</h4>

<blockquote>
  <p>因为用LLM来结构化数据不好，所以作者自己设计了API而不是使用LLM</p>
</blockquote>

<ol>
  <li>
    <p>知识图谱：</p>

    <ul>
      <li>Extraction_Neighbor_Relations(e)</li>
      <li>Extract_Triples(e,{r})</li>
    </ul>
  </li>
  <li>
    <p>表格：</p>

    <ul>
      <li>Extract_Columns(T,{c})</li>
      <li>……</li>
    </ul>
  </li>
  <li>
    <p>数据库</p>

    <ul>
      <li>Extract_Table\&amp;Column_Name (D)</li>
      <li>……</li>
    </ul>
  </li>
</ol>

<h4 id="invoking">Invoking</h4>

<p>调用接口从结构化数据中提取相关信息，送到LLM中</p>

<h4 id="information-linearization">Information Linearization</h4>

<p>根据提取的信息，将其转换为可被大型语言模型理解的文本句子</p>

<p>每个结构定义一种线性化规则</p>

<p>来自知识图谱的信息:将其连接成一个长句子，并用特定的分隔符和边界符号标记。</p>

<p>对于表格：</p>

<p>例如“（第1行，年份，1896）”和“（第1行，城市，雅典）”。然后，对于每一行，我们将行索引提取到句首，并在三元组中省略行索引，以组成简化的句子，例如“第1行：（年份，1896），（城市，雅典）”。对于多行数据，我们通过特殊的分隔符将它们连接成一个长句子。</p>

<h4 id="llm-for-generation">LLM for Generation</h4>

<p>有两种prompt：</p>

<ul>
  <li>筛选数据：从线性的数据中根据问题筛选有用的数据</li>
  <li>给出答案：生成最终答案（可以是自然语言也可以是形式化语言（SQL））</li>
</ul>

<h4 id="举例解释流程">举例解释流程</h4>

<p>以知识图谱为例：</p>

<ol>
  <li>根据问题 query 中提到的实体 搜索调用接口Extract_Neighbor_Relation、Extract_Triples</li>
  <li>然后线性化</li>
  <li>利用LLM根据问题选择有用的关系</li>
  <li>调用Extract_Triples收集头实体 eT 和 {r} 中关系的相关三元组</li>
  <li>然后线性化此信息</li>
  <li>LLM应评估当前信息是否足以回答问题，然后，LLM将根据评估结果采取相应操作（停止或迭代）</li>
  <li>使用大型语言模型选择最相关的三元组，其尾实体将被视为最终答案</li>
</ol>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>在8个数据集上的实验结果表明，我们的方法可以有效提升LLMs在零样本和少样本设置下对结构化数据的推理性能，甚至可以与具有竞争力的全数据监督微调方法相媲美。</p>

<p>在KGQA、TableQA和text-to-SQL任务中，与在零样本设置下直接使用ChatGPT相比，我们的方法在WebQSP上实现了11.4%的Hits\@1提升，在TabFact上实现了4.2%的准确率提升，在Spider上实现了4.7%的执行准确率提升。</p>

<p><img src="/assets/posts_assets/42LCZJPX%202.png" alt="" /></p>

<p><img src="/assets/posts_assets/KI6GJZ8H.png" alt="" /></p>

<p><img src="/assets/posts_assets/Y3L54F4W.png" alt="" /></p>

<p>错误：</p>

<ul>
  <li>选择错误：相关信息不是LLM选的</li>
  <li>推理错误：有相关信息但是LLM推理错误</li>
  <li>生成答案格式错误：无法被结果解析识别（数据集不同很难控制生成对应的格式）</li>
  <li>幻觉问题</li>
</ul>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>是什么情况下few-shot比zero-shot更差的？</li>
  <li>这种固定的pipeline可能无法让LLM选择自己要的数据</li>
  <li>这种自己定义数据的线性化，是不是太死板了，他说用LLM结构化不太好，但是后面有人做了，是可以的。</li>
  <li>总体来说并不算是真正的工具学习，因为不是 LLM 自主调用的，而是固定的步骤。</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;StructGPT&gt;论文粗读 💡 Meta Data Title StructGPT: A General Framework for Large Language Model to Reason over Structured Data Journal  (10.18653/v1/2023.emnlp-main.574) Authors Jiang Jinhao,Zhou Kun,Dong Zican,Ye Keming,Zhao Xin,Wen Ji-Rong Pub.date 2023]]></summary></entry><entry><title type="html">ChatCoT 论文粗读</title><link href="http://localhost:4000/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html" rel="alternate" type="text/html" title="ChatCoT 论文粗读" /><published>2024-12-14T00:00:00+08:00</published><updated>2024-12-14T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/2024/12/14/ChatCoT-%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB.html"><![CDATA[<h1 id="chatcot论文粗读">&lt;ChatCoT&gt;论文粗读</h1>

<h2 id="-meta-data"><span style="color: rgb(27, 94, 32)"><span style="background-color: rgb(241, 248, 233)">💡 Meta Data</span></span></h2>

<p>| <span style="background-color: rgb(219, 238, 221)">Title</span>    | <span style="background-color: rgb(219, 238, 221)">ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models</span>             |
| —————————————————————— | ———————————————————————————————————————————————————— |
| <span style="background-color: rgb(243, 250, 244)">Journal</span>  | <span style="background-color: rgb(243, 250, 244)"> </span><em><span style="background-color: rgb(243, 250, 244)">(10.18653/v1/2023.findings-emnlp.985)</span></em> |
| <span style="background-color: rgb(219, 238, 221)">Authors</span>  | <span style="background-color: rgb(219, 238, 221)">Chen Zhipeng,Zhou Kun,Zhang Beichen,Gong Zheng,Zhao Xin,Wen Ji-Rong</span>                                |
| <span style="background-color: rgb(243, 250, 244)">Pub.date</span> | <span style="background-color: rgb(243, 250, 244)">2023</span>                                                                                               |
<!---more--></p>
<h2 id="-研究背景--基础--目的-motivation"><span style="color: rgb(230, 81, 0)"><span style="background-color: rgb(255, 248, 225)">📜 研究背景 &#x26; 基础 &#x26; 目的 (Motivation)</span></span></h2>

<hr />

<p>现有的问题：</p>

<p>CoT的生成过程是一次性的，在中间步骤中使用工具将需要对其进行打断，从而损害生成过程的连续性</p>

<p>工具的调用会打断CoT的进程</p>

<ul>
  <li>
    <p>现有的解决方法：</p>

    <ul>
      <li>
        <p>依赖LLM预先安排工具使用计划以供后序执行</p>

        <ul>
          <li>缺点：生成计划后无法与工具交互，及时看到明显的错误也无法纠正，存在误差累积</li>
        </ul>
      </li>
      <li>
        <p>设计针对特定任务的固定操作</p>

        <ul>
          <li>缺点：必须频繁的在LLM推理和执行行动之间切换，损害了CoT之间的连贯性（就比如CoT下一步必须是调工具）</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>作者要寻找一种更统一的方法整合CoT和tool</p>

<h2 id="-研究方法"><span style="color: rgb(21, 101, 192)"><span style="background-color: rgb(225, 245, 254)">🔬 研究方法</span></span></h2>

<hr />

<h3 id="解决思路">解决思路</h3>

<ul>
  <li>
    <p>将LLM的工具的操作视为LLM与工具之间的交互。</p>
  </li>
  <li>
    <p>将LLM和工具之间的交互过程建模为多轮对话，利用LLM出色的对话能力来操作工具</p>

    <ul>
      <li>在每一轮中，LLM可以在需要时自由地与工具交互，否则自行进行推理</li>
      <li>对话持续进行直到LLM得出最终答案。</li>
    </ul>
  </li>
  <li>
    <p>针对问题：在此过程中，由于基于对话的LLM可以很好地理解多轮上下文，它们可以在整个对话中遵循思维链，并自然地相应地调用工具，从而保持推理过程的连续性。</p>
  </li>
</ul>

<p>所以作者提出了ChatCoT，一种用于基于聊天的LLM的工具增强型思维推理策略。</p>

<h3 id="初始设定">初始设定</h3>

<h4 id="任务定义">任务定义</h4>

<p>专注于提升LLM在复杂任务上的推理能力（解决数学竞赛问题）</p>

<p>任务描述：</p>

<ul>
  <li>问题陈述：复杂问题的背景和描述</li>
  <li>解答文本：获得答案单独详细解决过程</li>
  <li>答案</li>
</ul>

<p>任务目的：给定问题陈述最终生成准确答案</p>

<h4 id="工具集">工具集</h4>

<ul>
  <li>
    <p>计算器：给定数据表达式可以化简</p>

    <ul>
      <li>实现：用SymPy python库</li>
    </ul>
  </li>
  <li>
    <p>方程求解器：给定方程组和未知变量，可以求解</p>

    <ul>
      <li>实现：用SymPy python库</li>
    </ul>
  </li>
  <li>
    <p>检索器：给查询提取相关信息</p>

    <ul>
      <li>用SimCSE</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/posts_assets/MSM9TUAY.png" alt="" /></p>

<h3 id="具体方法">具体方法</h3>

<blockquote>
  <p>工具学习的训练方法：In-context learning</p>
</blockquote>

<p>通过agent（预定义的规则）与LLM的对话来实现推理和工具调用</p>

<p>整体分两个阶段：</p>

<ul>
  <li>
    <p>给LLM输入关于工具、任务和推理格式的知识来初始化对话的早期轮次(对话形式）</p>
  </li>
  <li>
    <p>迭代一个专门设计的<strong>工具增强型推理</strong>步骤(对话），直到获得答案</p>

    <ul>
      <li>在每次迭代中，基于当前的结果，我们首先利用大型语言模型进行推理，然后通过大型语言模型选择合适的工具，最后执行所选工具以获得当前步骤的中间结果。</li>
      <li>推理：LLM根据示例可以将推理分解为多轮对话，而无需专门的提示或指令。直到需要工具功能才停止</li>
      <li>工具选择：通过prompt提示让LLM选择（问LLM用什么工具如果回复不使用工具就继续推理）</li>
      <li>工具执行：给定选定的工具和参数，然后执行，可能结果无法让LLM满意，我们也可以增加几轮反馈，让LLM判断结果是否有用，然后重新使用该工具获取新结果</li>
    </ul>
  </li>
</ul>

<h2 id="-结论"><span style="color: rgb(74, 20, 140)"><span style="background-color: rgb(245, 245, 245)">🚩 结论</span></span></h2>

<hr />

<p>在两个复杂的推理基准数据集上进行了实验，即MATH 和HotpotQA 。</p>

<p>ChatCoT在MATH上取得了非常有希望的性能，与SOTA基线方法相比，平均性能相对提高了7.9%。</p>

<p><img src="/assets/posts_assets/J258MYBV.png" alt="" /></p>

<p><img src="/assets/posts_assets/YV2RNQDC.png" alt="" /></p>

<h2 id="-感想--疑问"><span style="color: rgb(0, 96, 100)"><span style="background-color: rgb(224, 247, 250)">📌 感想 &#x26; 疑问</span></span></h2>

<hr />

<ul>
  <li>整体的prompt流程具体是什么样子？</li>
  <li>agent是如何搞的</li>
  <li>为什么比其他的CoT+Tool好呢？</li>
  <li>读一下其他CoT+Tool</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[&lt;ChatCoT&gt;论文粗读 💡 Meta Data Title ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models Journal  (10.18653/v1/2023.findings-emnlp.985) Authors Chen Zhipeng,Zhou Kun,Zhang Beichen,Gong Zheng,Zhao Xin,Wen Ji-Rong Pub.date 2023]]></summary></entry><entry><title type="html">DSPY COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES论文学习</title><link href="http://localhost:4000/2024/12/08/DSPY-COMPILING-DECLARATIVE-LANGUAGE-MODEL-CALLS-INTO-SELF-IMPROVING-PIPELINES%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0.html" rel="alternate" type="text/html" title="DSPY COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES论文学习" /><published>2024-12-08T00:00:00+08:00</published><updated>2024-12-08T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/08/DSPY%20COMPILING%20DECLARATIVE%20LANGUAGE%20%20MODEL%20CALLS%20INTO%20SELF-IMPROVING%20PIPELINES%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0</id><content type="html" xml:base="http://localhost:4000/2024/12/08/DSPY-COMPILING-DECLARATIVE-LANGUAGE-MODEL-CALLS-INTO-SELF-IMPROVING-PIPELINES%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0.html"><![CDATA[<h1 id="dspy-compiling-declarative-language-model-calls-into-self-improving-pipelines论文学习">DSPY COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES论文学习</h1>

<h2 id="不懂的">不懂的</h2>

<!---more-->
<h3 id="teleprompter-在-dspy-编译器中的作用"><strong>Teleprompter 在 DSPy 编译器中的作用</strong></h3>

<p>在 DSPy 编程模型中，<strong>Teleprompter（提示器）</strong> 是一种核心组件，负责模块化优化过程。具体来说，Teleprompter 是通用的优化策略，用于指导 DSPy 编译器如何让各个模块从数据中学习，以提升整个程序的质量或降低其运行成本。以下是对 Teleprompter 的详细解释：</p>

<ol>
  <li><strong>定义与功能</strong>
    <ul>
      <li><strong>通用优化策略</strong>：Teleprompter 不局限于特定的优化方法，而是提供了一套通用的框架，可以应用于多种优化需求，如提升模型性能、减少计算资源消耗等。</li>
      <li><strong>决策指导</strong>：它决定了每个 DSPy 模块应如何从输入数据中学习。这包括选择合适的学习方法（如少样本学习、微调等）以及如何生成和利用示例数据来改进模块的行为。</li>
    </ul>
  </li>
  <li><strong>工作机制</strong>
    <ul>
      <li><strong>模块学习</strong>：Teleprompter 通过分析模块的示例轨迹（example traces），来理解模块在不同输入下的表现。这些轨迹包含模块在处理特定任务时的详细操作步骤和输出结果。</li>
      <li><strong>构建提示或微调模型</strong>：基于这些轨迹，Teleprompter 可以生成有效的少样本提示（few-shot prompts），帮助模块在未来处理类似任务时表现得更好。此外，它还可以指导对小型语言模型（LMs）的微调，使其更适应管道中各个步骤的需求。</li>
    </ul>
  </li>
  <li><strong>模块化优势</strong>
    <ul>
      <li><strong>高度模块化</strong>：由于 Teleprompter 是模块化设计的，它可以独立于具体的优化目标进行扩展和调整。这意味着可以灵活地应用不同的优化策略，而不需要对整个编译器进行大幅修改。</li>
      <li><strong>适应多种任务</strong>：无论是提示优化、模型微调、推理增强还是数据增强，Teleprompter 都能够根据具体任务需求，选择最合适的优化方法。</li>
    </ul>
  </li>
  <li><strong>自动化优化流程</strong>
    <ul>
      <li><strong>自动映射</strong>：Teleprompter 帮助编译器自动将声明式模块映射为高质量的优化组合。这包括提示生成、模型微调、推理过程的优化等，使得整个自然语言处理管道能够高效协同工作。</li>
      <li><strong>自我改进</strong>：通过不断地模拟和优化，Teleprompter 使得 DSPy 程序能够自我改进，逐步提升其在特定任务上的表现。</li>
    </ul>
  </li>
  <li><strong>类比与启发</strong>
    <ul>
      <li><strong>类比 PyTorch 的优化器</strong>：类似于 PyTorch 中用于调整模型参数的优化器（如 SGD、Adam 等），Teleprompter 也是一种用于优化 DSPy 模块行为的工具。不过，Teleprompter 更加专注于如何利用数据和示例来指导模块的学习过程。</li>
    </ul>
  </li>
</ol>

<p><strong>总结</strong>
Teleprompter 在 DSPy 编译器中扮演着至关重要的角色，通过提供通用的优化策略，指导各个模块如何从数据中有效学习，从而自动优化整个 DSPy 程序的性能和效率。其模块化和自动化的设计，使得 DSPy 编程模型能够灵活适应多种自然语言处理任务，并持续提升其处理能力。</p>

<h2 id="摘要">摘要</h2>

<p>背景：</p>

<p>当前的解决复杂问题，需要将多个语言模型堆叠成管道单的技术来解决，然后每个 LLM 负责一个特定的任务。一般情况下设计 prompt 模版让 LLM 负责特定的任务</p>

<p>问题：</p>

<ol>
  <li>需要专家人工设计 prompt</li>
  <li>设计的 prompt 依赖于经验和试错，面对复杂任务时会出错</li>
  <li>设计的 prompt 通用性较差，无法迁移到新的任务和场景上。</li>
  <li>Prompt 是静态的，缺乏灵活的机制</li>
  <li>用 prompt 可能让多个 LLM 堆叠的性能下降</li>
</ol>

<p>工作:</p>

<p>提出 DSPy（Declarative Self-Improvement Pipelines）模块: 将 LM 的工作流转换为 text transformation graph 文本变换图来实现对复杂任务的处理</p>

<blockquote>
  <p>这些图实际上是 <strong>命令式计算图（imperative computation graphs）</strong>，其中语言模型（LM）通过声明式的模块调用。</p>
</blockquote>

<p>解释：</p>

<ul>
  <li>DSPy 模块具有<strong>参数化</strong>特性，可以通过创建和收集示例来学习- 如何应用 <strong>prompting</strong>、<strong>微调（finetuning）</strong>、<strong>数据增强（augmentation）</strong> 和 <strong>推理（reasoning）</strong> 等技术的组合。</li>
  <li>DSPy 允许用户通过编写简单的程序来定义 LM 管道，这些管道能够执行复杂的任务，如<strong>数学问题推理</strong>、<strong>多跳检索</strong>、<strong>复杂问题回答</strong>和<strong>控制智能体循环</strong>等。</li>
  <li>DSPy 中的程序通过一个<strong>编译器</strong>进行优化，能够在几分钟内自动调整管道，以最大化某个指定的指标（如任务表现）。</li>
</ul>

<p>结果：</p>

<ul>
  <li>
    <p>比<strong>少量样本提示（few-shot prompting）</strong> 提高了 25% 到 65% 的表现，并且相比 <strong>专家创建的示例</strong> 提高了 5% 到 46%（具体数据取决于不同的模型和任务）。</p>
  </li>
  <li>
    <p>DSPy 程序即使编译到较小的开源语言模型（如 770M 参数的 T5 和 llama2-13b-chat）上，表现也能与依赖专家编写提示链的专有 GPT-3.5 方法相媲美。</p>
  </li>
</ul>

<h2 id="引言">引言</h2>

<h3 id="背景">背景</h3>

<p>多阶段管道和 agent 发展：将复杂任务分解为对多个可以调用 LM 任务</p>

<h3 id="问题">问题</h3>

<ol>
  <li>LLM 对 prompt 非常敏感，并且在多个 LM 的系统中更敏感</li>
  <li>当前 LM 调用一般使用 prompt 模版来实现
    <ol>
      <li>这种 prompt 无法扩展泛化不能用到其他的 pipeline 上</li>
    </ol>
  </li>
</ol>

<h3 id="工作">工作</h3>

<h5 id="引入">引入</h5>

<p>为了实现更系统化的 AI pipeline设计方法，我们引入了 DSPy 编程模块</p>

<ul>
  <li>不用自由形式的 strings，而是用类似编程语言</li>
  <li>然后编译器就可以自动从中生成 LM 调用策略和 prompt</li>
</ul>

<p>想法来源：</p>

<p>受到了<strong>神经网络抽象的启发</strong></p>

<ul>
  <li><strong>通用层的模块化组合</strong>：在构建复杂的神经网络架构时，许多通用的层（如卷积层、全连接层等）可以以模块化的方式进行组合。类似地，DSPy 也允许将各种处理步骤（例如提示生成、数据预处理等）作为模块组合起来，构建复杂的语言模型管道。</li>
  <li><strong>优化器而非手动调优</strong>：神经网络的训练不再依赖于人工手动调整每个模型参数，而是通过使用优化算法（如梯度下降）来自动调整网络权重。同样，DSPy 的编译器通过自动化的优化策略，减少了人工设计和调优每个模型的需求</li>
</ul>

<h5 id="实现">实现</h5>

<h6 id="dspy-programming-model">DSPy programming model</h6>

<ol>
  <li>将 prompt 转换为具有自然语言类型签名的声明模块
    <ol>
      <li>DSPy 模块类似于神经网络的层，是适应任务的组件，能够抽象出各种文本转换任务，例如回答问题或总结论文。</li>
      <li>对每个模块进行参数化，能够通过在管道中反复引导有用的示范来学习其预期的行为。</li>
    </ol>
  </li>
</ol>

<blockquote>
  <p>pipeline 构建：</p>
  <ol>
    <li>声明所需模块</li>
    <li>使用的逻辑流来逻辑地连接模块</li>
  </ol>
</blockquote>

<h6 id="dspy-compiler">DSPy compiler</h6>
<ol>
  <li><strong>编译器的作用</strong>：
    <ul>
      <li><strong>优化 DSPy 程序</strong>：提升程序的质量或降低其成本。</li>
      <li><strong>自动映射</strong>：
        <ul>
          <li><strong>高质量组合</strong>：编译器自动将声明式模块映射为高质量的提示（prompting）、微调（finetuning）、推理（reasoning）和增强（augmentation）的组合，从而优化整个管道的性能。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>编译器的输入</strong>：
    <ul>
      <li><strong>程序</strong>：待优化的 DSPy 程序。</li>
      <li><strong>训练输入</strong>：少量带有可选标签的训练数据。</li>
      <li><strong>验证指标</strong>：用于评估优化效果的标准。</li>
    </ul>
  </li>
  <li><strong>训练过程</strong>：
    <ul>
      <li><strong>程序模拟</strong>：编译器在给定的输入上模拟程序的不同版本。</li>
      <li><strong>自我改进</strong>：通过引导模块生成示例轨迹，编译器利用这些轨迹构建有效的少样本提示（few-shot prompts）或对管道的步骤进行小型语言模型（LMs）的微调（finetuning）。</li>
      <li><strong>模块化优化</strong>：
        <ul>
          <li><strong>Teleprompters</strong>：编译器使用称为 teleprompters 的通用优化策略来决定模块如何从数据中学习。这些策略是高度模块化的，能够灵活应用于不同的优化需求。</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h6 id="评估">评估</h6>

<p>超过专家编写 prompt 的性能</p>

<p>数学语言问题（GMS8K；Cobbe等，2021）和多跳问答</p>

<h5 id="结果">结果</h5>

<ul>
  <li>表明简单的DSPy程序在性能上优于使用手工设计提示的系统，</li>
  <li>同时也使我们的程序能够有效地使用更小、更高效的语言模型。</li>
</ul>

<h2 id="相关工作">相关工作</h2>

<p>这一段介绍了 DSPy 编程模型的背景和灵感来源，并回顾了与之相关的研究和工作。主要包括以下几个方面：</p>

<h3 id="1-灵感来源">1. <strong>灵感来源</strong>：</h3>

<ul>
  <li>DSPy 的灵感来自于 <strong>Torch</strong>, <strong>Theano</strong>, <strong>Chainer</strong> 等深度学习框架的工作，这些框架通过提供强大的抽象，推动了深度学习的发展。</li>
  <li>类似的转变也正在发生在 <strong>语言模型（LM）管道</strong> 的发展上，DSPy 的目标是为 <strong>基础模型编程（foundation model programming）</strong> 提供一个坚实的概念框架和编程抽象。</li>
  <li>DSPy 借鉴了 <strong>可微编程（differentiable programming）</strong> 的思想，但应用于语言模型调用，而非神经网络，并且在语法上借鉴了 <strong>PyTorch</strong> 的元素。</li>
</ul>

<h3 id="2-in-context-learning-及其发展">2. <strong>In-context learning 及其发展</strong>：</h3>

<ul>
  <li><strong>In-context learning（上下文学习）</strong> 是基础模型编程的关键机制，随着研究的发展，越来越多的工作表明，尤其是在 <strong>指令调优（instruction tuning）</strong> 上，我们可以通过 <strong>prompting</strong>（提示）来引导语言模型表现出复杂的行为。</li>
  <li>这些方法依赖于语言模型进行任务指定的行为，而不再依赖于传统的手工构建的启发式规则或任务特定的标注（如 <strong>weak supervision</strong>），语言模型已经能够替代这些手动构建的任务特定方法。</li>
</ul>

<h3 id="3-语言模型管道和工具的应用">3. <strong>语言模型管道和工具的应用</strong>：</h3>

<ul>
  <li>当前，语言模型管道通常会调用各种工具，包括 <strong>检索模型</strong>、<strong>多模态基础模型</strong> 和更传统的工具（如 <strong>API</strong> 和 <strong>计算器</strong>）。许多工具包（如 <strong>LangChain</strong>, <strong>Semantic Kernel</strong>, <strong>LlamaIndex</strong> 等）已经被开发出来，用于简化这些管道的搭建和应用。</li>
  <li>这些工具包通常依赖于手工编写的 <strong>prompt模板</strong> 来表达任务特定的行为，这就是 DSPy 试图解决的问题。DSPy 提供了一种更系统化的方式，避免了手动调整模板的复杂性。</li>
</ul>

<h3 id="4-离散优化和强化学习的应用">4. <strong>离散优化和强化学习的应用</strong>：</h3>

<ul>
  <li>当前有一些研究应用了 <strong>离散优化</strong> 和 <strong>强化学习（RL）</strong> 来寻找有效的提示，通常是针对单一的语言模型调用（例如 <strong>Guo et al., 2023</strong> 等）。然而，DSPy 希望将这一领域的技术推广，提供一个更通用的框架，允许从高层次的声明性签名中优化任意管道，并通过引导高质量的多阶段演示和约束来实现这一目标。</li>
  <li>在此框架中，DSPy 编译器可能会应用 <strong>模型选择技术</strong>（如交叉验证）或使用 <strong>强化学习</strong> 和 <strong>语言模型反馈</strong> 进行优化，甚至可能结合 <strong>贝叶斯超参数优化方法</strong>。</li>
</ul>

<h3 id="5-dspy-编程模型的目标与贡献">5. <strong>DSPy 编程模型的目标与贡献</strong>：</h3>

<ul>
  <li>本文旨在 <strong>展示 DSPy 编程模型的动机</strong>，并报告应用 DSPy 编译器后的新实证结果。其灵感来自于早期的研究工作，如 <strong>Bergstra et al., 2010; 2013</strong> 和 <strong>Paszke et al., 2019</strong>，这些研究通过基准数据和定性指标支持各自的编程模型。</li>
  <li>本文重点展示了 <strong>DSPy 编程模型</strong> 和其编译器如何帮助构建 <strong>出色的语言模型系统</strong>，无需手工编写提示字符串，而是通过模块化的单元来构建，从而打开了在 <strong>高级抽象层次</strong> 上系统性探索丰富设计空间的大门。</li>
</ul>

<h2 id="dspy-programming-modeldspy-编程模型">DSPy programming model（DSPy 编程模型）</h2>

<p>我们提出了 DSPy，它将语言模型视为文本生成的抽象设备，并优化其在任意计算图中的使用。</p>

<p>DSPy 程序用 Python 表达：每个程序接收任务输入（例如，要回答的问题或要总结的论文），并在一系列步骤后返回输出（例如，答案或摘要）。</p>

<p>DSPy 为自动优化贡献了三个抽象：签名、模块和提词器。</p>

<ul>
  <li>签名抽象了模块的输入/输出行为；</li>
  <li>模块替代现有的手动提示技术，可以在任意管道中组合；</li>
  <li>提词器优化管道中的所有模块，以最大化某个指标。</li>
</ul>

<h3 id="自然语言签名natural-language-signatures">自然语言签名（Natural language signatures）</h3>

<p>使用自然语言类型签名，抽象 prompt 和 fine-tuning</p>

<p>与 prompt 不同，DSPy 程序使用自然语言签名将工作分配给 LLM。</p>

<p>自然语言类型签名：</p>

<ul>
  <li>自然语言类型的函数声明，描述了输入和输出，而不是提示 LM 来实现该操作。</li>
  <li>形式：一个元组（包含输入字段和输出字段）
    <ul>
      <li>一个字段由在字段名称和可选的元数据组成</li>
      <li><strong>在使用过程中 DSPy 编译器会根据字段名称推断字段的对应的内容（ICL）</strong></li>
    </ul>
  </li>
</ul>

<h3 id="模块">模块</h3>

<p>自然语言签名定义了一个接口，而没有实现，下面就介绍如何实例化模块。</p>

<p>使用签名，返回一个具有该签名的函数
<img src="assets/posts_assets/Pasted%20image%2020241210145143.png" alt="" /></p>

<h4 id="预测模块">预测模块</h4>

<ul>
  <li>总体功能
    <ul>
      <li>是签名和模型之间的桥梁</li>
      <li>存储提供的签名、可选的语言模型、一个用于提示的演示列表</li>
    </ul>
  </li>
  <li>工作：
    <ul>
      <li>接受输入字段的关键字参数</li>
      <li>利用输入字段过构造 prompt，并包括一些示范</li>
      <li>最后调用指定的 LM 生成输出</li>
      <li>解析输出字段，将语言模型结果转换为最终的输出</li>
    </ul>
  </li>
  <li>编译模式
    <ul>
      <li>
        <ul>
          <li>当 <strong>Predict</strong> 检测到它正处于“编译模式”时，它会<strong>内部追踪输入和输出的记录</strong>（input/output traces）。这些记录用于帮助 <strong>teleprompter</strong>（优化器）在后续的引导式学习过程中生成有用的示范（demonstrations）。</li>
        </ul>
      </li>
      <li>这个过程类似于通过示范和优化来增强模型的效果，从而提升任务执行的精度和效率。</li>
    </ul>
  </li>
</ul>

<h4 id="其他内置模块">其他内置模块</h4>

<ul>
  <li><strong>将 prompt 转换为支持任何签名的模块化函数，这与任务特定细节</strong></li>
  <li>模块里内置的是（方法），而签名定义的是任务</li>
</ul>

<h4 id="参数化-将上面介绍的参数化">参数化 (将上面介绍的参数化)</h4>

<p>参数化：DSPy 在构建和使用语言模型时，通过<strong>参数化</strong>来细化和控制模型的行为。换句话说，DSPy 允许对每个语言模型调用进行精细的定制，以满足特定任务的需求。</p>

<p><strong>参数化的三个关键要素</strong>： 要使语言模型正确执行一个特定的任务或签名，DSPy 需要传递三个重要的参数：</p>

<ul>
  <li>
    <p><strong>(1) 特定的语言模型（LM）</strong>： 这里，DSPy 需要明确调用哪个语言模型。不同的语言模型可能具有不同的能力和行为。例如，某些模型可能擅长生成文本，另一些可能在推理或翻译任务上更为有效。</p>

    <p>举例来说，如果任务是生成一段文章的摘要，DSPy 可能选择一个大规模的文本生成模型；如果任务是代码生成，可能选择一个训练过编程语言的特定模型。</p>
  </li>
  <li>
    <p><strong>(2) 提示指令和字段前缀（Prompt Instructions）</strong>： 对于每个任务，DSPy 需要明确地传达给模型它应该如何执行。例如，如果任务是翻译，提示指令可能是“Translate English to French”。同时，字段的前缀（字段名如 “question” 和 “answer”）会提供更多关于任务类型的上下文，以确保模型能够理解输入的格式和输出的要求。</p>

    <p>例如：</p>

    <ul>
      <li>输入字段：“question: What is the capital of France?”</li>
      <li>输出字段：“answer: ”</li>
    </ul>

    <p>DSPy 会使用这些字段来生成任务的提示，如“Question: What is the capital of France?” 然后根据输入的“question”字段生成“answer”的输出。</p>
  </li>
  <li>
    <p><strong>(3) 演示示例（Demonstrations）</strong>： 最重要的一部分是<strong>演示示例</strong>。这些示例是 DSPy 用来指导语言模型生成正确输出的数据。演示示例提供了任务的具体表现形式，可以用来训练模型或作为少量提示（few-shot prompts）引导模型在没有完全微调的情况下学习。</p>

    <ul>
      <li>对于冻结的模型（没有进一步训练的模型），演示示例作为提示直接传递给模型，帮助模型理解如何在特定上下文中生成正确的输出。</li>
      <li>对于需要微调的模型，演示示例可以作为训练数据，帮助模型学习任务的特定行为。</li>
    </ul>
  </li>
</ul>

<p><strong>作者的主要研究在于：</strong></p>

<ul>
  <li>
    <p><strong>自动生成和选择有用的演示</strong>： DSPy 的关键优势在于能够自动生成和选择有用的演示示例。这使得用户能够为模型任务提供高质量的“少量示例”，而不必手动编写或收集大量的训练数据。通过从实际使用中不断“启动”（bootstrapping）新的演示，DSPy 可以让语言模型不断学习新的行为。</p>
  </li>
  <li>
    <p>[I] 我们可以专注于模型该怎么去做，而不是专注于生成有效示例  [created:: 2024-12-10]</p>
  </li>
</ul>

<h4 id="示例">示例</h4>

<p><strong>RAG 系统示例：</strong></p>

<p>假设你想要创建一个基于“检索增强生成”（RAG）的系统，该系统结合了<strong>检索</strong>和<strong>生成</strong>的步骤来回答问题。具体来说，RAG 系统从数据库中检索相关信息（context），然后基于这些信息生成答案。</p>

<p>以下是 RAG 系统的代码示例：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RAG</span><span class="p">(</span><span class="n">dspy</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_passages</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="c1"># 'Retrieve'模块会使用用户的默认检索设置，除非被覆盖。
</span>        <span class="n">self</span><span class="p">.</span><span class="n">retrieve</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">Retrieve</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">num_passages</span><span class="p">)</span>
        <span class="c1"># 'ChainOfThought'模块：根据检索到的context和问题生成答案。
</span>        <span class="n">self</span><span class="p">.</span><span class="n">generate_answer</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">ChainOfThought</span><span class="p">(</span><span class="sh">"</span><span class="s">context, question -&gt; answer</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">question</span><span class="p">):</span>
        <span class="c1"># 使用检索模块来获取问题的相关文档（passages）。
</span>        <span class="n">context</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">retrieve</span><span class="p">(</span><span class="n">question</span><span class="p">).</span><span class="n">passages</span>
        <span class="c1"># 使用ChainOfThought模块来根据检索到的上下文和问题生成答案。
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">generate_answer</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span> <span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">)</span>
</code></pre></div></div>

<p>示例使用：</p>

<p>用户可以通过简单的调用来使用该系统：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">RAG</span><span class="p">()(</span><span class="sh">"</span><span class="s">Where is Guaraní spoken?</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>这行代码将会使用 <code class="language-plaintext highlighter-rouge">RAG</code> 模块来回答“Where is Guaraní spoken?”这个问题，具体的操作流程是：首先检索与问题相关的文档，然后使用 <code class="language-plaintext highlighter-rouge">ChainOfThought</code> 来生成答案。</p>

<h5 id="模块化的好处">模块化的好处：</h5>

<ul>
  <li>
    <p><strong>模块化</strong>：该系统清晰地分为两个独立的模块：一个用于检索相关信息，另一个用于基于检索到的信息生成答案。这种模块化设计使得每个部分可以独立地进行开发、测试和优化。</p>
  </li>
  <li>
    <p><strong>灵活的组合</strong>：用户可以根据不同的需求替换模块。例如，<code class="language-plaintext highlighter-rouge">ChainOfThought</code> 可以替代基本的 <code class="language-plaintext highlighter-rouge">Predict</code> 模块，用来生成更复杂的答案。甚至可以根据不同的任务（例如搜索查询生成）调整模块的功能。</p>
  </li>
</ul>

<h5 id="任务定制">任务定制：</h5>

<p>通过调整签名（signature），你可以改变系统的行为。例如，如果使用签名 <code class="language-plaintext highlighter-rouge">"context, question -&gt; search query"</code>，系统将不再生成答案，而是生成一个搜索查询。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">self</span><span class="p">.</span><span class="n">generate_search_query</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">ChainOfThought</span><span class="p">(</span><span class="sh">"</span><span class="s">context, question -&gt; search query</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>这会将任务从回答问题变为生成搜索查询。这样，用户可以灵活地在不同任务之间切换。</p>

<h3 id="提示器">提示器</h3>

<p>在编译 DSPy 程序时，我们通常会调用一个提词器，它是一个<strong>优化器</strong>，接收程序、训练集和指标，并返回一个新的优化程序。不同的提词器（第 4 节）采用不同的优化策略。</p>

<ul class="task-list">
  <li class="task-list-item">
    <p><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />DSPy要人工定义管道,我们可不可以自动生成管道，让 AI 定义 pipieline，这样的 pipeline 在复杂、多变的情况下更好，减少了人工干预的需要  [created:: 2024-12-10]  [completion:: 2024-12-11]</p>
  </li>
  <li class="task-list-item">训练数据：
    <ul>
      <li>小型训练集</li>
      <li>仅使用输入数据，并不需要完整中间步骤的标签，（除非对于评估模型性能的度量标准有用）
        <ul>
          <li>减少构建一个新 pipeline 的时候需要重新标注数据</li>
        </ul>
      </li>
    </ul>
  </li>
  <li class="task-list-item">评估指标：
    <ul>
      <li>简单的指标: EM、F 1</li>
      <li>复杂的指标，平衡多个关注点</li>
    </ul>
  </li>
  <li class="task-list-item">提示器可以由 teacher 模型组成
    <ul>
      <li>用 teacher 模型生成适合的演示样例，这样可以提供一些无标签的数据进行训练.</li>
    </ul>
  </li>
</ul>

<h4 id="示例-1">示例</h4>

<h5 id="rag">RAG</h5>

<ul>
  <li>展示了如何使用一个小型的问答训练集和精确匹配指标来优化RAG模块。</li>
</ul>

<p>代码逐行解释：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Small training set with only questions and final answers.
</span><span class="n">qa_trainset</span> <span class="o">=</span> <span class="p">[</span><span class="n">dspy</span><span class="p">.</span><span class="nc">Example</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="sh">"</span><span class="s">What is the capital of France?</span><span class="sh">"</span><span class="p">,</span> <span class="n">answer</span><span class="o">=</span><span class="sh">"</span><span class="s">Paris</span><span class="sh">"</span><span class="p">)]</span>

 <span class="c1"># The teleprompter will bootstrap missing labels: reasoning chains and retrieval contexts.
</span><span class="n">teleprompter</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">BootstrapFewShot</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">dspy</span><span class="p">.</span><span class="n">evaluate</span><span class="p">.</span><span class="n">answer_exact_match</span><span class="p">)</span>
<span class="n">compiled_rag</span> <span class="o">=</span> <span class="n">teleprompter</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="nc">RAG</span><span class="p">(),</span> <span class="n">trainset</span><span class="o">=</span><span class="n">qa_trainset</span><span class="p">)</span>
</code></pre></div></div>

<p>第1-2行：定义训练集</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">qa_trainset</span> <span class="o">=</span> <span class="p">[</span><span class="n">dspy</span><span class="p">.</span><span class="nc">Example</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="sh">"</span><span class="s">What is the capital of France?</span><span class="sh">"</span><span class="p">,</span> <span class="n">answer</span><span class="o">=</span><span class="sh">"</span><span class="s">Paris</span><span class="sh">"</span><span class="p">)]</span>
</code></pre></div></div>

<ul>
  <li><strong>解释</strong>：
    <ul>
      <li>创建了一个小型的训练集 <code class="language-plaintext highlighter-rouge">qa_trainset</code>，其中包含一个问答对。</li>
      <li>每个 <code class="language-plaintext highlighter-rouge">dspy.Example</code> 包含 <code class="language-plaintext highlighter-rouge">question</code>（问题）和 <code class="language-plaintext highlighter-rouge">answer</code>（答案）两个字段。</li>
      <li>这里的训练集非常小，仅包含一个示例，但DSPy设计允许在少量数据下仍能有效工作。</li>
    </ul>
  </li>
</ul>

<p>第4-6行：引导和编译管道</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">teleprompter</span> <span class="o">=</span> <span class="n">dspy</span><span class="p">.</span><span class="nc">BootstrapFewShot</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">dspy</span><span class="p">.</span><span class="n">evaluate</span><span class="p">.</span><span class="n">answer_exact_match</span><span class="p">)</span>
<span class="n">compiled_rag</span> <span class="o">=</span> <span class="n">teleprompter</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="nc">RAG</span><span class="p">(),</span> <span class="n">trainset</span><span class="o">=</span><span class="n">qa_trainset</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><strong>解释</strong>：
    <ul>
      <li><strong>第5行</strong>：创建一个 <code class="language-plaintext highlighter-rouge">BootstrapFewShot</code> 类型的 <strong>远程提示器（teleprompter）</strong>，并指定使用的评估指标为精确匹配（EM）。
        <ul>
          <li><code class="language-plaintext highlighter-rouge">BootstrapFewShot</code> 的作用是自动生成缺失的标签，如推理链（reasoning chains）和检索上下文（retrieval contexts），从而丰富训练示例。</li>
          <li>评估指标 <code class="language-plaintext highlighter-rouge">dspy.evaluate.answer_exact_match</code> 用于衡量生成的答案与参考答案的精确匹配程度。</li>
        </ul>
      </li>
      <li><strong>第6行</strong>：使用远程提示器编译 <code class="language-plaintext highlighter-rouge">RAG</code> 模块，并传入训练集 <code class="language-plaintext highlighter-rouge">qa_trainset</code>。
        <ul>
          <li><code class="language-plaintext highlighter-rouge">RAG()</code> 创建了一个RAG模块实例，该模块包含检索（Retrieve）和生成（ChainOfThought）两个子模块。</li>
          <li><code class="language-plaintext highlighter-rouge">teleprompter.compile(RAG(), trainset=qa_trainset)</code> 会根据训练集和指定的指标，自动生成和优化RAG管道。</li>
          <li>编译后的 <code class="language-plaintext highlighter-rouge">compiled_rag</code> 是一个优化后的RAG管道，能够根据少量训练示例有效地执行问答任务。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>整体流程说明：</p>

<ol>
  <li>
    <p><strong>定义训练集</strong>：</p>

    <ul>
      <li>创建一个包含问题和答案的小型训练集。例如：“What is the capital of France?” -&gt; “Paris”。</li>
    </ul>
  </li>
  <li>
    <p><strong>创建远程提示器</strong>：</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">BootstrapFewShot</code> 使用指定的评估指标（如精确匹配）来指导管道的优化。</li>
      <li>远程提示器负责自动生成缺失的标签信息，如推理链和检索上下文，提升训练示例的质量和多样性。</li>
    </ul>
  </li>
  <li>
    <p><strong>编译优化管道</strong>：</p>

    <ul>
      <li>使用远程提示器编译RAG模块，并传入训练集。</li>
      <li>通过编译过程，DSPy 自动生成高质量的少量示例，优化RAG管道的各个模块，使其能够更好地完成问答任务。</li>
    </ul>
  </li>
</ol>

<p>优势：</p>

<ul>
  <li><strong>标签效率</strong>：只需为最终输出提供标签（答案），不需要为每个中间步骤提供标签（如推理链和检索上下文），减少了数据标注的工作量。</li>
  <li><strong>模块化与自动化优化</strong>：用户只需定义高层次的任务需求，DSPy 会自动生成和优化模块行为，使得管道能够高效且准确地完成任务。</li>
  <li><strong>少量数据有效性</strong>：即使训练集很小，通过引导生成高质量的示例，DSPy 仍能有效优化管道，适应复杂任务。</li>
</ul>

<h2 id="dspy-编译器">DSPy 编译器</h2>

<p>分为三个阶段</p>

<h3 id="阶段一候选生成">阶段一：候选生成</h3>

<p>生成数据</p>

<p>需要先造一下示例</p>

<p>用 teacher moodel 或者 zero-shot 生成一些输出，然后用指标去评估，选一些合格的好的</p>

<h3 id="阶段二参数优化">阶段二：参数优化</h3>

<p>参数优化是确保程序高效运行和达成预期目标的关键步骤。该阶段的核心任务是为每个参数选择最优的候选值，以提升整体系统的性能或降低资源消耗。</p>

<ul>
  <li>Few-shot
    <ul>
      <li>随机搜索</li>
      <li><strong>树结构的帕森估计器（Tree-structured Parzen Estimators, TPE）</strong></li>
    </ul>
  </li>
  <li>Fine-tuning
    <ul>
      <li>更新模块的权重</li>
    </ul>
  </li>
</ul>

<h3 id="阶段三高阶程序优化">阶段三：高阶程序优化</h3>

<p>修改程序的 pipeline</p>

<ul class="task-list">
  <li>方式一：集成
    <ul>
      <li>将引导多个相同程序的副本，然后用一个新的程序替换它，新的程序并行运行所有副本，并将它们的预测通过自定义函数（例如，多数投票）汇总成一个结果</li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />可不可让他自己优化pipeline  [created:: 2024-12-11]  [completion:: 2024-12-14]</li>
</ul>

<h2 id="目标和评估">目标和评估</h2>

<p>结果</p>

<ul>
  <li>通过 DSPy，我们可以用简洁且明确定义的模块替换手工制作的提示字符串，而不会降低质量或表达能力。</li>
  <li>参数化模块并将提示处理为优化问题使 DSPy 更适合适应不同的语言模型，并且它可能优于专家撰写的提示。</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><category term="#工具学习" /><summary type="html"><![CDATA[DSPY COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES论文学习 不懂的]]></summary></entry><entry><title type="html">T-Eval Evaluating the Tool Utilization Capability of Large Language Models Step by Step论文笔记</title><link href="http://localhost:4000/2024/12/01/T-Eval-Evaluating-the-Tool-Utilization-Capability-of-Large-Language-Models-Step-by-Step%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0.html" rel="alternate" type="text/html" title="T-Eval Evaluating the Tool Utilization Capability of Large Language Models Step by Step论文笔记" /><published>2024-12-01T00:00:00+08:00</published><updated>2024-12-01T00:00:00+08:00</updated><id>http://localhost:4000/2024/12/01/T-Eval%20Evaluating%20the%20Tool%20Utilization%20Capability%20of%20%20Large%20Language%20Models%20Step%20by%20Step%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0</id><content type="html" xml:base="http://localhost:4000/2024/12/01/T-Eval-Evaluating-the-Tool-Utilization-Capability-of-Large-Language-Models-Step-by-Step%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0.html"><![CDATA[<h1 id="t-eval-evaluating-the-tool-utilization-capability-of-large-language-models-step-by-step论文笔记">T-Eval Evaluating the Tool Utilization Capability of Large Language Models Step by Step论文笔记</h1>

<!---more-->
<h2 id="摘要">摘要</h2>

<h3 id="背景">背景</h3>

<ul>
  <li>LLM 工具学习的发展</li>
  <li>如何评估 LLMs 的工具的利用能力还有待研究</li>
</ul>

<h3 id="工作">工作</h3>

<ul>
  <li>与之前全面评估模型的研究相比，我们综合地将工具利用分解为多个子过程，包括遵循指令、规划、推理、检索、理解和复习。</li>
</ul>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><summary type="html"><![CDATA[T-Eval Evaluating the Tool Utilization Capability of Large Language Models Step by Step论文笔记]]></summary></entry><entry><title type="html">Tool Learning through Simulated Trial and Error论文笔记</title><link href="http://localhost:4000/2024/11/29/Tool-Learning-through-Simulated-Trial-and-Error%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0.html" rel="alternate" type="text/html" title="Tool Learning through Simulated Trial and Error论文笔记" /><published>2024-11-29T00:00:00+08:00</published><updated>2024-11-29T00:00:00+08:00</updated><id>http://localhost:4000/2024/11/29/Tool%20Learning%20through%20Simulated%20Trial%20and%20Error%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0</id><content type="html" xml:base="http://localhost:4000/2024/11/29/Tool-Learning-through-Simulated-Trial-and-Error%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0.html"><![CDATA[<h1 id="2024-11-29-tool-learning-through-simulated-trial-and-error论文笔记">2024-11-29-Tool Learning through Simulated Trial and Error论文笔记</h1>

<!---more-->
<h2 id="摘要">摘要</h2>

<blockquote>
  <p>短期记忆和长期记忆是什么？</p>

  <p>怎么实现的持续学习？</p>

  <p>这篇文章提升的是选择工具的准确性，还是使用工具的操作的准确性？</p>

  <p>试错也是一种认识工具，感觉这些研究都是主动让 LLM 使用预设的认知工具，然后提升性能。就比这种试错的思想是在 query 中给出而不是 LLM 自己得出的。就是说试错这种规则是人告诉 LLM 让他按这种规则做，而不是 LLM 学会这种规则后自就做。</p>

  <p>这篇文章就感觉就是先造数据、知识，然后再将知识转换为参数形式（微调）</p>

  <p>为什么不用 DPO 呢？</p>
</blockquote>

<h3 id="背景">背景</h3>

<ul>
  <li>工具学习有一定作用</li>
  <li>现在主要研究是工具的广泛覆盖和添加新工具的灵活性上</li>
</ul>

<h3 id="问题">问题</h3>

<ul>
  <li>LLM 在使用工具时的准确性被人忽略了
    <ul>
      <li>现有 LLM 使用工具的正确率只有 30%到 60%</li>
    </ul>
  </li>
</ul>

<h3 id="工作">工作</h3>

<ul>
  <li>提出了 simulated trial and error (STE) 的方法
    <ul>
      <li>思路：模仿生物中成功工具使用行为的三个关键机制：试错、想象和记忆。</li>
      <li>具体：
        <ul>
          <li>STE 利用大型语言模型（LLM）的“想象力”来模拟使用工具的合理场景，之后 LLM 与工具互动，以从其执行反馈中学习</li>
          <li>短期记忆和长期记忆均被运用，以分别提高探索的深度和广度。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="实验">实验</h3>

<ul>
  <li>对于ToolBench的综合实验显示，STE在上下文学习和微调设置下显著提高了大型语言模型（LLMs）的工具学习。
    <ul>
      <li>为Mistral-Instruct-7B带来了46.7%的提升，使其超越了GPT-4。</li>
    </ul>
  </li>
  <li>我们还展示了通过简单的经验重放策略实现工具的有效持续学习。</li>
</ul>

<h2 id="引言">引言</h2>

<h3 id="背景-1">背景</h3>

<p>工具学习有所发展：</p>

<ul>
  <li>帮助模型超越静态参数中的知识</li>
  <li>可以获取最新的信息、调用外部推理者、影响外部世界</li>
</ul>

<p>当前主要研究方向：</p>

<ul>
  <li>提高新工具的便利性或能使用更多的工具 (Tool LLM  掌握 16000+ API)
    <ul>
      <li>方法：
        <ul>
          <li>使用 In Conext Learning (ICL) 使得 LLM 从上下文中学习工具</li>
          <li>通过 LLMs 造工具使用示例进行微调</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>问题：</p>

<ul>
  <li>LLM 在使用其训练过的工具时的准确性被忽略了
    <ul>
      <li>ICL 灵活但难以达到生产级的准确性。</li>
      <li>微调可以通过整合更多示例来潜在地提高准确性，但现有的研究大多侧重于推广到未见过的工具，而不是优化 LLM 在训练期间已见工具的使用能力</li>
    </ul>
  </li>
  <li>准确性的需求很大：
    <ul>
      <li>例如金融交易或其他具有法律约束力的操作。不准确的工具使用可能导致不必要或有害的结果，并迅速破坏用户信任。</li>
    </ul>
  </li>
</ul>

<h3 id="工作-1">工作</h3>

<h4 id="作者的解决思路">作者的解决思路</h4>

<p>如何真正掌握一种工具？</p>

<ul>
  <li>试错法对于工具学习至关重要
    <ul>
      <li>我们并不仅仅是通过阅读用户手册来掌握工具，而且从成功和失败中学习</li>
    </ul>
  </li>
  <li>试错：聪明的动物不是随机进行试错而是主动想象或模拟目前无法感知的合理情景进行探索</li>
  <li>记忆：记忆，无论是短期还是长期，对于工具的渐进学习和反复使用都起着重要作用</li>
</ul>

<h4 id="作者的解决方法">作者的解决方法</h4>

<p>提出了 simulated ttrial and error (STE) 的方法,，一种基于生物的工具增强型 LLM 的方法</p>

<ol>
  <li>模拟：给定一个工具（API），STE 利用 LLM 模拟或想象是用该工具的克星场景（即指令），</li>
  <li>试错：然后，它通过合成、执行并观察 API 调用的反馈，迭代与 API 进行交互，完成该场景，并反思之前的尝试</li>
</ol>

<p>设计了记忆机制，用于提高模拟指令的质量：</p>

<ul>
  <li>短期记忆：有最近的试错轨迹组成，用于提高单个场景中的更深入探索</li>
  <li>长期记忆：包含过去提炼过的探索和反思，维持长期的渐进学习。</li>
</ul>

<p>在开发阶段：可以用探索实验中的工具使用示例来 fine-tuning 或者 In-context Learning</p>

<h4 id="实验结果">实验&amp;结果</h4>

<p>在 ToolBench 中的 API 进行了全面实验</p>

<ul>
  <li>现在 LLM 使用工具的可靠性还有很大差距：
    <ul>
      <li>GPT-4（OpenAI, 2023）的正确率为 60.8%，</li>
      <li>而专门为工具使用进行微调的 ToolLLaMAv 2（Qin et al., 2024）仅为 37.3%。</li>
    </ul>
  </li>
  <li>STE 在增强 LLM 与工具的结合方面很有效（ICL 或 fine-tuning）
    <ul>
      <li>STE 将 Mistral-Instruct-7 B（Jiang et al., 2023）的工具使用能力提高到 76.8%（绝对提升 46.7%），使其在 ICL 下超越了 GPT-4。</li>
    </ul>
  </li>
  <li>新工具添加会造成灾难性遗忘（fine-tuning）: 学习新工具可能导致 LLM 失去其现有的工具使用能力或通用语言能力
    <ul>
      <li>作者提出了一种简单的经验重放策略(experience replay strategy)，缓解了这一问题，以实现工具的持续学习</li>
    </ul>
  </li>
</ul>

<h2 id="方法介绍siimulated-trial-and-error-ste">方法介绍：Siimulated Trial and Error (STE)</h2>

<p>STE 由两个阶段组成：探索阶段和利用阶段</p>

<h3 id="探索阶段">探索阶段</h3>

<ul>
  <li>对于每个 API：LLM 在预算范围内与 API 进行交互，以尽可能多地获取有关 API 的信息</li>
  <li>探索方式：
    <ul>
      <li><img src="assets/posts_assets/Pasted%20image%2020241130163332.png" alt="" /></li>
      <li>在每个试验中，基于 API 描述，LLM想象一个与 API 相关的合理用户查询；</li>
      <li>试图通过与 API 交互来满足该查询；</li>
      <li>反思该试验，以促进后续的探索。</li>
    </ul>
  </li>
</ul>

<h4 id="迭代自我修正与执行工具得到反馈">迭代自我修正与执行工具得到反馈</h4>

<p>思路：LLM 通过工具的执行反馈来修正其输出</p>

<p>具体：采用 ReAct 格式：</p>

<ol>
  <li>LLM 首先将其内部思维进行口头表达，然后再调 API</li>
  <li>再重复思考→行动→观察过程，直到模型决定 API 调用已经返回了足够的信息或者达到了预定义的最大调用次数
    <ul>
      <li>这个阶段用 ICL 学习纠正 API 调用中的语法和语义的错误，收集工具使用姜堰作为细粒度试错轨迹</li>
    </ul>
  </li>
  <li>模型对用户的查询做出响应，并自我反思所搜索的查询是否成功满足</li>
</ol>

<h4 id="短期记忆">短期记忆</h4>

<p><img src="assets/posts_assets/Pasted%20image%2020241130170405.png" alt="" /></p>

<ul>
  <li>该记忆由最近试验的探索轨迹组成，LLM 被指示在该记忆的条件下进行后续试验</li>
  <li>每个回合都从一个新的短期记忆开始，新进行的试验会动态地添加到记忆中，持续一定的试验次数。</li>
</ul>

<h4 id="长期记忆">长期记忆</h4>

<ul>
  <li>
    <p>短期记忆只能存储少量的试验，因为细致的轨迹会迅速消耗大型语言模型（LLM）的上下文容量。</p>
  </li>
  <li>
    <p>长期记忆作用：该记忆存储来自过去情境的提炼试错经验，以支持在较长时间范围内的渐进学习。</p>
  </li>
</ul>

<p>具体实现：</p>

<ul>
  <li>长期记忆记录了过去探索的查询及其是否被判断为成功完成（图 2，右侧）。</li>
  <li>它仅在每个新试验开始时加载到上下文中，确保本次想象的场景与之前不一样。</li>
  <li>通过这种方式，长期记忆作为一个不断增长的过去成功与失败库，使 LLM 能够不断扩大探索，从而在不同情节中取得进展。</li>
</ul>

<h3 id="利用阶段">利用阶段</h3>
<p>从探索阶段获得的试验被用来通过 fine-tuning 或上下文学习（ICL）来增强大型语言模型（LLM）的工具使用能力。</p>

<ol>
  <li>对于每个试验，我们提取合成的用户查询、LLM 的最后一次 API 调用及其执行结果，以及试验轨迹中的最终响应。</li>
  <li>然后，我们使用 GPT-4 进行过滤，以判断每个示例的有效性，并为每个新的 API 对有效示例进行改写，使其大致相同（附录 E），以在不同 API 之间保持平衡，并进一步为合成的工具使用示例增加语言变化</li>
  <li>训练：
    <ol>
      <li>对于微调，我们使用标准的语言建模目标，损失仅在工具使用/响应生成部分计算，而不包括上下文中的 API 文档。</li>
      <li>对于 ICL，合成示例用作演示池，从中检索上下文示例并附加到LLM的上下文中的API文档。我们使用一种动态的最近邻演示选择策略，其中与测试用户查询在语义上最接近的示例被检索为上下文示例</li>
    </ol>
  </li>
</ol>

<h2 id="实验-1">实验</h2>

<h3 id="工具">工具</h3>

<ul>
  <li>使用 ToolBench 中选了 50 个 API 可以免费并且低延迟的，涵盖搜索引擎，特定领域的信息检索 API，以及解决问题的 API （计算器）</li>
</ul>

<h3 id="探索阶段的设置">探索阶段的设置</h3>

<ul>
  <li>使用 ChatGPT（16 k-0613）进行探索和释义，并使用 GPT-4（8 k-0613）进行最终示例过滤。</li>
  <li>每次试验的最大 API 调用次数设置为 4</li>
  <li>每个 API，探索阶段持续 15 个回合，每个回合进行 4 次试验，总共在过滤和释义之前产生 60 个示例。</li>
  <li>过滤后，每个 API 随机选择 15 个示例进入测试集，其余的被释义和重述成大约 140 个示例，总计约 7 K 的工具使用示例。（对于测试示例，我们手动检查并纠正任何问题（如有），以确保测试集的质量。）</li>
</ul>

<h3 id="基线使用-ste">基线&amp;使用 STE</h3>

<p>基础模型： Llama-2-Chat-7 B/13 B 、Mistral-Instruct-7 B 和 GPT-3.5-turbo/GPT-4（仅限 ICL），并比较它们在有无 STE 情况下的性能</p>

<p>基线：ToolLLaMA-v 2（它基于 Llama-2-7 B，并在 126 K 个由 ChatGPT 3.5-turbo 合成的一般工具使用示例上进行了微调，涵盖了来自 RapidAPI 的大量工具，包括我们实验中使用的工具。）</p>

<p>实验设置：</p>

<ul>
  <li>ICL：使用 SentenceBERT 的 paraphrase-mpnet-base-v 2 模型来计算语义相似度，并选择与测试查询最接近的前 8 个示例作为上下文演示
    <ul>
      <li>对于使用 ICL 的 Llama-2，由于完整的 50 个 API 文档的令牌长度（约 7 K 个令牌）超出了其上下文长度（4096），我们为模型添加了一个 oracle tool retriever，该检索器根据相关文档检索与真实 API 最相似的前 15 个 API。</li>
    </ul>
  </li>
  <li>我们将规模相近的其他模型（7 B/13 B）与相同的工具检索器结合使用（当 ICL 用于利用阶段时）</li>
  <li>Fine-tuning：为了公平不添加的 API 文档</li>
</ul>

<h3 id="评估指标">评估指标</h3>

<ul>
  <li>正确性：调 API 名字正确，参数正确，考虑到 API 名称和参数</li>
  <li>Wellformedness：有效 API 调用且没有语法/格式错误(调 API 的格式)的示例百分比</li>
  <li>API 匹配性：正确选择使用真实 API 的示例百分比</li>
</ul>

<blockquote>
  <p>直接检查是否回答用户问题不行，因为大部分 API 是动态的现实世界信息单独</p>

  <p>例如，天气“明天”，其中日期取决于进行 API 调用的实际时间），这使得此类评估不可行。我们将这一挑战留给未来的研究。</p>
</blockquote>

<h2 id="结果">结果</h2>

<h3 id="ste-的效果">STE 的效果</h3>

<p><img src="/assets/posts_assets/Pasted%20image%2020241130220438.png" alt="" /></p>

<ul>
  <li>基线：
    <ul>
      <li>GPT-4 最好，但是正确率只有 60.8%</li>
      <li>Llama 和 Mistral 都不比较差，因为他们进行 API 调用时无法遵循规定的句法/格式要求</li>
      <li>ToolLLaMAv 2经过了广泛的工具使用微调，但其表现仍远低于 GPT-3.5/4,</li>
      <li>ToolLLaMAv 2 比 Llama 2 ，它的性能提升似乎主要来自于格式的良好程度，但在选择正确的工具和预测正确的参数方面仍面临严重困难
        <ul>
          <li>结论：表明，仅仅针对一般工具使用进行微调是不够的，无法达到实际部署所需的性能水平。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>STE 在 fine-tuning 中和 ICL 中都有很好的效果
    <ul>
      <li>Mistral-Instruct-7 B 在 ICL 下的性能超过了 GPT-4，达到了 76.8%</li>
      <li>STE 在 Mistral-Instruct-7 B 上的性能提升了 46.7%，使其超越了 GPT-4</li>
    </ul>
  </li>
  <li>使用 STE 进行微调还使 LLM 在合规性和选择正确工具方面几乎完美。
    <ul>
      <li>这可能是因为微调允许将更广泛的工具使用示例注入模型，而不仅仅是 ICL。虽然由于成本和可用性我们无法微调 GPT-3.5/4，但可以合理假设，STE 可能会进一步提升它们的工具使用能力，超越其当前的 ICL 表现。</li>
    </ul>
  </li>
</ul>

<h3 id="消融实验">消融实验</h3>

<p><img src="/assets/posts_assets/Pasted%20image%2020241130222754.png" alt="" /></p>

<ol>
  <li>没有执行反馈的探索可能会产生大量格式不正确的示例，其中 API 调用不符合语法/格式要求；</li>
  <li>短期和长期记忆都证明对有效的试验和错误至关重要；</li>
  <li>自我反思在保持信息丰富的长期记忆以进行探索方面很重要。</li>
</ol>

<ul>
  <li>短期记忆有效地推动 LLM 从工具中全面探索细致的信息
    <ul>
      <li>缺乏短期记忆的探索导致积极使用工具示例的比例显著下降（78.3%→51.7%），因为模型无法从细粒度的过去错误中学习以促进未来的试验</li>
    </ul>
  </li>
  <li>长期记忆在较长时间范围内改善了整体多样性</li>
</ul>

<h3 id="错误分析">错误分析</h3>

<h4 id="基础模型的错误无-ste">基础模型的错误（无 STE）</h4>
<ul>
  <li>API 错误选择
    <ul>
      <li><img src="/assets/posts_assets/Pasted%20image%2020241130223811.png" alt="" /></li>
      <li>使用 ICL 和 STE 示例可以通过更好地说明 API 的细粒度语义来解决大约一半此类错误</li>
    </ul>
  </li>
  <li>缺失/错误的参数
    <ul>
      <li>STE 对于此类错误特别有效</li>
    </ul>
  </li>
  <li>难以评估的示例
    <ul>
      <li><img src="/assets/posts_assets/Pasted%20image%2020241130224133.png" alt="" /></li>
      <li>对于大约三分之一的错误示例（表 6 中的一个示例），判断模型预测的正确性是困难的。造成这种情况的主要原因有
        <ul>
          <li>存在功能重叠的工具，这使得真实情况不唯一</li>
          <li>某些工具的时间敏感性质妨碍了一致的真实情况。</li>
        </ul>
      </li>
      <li>现有研究（Qin 等，2024；Patil 等，2023）也指出了工具使用评估中的这种困难，这对未来的研究仍然是一个开放的挑战</li>
    </ul>
  </li>
</ul>

<h4 id="微调后的错误">微调后的错误</h4>

<p>用的是最强的（Mistral-Instruct-7 B）</p>

<ul>
  <li>常识/世界知识（47.4%）。许多工具需要常识/世界知识。图 3 (a) 展示了一个示例，其中调用 API 需要知道目标交通站的 4 个字符缩写，而模型在这里产生了错误的缩写。可以通过扩展或额外的知识检索来缓解这个问题。</li>
  <li>语言理解（31.6%）。某些错误是由于缺乏基本的语言理解能力造成的。图 3 (b) 展示了一个示例，其中模型误解了用户查询，从而导致错误的参数。使用更强大的基础语言模型可以减少此类错误。</li>
  <li>基础知识（21.1%）。我们发现一些错误是由于缺乏基础知识，模型生成的 API 调用在语义上是正确的，但没有基于 API 约束进行支持。</li>
</ul>

<h4 id="持续工具学习">持续工具学习</h4>

<p>尽管微调在工具使用方面显著优于示例学习，但一个缺点是由于灾难性遗，导致灵活性可能下降。</p>

<p>由于从头开始重新训练模型成本高昂且会影响灵活性，我们探索了持续学习（CL），并表明简单的复习（Scialom et al., 2022）似乎足以实现与 STE 的持续工具学习。</p>

<p>方法：</p>

<ol>
  <li>
    <p><strong>工具的批次添加</strong>：</p>

    <ul>
      <li>研究人员将可用的工具分为四个连续的批次，逐步引入这些工具，模拟模型在不断学习新工具的情况下的表现。</li>
    </ul>
  </li>
  <li>
    <p><strong>回放缓冲区（Replay Buffer）</strong>：</p>

    <ul>
      <li>在每一轮训练中，为了避免模型遗忘已学过的工具，研究人员将每个API（工具）的10%用例从之前的批次中添加到回放缓冲区。这类似于记忆复习的概念，确保模型在学习新工具时不会遗忘之前学过的内容。</li>
    </ul>
  </li>
  <li>
    <p><strong>保持通用能力</strong>：</p>

    <ul>
      <li>为了确保模型不仅在使用工具上表现良好，还能保留其通用的语言能力（例如理解和生成自然语言），每一轮训练都会从<strong>FlanV2</strong>数据集中随机抽取2,000个样本来进行训练。这是一个高质量的通用指令数据集。</li>
      <li>同时，评估模型的通用能力时，使用了<strong>MMLU（Massive Multitask Language Understanding）</strong>和<strong>BBH（Big-Bench-Hard）</strong>这两个广泛使用的基准测试集。</li>
    </ul>
  </li>
  <li>
    <p><strong>模型表现</strong>：</p>

    <ul>
      <li>研究发现，如果没有回放机制（rehearsal），模型会严重遗忘之前学过的工具，尤其是较早学到的工具。回放机制能够有效地缓解这种遗忘问题，使得模型在新的训练阶段，能够保留对旧工具的知识。</li>
      <li>使用回放机制的<strong>CL-trained模型</strong>（即经过持续学习训练的模型）在性能上与<strong>Llama-FT</strong>（即在大规模数据集上经过微调的Llama模型）相当，表现出在学习新工具的同时，依然保持了良好的语言理解能力。</li>
    </ul>
  </li>
  <li>
    <p><strong>经验回放在LLM工具学习中的应用</strong>：</p>

    <ul>
      <li>该研究扩展了<strong>Scialom et al. (2022)</strong> 的发现，证明了经验回放在语言模型工具学习中的有效性。通过这种方法，模型可以灵活地学习新工具，同时避免忘记已经掌握的知识。</li>
    </ul>
  </li>
</ol>]]></content><author><name>Xingjie Gao</name><email>xingjie-gao@outlook.com</email></author><category term="nlp" /><category term="自然语言处理" /><category term="论文笔记" /><summary type="html"><![CDATA[2024-11-29-Tool Learning through Simulated Trial and Error论文笔记]]></summary></entry></feed>